Using cuda device

-------------------- Epoch 1 --------------------
Train loss: 0.9999
Test loss: 202.32319196065268
Test loss: 208.63079071044922
New best validation loss: 202.3232, saving model weights to best_model_weights.pth

-------------------- Epoch 2 --------------------
Train loss: 1.0029
Test loss: 202.32556279500326
Test loss: 208.63317362467447
Validation loss: 202.3256

-------------------- Epoch 3 --------------------
Train loss: 1.0006
Test loss: 202.32402229309082
Test loss: 208.63161404927573
Validation loss: 202.3240

-------------------- Epoch 4 --------------------
Train loss: 1.0046
Test loss: 202.32658449808756
Test loss: 208.63420867919922
Validation loss: 202.3266

-------------------- Epoch 5 --------------------
Train loss: 1.0049
Test loss: 202.323756535848
Test loss: 208.63133684794107
Validation loss: 202.3238

-------------------- Epoch 6 --------------------
Train loss: 1.0005
Test loss: 202.32992935180664
Test loss: 208.637570699056
Validation loss: 202.3299

-------------------- Epoch 7 --------------------
Train loss: 1.0041
Test loss: 202.32489140828451
Test loss: 208.6324723561605
Validation loss: 202.3249

-------------------- Epoch 8 --------------------
Train loss: 0.9993
Test loss: 202.329953511556
Test loss: 208.63759803771973
Validation loss: 202.3300

-------------------- Epoch 9 --------------------
Train loss: 1.0051
Test loss: 202.33169809977213
Test loss: 208.63934516906738
Validation loss: 202.3317

-------------------- Epoch 10 --------------------
Train loss: 1.0043
Test loss: 202.3289000193278
Test loss: 208.63651847839355
Validation loss: 202.3289

-------------------- Epoch 11 --------------------
Train loss: 1.0033
Test loss: 202.3269837697347
Test loss: 208.63456217447916
Validation loss: 202.3270

-------------------- Epoch 12 --------------------
Train loss: 1.0011
Test loss: 202.32570457458496
Test loss: 208.63327725728354
Validation loss: 202.3257

-------------------- Epoch 13 --------------------
Train loss: 1.0010
Test loss: 202.32171694437662
Test loss: 208.6292241414388
New best validation loss: 202.3217, saving model weights to best_model_weights.pth

-------------------- Epoch 14 --------------------
Train loss: 1.0012
Test loss: 202.32806968688965
Test loss: 208.63564745585123
Validation loss: 202.3281

-------------------- Epoch 15 --------------------
Train loss: 1.0011
Test loss: 202.31482378641763
Test loss: 208.62225087483725
New best validation loss: 202.3148, saving model weights to best_model_weights.pth

-------------------- Epoch 16 --------------------
Train loss: 1.0014
Test loss: 202.3261013031006
Test loss: 208.63364219665527
Validation loss: 202.3261

-------------------- Epoch 17 --------------------
Train loss: 1.0032
Test loss: 202.32846959431967
Test loss: 208.63602765401205
Validation loss: 202.3285

-------------------- Epoch 18 --------------------
Train loss: 1.0042
Test loss: 202.33101654052734
Test loss: 208.63860003153482
Validation loss: 202.3310

-------------------- Epoch 19 --------------------
Train loss: 1.0044
Test loss: 202.32351620992026
Test loss: 208.63099988301596
Validation loss: 202.3235

-------------------- Epoch 20 --------------------
Train loss: 1.0028
Test loss: 202.31553586324057
Test loss: 208.62294006347656
Validation loss: 202.3155

-------------------- Epoch 21 --------------------
Train loss: 1.0041
Test loss: 202.32442410786948
Test loss: 208.63189697265625
Validation loss: 202.3244

-------------------- Epoch 22 --------------------
Train loss: 1.0004
Test loss: 202.3210538228353
Test loss: 208.62848472595215
Validation loss: 202.3211

-------------------- Epoch 23 --------------------
Train loss: 1.0003
Test loss: 202.32698694864908
Test loss: 208.63448842366537
Validation loss: 202.3270

-------------------- Epoch 24 --------------------
Train loss: 1.0054
Test loss: 202.3318920135498
Test loss: 208.63943354288736
Validation loss: 202.3319

-------------------- Epoch 25 --------------------
Train loss: 1.0030
Test loss: 202.32792536417642
Test loss: 208.63543128967285
Validation loss: 202.3279

-------------------- Epoch 26 --------------------
Train loss: 1.0040
Test loss: 202.32939592997232
Test loss: 208.63691329956055
Validation loss: 202.3294

-------------------- Epoch 27 --------------------
Train loss: 1.0053
Test loss: 202.3273639678955
Test loss: 208.63486289978027
Validation loss: 202.3274

-------------------- Epoch 28 --------------------
Train loss: 0.9999
Test loss: 202.31859715779623
Test loss: 208.6259994506836
Validation loss: 202.3186

-------------------- Epoch 29 --------------------
Train loss: 0.9996
Test loss: 202.32555452982584
Test loss: 208.633025487264
Validation loss: 202.3256

-------------------- Epoch 30 --------------------
Train loss: 1.0085
Test loss: 202.3189608256022
Test loss: 208.62635930379233
Validation loss: 202.3190

-------------------- Epoch 31 --------------------
Train loss: 1.0029
Test loss: 202.32377688090006
Test loss: 208.63123257954916
Validation loss: 202.3238

-------------------- Epoch 32 --------------------
Train loss: 1.0021
Test loss: 202.31294631958008
Test loss: 208.6202850341797
New best validation loss: 202.3129, saving model weights to best_model_weights.pth

-------------------- Epoch 33 --------------------
Train loss: 1.0054
Test loss: 202.32287152608237
Test loss: 208.63030560811362
Validation loss: 202.3229

-------------------- Epoch 34 --------------------
Train loss: 1.0032
Test loss: 202.3339055379232
Test loss: 208.6414655049642
Validation loss: 202.3339

-------------------- Epoch 35 --------------------
Train loss: 1.0025
Test loss: 202.3186410268148
Test loss: 208.62600644429526
Validation loss: 202.3186

-------------------- Epoch 36 --------------------
Train loss: 1.0009
Test loss: 202.31861877441406
Test loss: 208.6259848276774
Validation loss: 202.3186

-------------------- Epoch 37 --------------------
Train loss: 1.0020
Test loss: 202.32597287495932
Test loss: 208.63342094421387
Validation loss: 202.3260

-------------------- Epoch 38 --------------------
Train loss: 1.0010
Test loss: 202.32222175598145
Test loss: 208.62954584757486
Validation loss: 202.3222

-------------------- Epoch 39 --------------------
Train loss: 1.0022
Test loss: 202.31951014200845
Test loss: 208.62680308024088
Validation loss: 202.3195

-------------------- Epoch 40 --------------------
Train loss: 1.0078
Test loss: 202.31647809346518
Test loss: 208.62366803487143
Validation loss: 202.3165

-------------------- Epoch 41 --------------------
Train loss: 1.0032
Test loss: 202.31610425313315
Test loss: 208.62332979838052
Validation loss: 202.3161

-------------------- Epoch 42 --------------------
Train loss: 1.0020
Test loss: 202.31620152791342
Test loss: 208.6233425140381
Validation loss: 202.3162

-------------------- Epoch 43 --------------------
Train loss: 1.0031
Test loss: 202.31472969055176
Test loss: 208.62179056803384
Validation loss: 202.3147

-------------------- Epoch 44 --------------------
Train loss: 1.0026
Test loss: 202.32468541463217
Test loss: 208.63185691833496
Validation loss: 202.3247

-------------------- Epoch 45 --------------------
Train loss: 1.0015
Test loss: 202.31574376424155
Test loss: 208.62277030944824
Validation loss: 202.3157

-------------------- Epoch 46 --------------------
Train loss: 1.0030
Test loss: 202.30804888407388
Test loss: 208.61488469441733
New best validation loss: 202.3080, saving model weights to best_model_weights.pth

-------------------- Epoch 47 --------------------
Train loss: 1.0009
Test loss: 202.33405558268228
Test loss: 208.64119021097818
Validation loss: 202.3341

-------------------- Epoch 48 --------------------
Train loss: 1.0045
Test loss: 202.31789779663086
Test loss: 208.62469291687012
Validation loss: 202.3179

-------------------- Epoch 49 --------------------
Train loss: 1.0043
Test loss: 202.33779335021973
Test loss: 208.644775390625
Validation loss: 202.3378

-------------------- Epoch 50 --------------------
Train loss: 1.0064
Test loss: 202.32353528340658
Test loss: 208.62997563680014
Validation loss: 202.3235

-------------------- Epoch 51 --------------------
Train loss: 1.0032
Test loss: 202.32175636291504
Test loss: 208.62790298461914
Validation loss: 202.3218

-------------------- Epoch 52 --------------------
Train loss: 1.0003
Test loss: 202.3183765411377
Test loss: 208.62431526184082
Validation loss: 202.3184

-------------------- Epoch 53 --------------------
Train loss: 1.0000
Test loss: 202.31790733337402
Test loss: 208.62374687194824
Validation loss: 202.3179

-------------------- Epoch 54 --------------------
Train loss: 1.0055
Test loss: 202.2898743947347
Test loss: 208.59516143798828
New best validation loss: 202.2899, saving model weights to best_model_weights.pth

-------------------- Epoch 55 --------------------
Train loss: 0.9995
Test loss: 202.31110509236655
Test loss: 208.61670684814453
Validation loss: 202.3111

-------------------- Epoch 56 --------------------
Train loss: 1.0003
Test loss: 202.30382855733237
Test loss: 208.60924084981283
Validation loss: 202.3038

-------------------- Epoch 57 --------------------
Train loss: 1.0020
Test loss: 202.3027718861898
Test loss: 208.608003616333
Validation loss: 202.3028

-------------------- Epoch 58 --------------------
Train loss: 1.0006
Test loss: 202.2586409250895
Test loss: 208.5627841949463
New best validation loss: 202.2586, saving model weights to best_model_weights.pth

-------------------- Epoch 59 --------------------
Train loss: 1.0003
Test loss: 202.25465710957846
Test loss: 208.55851809183756
New best validation loss: 202.2547, saving model weights to best_model_weights.pth

-------------------- Epoch 60 --------------------
Train loss: 1.0026
Test loss: 202.2576993306478
Test loss: 208.56136322021484
Validation loss: 202.2577

-------------------- Epoch 61 --------------------
Train loss: 1.0003
Test loss: 202.25853411356607
Test loss: 208.5619970957438
Validation loss: 202.2585

-------------------- Epoch 62 --------------------
Train loss: 1.0042
Test loss: 202.25294876098633
Test loss: 208.5562655131022
New best validation loss: 202.2529, saving model weights to best_model_weights.pth

-------------------- Epoch 63 --------------------
Train loss: 1.0002
Test loss: 202.2554734547933
Test loss: 208.55852635701498
Validation loss: 202.2555

-------------------- Epoch 64 --------------------
Train loss: 1.0021
Test loss: 202.2612622578939
Test loss: 208.56432088216147
Validation loss: 202.2613

-------------------- Epoch 65 --------------------
Train loss: 1.0005
Test loss: 202.25057156880698
Test loss: 208.55323028564453
New best validation loss: 202.2506, saving model weights to best_model_weights.pth

-------------------- Epoch 66 --------------------
Train loss: 1.0004
Test loss: 202.23412132263184
Test loss: 208.53630701700845
New best validation loss: 202.2341, saving model weights to best_model_weights.pth

-------------------- Epoch 67 --------------------
Train loss: 0.9996
Test loss: 202.2385679880778
Test loss: 208.54081535339355
Validation loss: 202.2386

-------------------- Epoch 68 --------------------
Train loss: 1.0036
Test loss: 202.2468967437744
Test loss: 208.5492426554362
Validation loss: 202.2469

-------------------- Epoch 69 --------------------
Train loss: 1.0039
Test loss: 202.23226737976074
Test loss: 208.53401565551758
New best validation loss: 202.2323, saving model weights to best_model_weights.pth

-------------------- Epoch 70 --------------------
Train loss: 1.0012
Test loss: 202.19529660542807
Test loss: 208.49625523885092
New best validation loss: 202.1953, saving model weights to best_model_weights.pth

-------------------- Epoch 71 --------------------
Train loss: 1.0027
Test loss: 202.19241841634116
Test loss: 208.4930674235026
New best validation loss: 202.1924, saving model weights to best_model_weights.pth

-------------------- Epoch 72 --------------------
Train loss: 1.0045
Test loss: 202.18447240193686
Test loss: 208.4847469329834
New best validation loss: 202.1845, saving model weights to best_model_weights.pth

-------------------- Epoch 73 --------------------
Train loss: 1.0005
Test loss: 202.2430419921875
Test loss: 208.54429562886557
Validation loss: 202.2430

-------------------- Epoch 74 --------------------
Train loss: 0.9988
Test loss: 202.21078046162924
Test loss: 208.51091766357422
Validation loss: 202.2108

-------------------- Epoch 75 --------------------
Train loss: 1.0016
Test loss: 202.22508748372397
Test loss: 208.52534357706705
Validation loss: 202.2251

-------------------- Epoch 76 --------------------
Train loss: 0.9997
Test loss: 202.23349698384604
Test loss: 208.5336570739746
Validation loss: 202.2335

-------------------- Epoch 77 --------------------
Train loss: 1.0020
Test loss: 202.2275416056315
Test loss: 208.52729670206705
Validation loss: 202.2275

-------------------- Epoch 78 --------------------
Train loss: 1.0001
Test loss: 202.21333821614584
Test loss: 208.5125732421875
Validation loss: 202.2133

-------------------- Epoch 79 --------------------
Train loss: 1.0003
Test loss: 202.1667683919271
Test loss: 208.46458625793457
New best validation loss: 202.1668, saving model weights to best_model_weights.pth

-------------------- Epoch 80 --------------------
Train loss: 0.9990
Test loss: 202.1874853769938
Test loss: 208.48541514078775
Validation loss: 202.1875

-------------------- Epoch 81 --------------------
Train loss: 1.0001
Test loss: 202.18622207641602
Test loss: 208.48377164204916
Validation loss: 202.1862

-------------------- Epoch 82 --------------------
Train loss: 1.0015
Test loss: 202.16736348470053
Test loss: 208.4641933441162
Validation loss: 202.1674

-------------------- Epoch 83 --------------------
Train loss: 1.0015
Test loss: 202.19676208496094
Test loss: 208.49410502115884
Validation loss: 202.1968

-------------------- Epoch 84 --------------------
Train loss: 1.0032
Test loss: 202.19876289367676
Test loss: 208.4958667755127
Validation loss: 202.1988

-------------------- Epoch 85 --------------------
Train loss: 1.0001
Test loss: 202.1750456492106
Test loss: 208.47122955322266
Validation loss: 202.1750

-------------------- Epoch 86 --------------------
Train loss: 1.0071
Test loss: 202.1798127492269
Test loss: 208.47584279378256
Validation loss: 202.1798

-------------------- Epoch 87 --------------------
Train loss: 1.0014
Test loss: 202.2240753173828
Test loss: 208.52173932393393
Validation loss: 202.2241

-------------------- Epoch 88 --------------------
Train loss: 1.0001
Test loss: 202.14382044474283
Test loss: 208.43863932291666
New best validation loss: 202.1438, saving model weights to best_model_weights.pth

-------------------- Epoch 89 --------------------
Train loss: 1.0030
Test loss: 202.17847696940103
Test loss: 208.47426668802896
Validation loss: 202.1785

-------------------- Epoch 90 --------------------
Train loss: 1.0003
Test loss: 202.16905975341797
Test loss: 208.46452649434408
Validation loss: 202.1691

-------------------- Epoch 91 --------------------
Train loss: 1.0014
Test loss: 202.15153630574545
Test loss: 208.44603538513184
Validation loss: 202.1515

-------------------- Epoch 92 --------------------
Train loss: 1.0033
Test loss: 202.1687068939209
Test loss: 208.46368344624838
Validation loss: 202.1687

-------------------- Epoch 93 --------------------
Train loss: 1.0015
Test loss: 202.13984553019205
Test loss: 208.4338010152181
New best validation loss: 202.1398, saving model weights to best_model_weights.pth

-------------------- Epoch 94 --------------------
Train loss: 0.9994
Test loss: 202.11601384480795
Test loss: 208.4091822306315
New best validation loss: 202.1160, saving model weights to best_model_weights.pth

-------------------- Epoch 95 --------------------
Train loss: 1.0059
Test loss: 202.0954875946045
Test loss: 208.38778241475424
New best validation loss: 202.0955, saving model weights to best_model_weights.pth

-------------------- Epoch 96 --------------------
Train loss: 1.0046
Test loss: 202.13063176472983
Test loss: 208.4235324859619
Validation loss: 202.1306

-------------------- Epoch 97 --------------------
Train loss: 1.0020
Test loss: 202.1223258972168
Test loss: 208.41475105285645
Validation loss: 202.1223

-------------------- Epoch 98 --------------------
Train loss: 0.9983
Test loss: 202.10693168640137
Test loss: 208.39881579081217
Validation loss: 202.1069

-------------------- Epoch 99 --------------------
Train loss: 1.0006
Test loss: 202.0610491434733
Test loss: 208.35149892171225
New best validation loss: 202.0610, saving model weights to best_model_weights.pth

-------------------- Epoch 100 --------------------
Train loss: 1.0007
Test loss: 202.10870933532715
Test loss: 208.40027046203613
Validation loss: 202.1087

-------------------- Epoch 101 --------------------
Train loss: 0.9991
Test loss: 202.05781682332358
Test loss: 208.34782791137695
New best validation loss: 202.0578, saving model weights to best_model_weights.pth

-------------------- Epoch 102 --------------------
Train loss: 0.9990
Test loss: 202.0808130900065
Test loss: 208.3712100982666
Validation loss: 202.0808

-------------------- Epoch 103 --------------------
Train loss: 1.0020
Test loss: 202.07928148905435
Test loss: 208.3693758646647
Validation loss: 202.0793

-------------------- Epoch 104 --------------------
Train loss: 1.0020
Test loss: 202.02290852864584
Test loss: 208.31126594543457
New best validation loss: 202.0229, saving model weights to best_model_weights.pth

-------------------- Epoch 105 --------------------
Train loss: 0.9997
Test loss: 202.07013257344565
Test loss: 208.35953521728516
Validation loss: 202.0701

-------------------- Epoch 106 --------------------
Train loss: 1.0004
Test loss: 202.061061223348
Test loss: 208.349973042806
Validation loss: 202.0611

-------------------- Epoch 107 --------------------
Train loss: 0.9996
Test loss: 202.0465990702311
Test loss: 208.3348731994629
Validation loss: 202.0466

-------------------- Epoch 108 --------------------
Train loss: 1.0001
Test loss: 202.05158869425455
Test loss: 208.33981895446777
Validation loss: 202.0516

-------------------- Epoch 109 --------------------
Train loss: 0.9984
Test loss: 202.0228474934896
Test loss: 208.3102938334147
New best validation loss: 202.0228, saving model weights to best_model_weights.pth

-------------------- Epoch 110 --------------------
Train loss: 1.0001
Test loss: 202.030392964681
Test loss: 208.31781768798828
Validation loss: 202.0304

-------------------- Epoch 111 --------------------
Train loss: 1.0002
Test loss: 202.0147279103597
Test loss: 208.30144627888998
New best validation loss: 202.0147, saving model weights to best_model_weights.pth

-------------------- Epoch 112 --------------------
Train loss: 1.0027
Test loss: 202.02759234110513
Test loss: 208.31439081827799
Validation loss: 202.0276

-------------------- Epoch 113 --------------------
Train loss: 1.0002
Test loss: 202.00105412801108
Test loss: 208.28679211934408
New best validation loss: 202.0011, saving model weights to best_model_weights.pth

-------------------- Epoch 114 --------------------
Train loss: 1.0013
Test loss: 202.00708516438803
Test loss: 208.29290453592935
Validation loss: 202.0071

-------------------- Epoch 115 --------------------
Train loss: 1.0002
Test loss: 202.02648226420084
Test loss: 208.3127009073893
Validation loss: 202.0265

-------------------- Epoch 116 --------------------
Train loss: 0.9975
Test loss: 202.0473664601644
Test loss: 208.33440844217935
Validation loss: 202.0474

-------------------- Epoch 117 --------------------
Train loss: 1.0034
Test loss: 201.861328125
Test loss: 208.14324887593588
New best validation loss: 201.8613, saving model weights to best_model_weights.pth

-------------------- Epoch 118 --------------------
Train loss: 0.9996
Test loss: 202.02718925476074
Test loss: 208.31326738993326
Validation loss: 202.0272

-------------------- Epoch 119 --------------------
Train loss: 1.0000
Test loss: 201.97586250305176
Test loss: 208.25996271769205
Validation loss: 201.9759

-------------------- Epoch 120 --------------------
Train loss: 1.0017
Test loss: 201.9710235595703
Test loss: 208.25487581888834
Validation loss: 201.9710

-------------------- Epoch 121 --------------------
Train loss: 0.9985
Test loss: 201.98311614990234
Test loss: 208.2673199971517
Validation loss: 201.9831

-------------------- Epoch 122 --------------------
Train loss: 0.9990
Test loss: 201.9714724222819
Test loss: 208.25533485412598
Validation loss: 201.9715

-------------------- Epoch 123 --------------------
Train loss: 0.9986
Test loss: 201.9506861368815
Test loss: 208.23378562927246
Validation loss: 201.9507

-------------------- Epoch 124 --------------------
Train loss: 0.9994
Test loss: 201.95009167989096
Test loss: 208.23299407958984
Validation loss: 201.9501

-------------------- Epoch 125 --------------------
Train loss: 0.9982
Test loss: 201.91184616088867
Test loss: 208.19315020243326
Validation loss: 201.9118

-------------------- Epoch 126 --------------------
Train loss: 0.9989
Test loss: 202.0202121734619
Test loss: 208.30546696980795
Validation loss: 202.0202

-------------------- Epoch 127 --------------------
Train loss: 1.0030
Test loss: 201.91451708475748
Test loss: 208.19563102722168
Validation loss: 201.9145

-------------------- Epoch 128 --------------------
Train loss: 0.9983
Test loss: 201.91969045003256
Test loss: 208.20092010498047
Validation loss: 201.9197

-------------------- Epoch 129 --------------------
Train loss: 0.9968
Test loss: 201.94695790608725
Test loss: 208.22905858357748
Validation loss: 201.9470

-------------------- Epoch 130 --------------------
Train loss: 0.9976
Test loss: 201.87139129638672
Test loss: 208.1506029764811
Validation loss: 201.8714

-------------------- Epoch 131 --------------------
Train loss: 0.9987
Test loss: 201.86112467447916
Test loss: 208.13979530334473
New best validation loss: 201.8611, saving model weights to best_model_weights.pth

-------------------- Epoch 132 --------------------
Train loss: 0.9963
Test loss: 201.95621490478516
Test loss: 208.23841412862143
Validation loss: 201.9562

-------------------- Epoch 133 --------------------
Train loss: 0.9975
Test loss: 201.89450200398764
Test loss: 208.1742057800293
Validation loss: 201.8945

-------------------- Epoch 134 --------------------
Train loss: 0.9967
Test loss: 201.8685213724772
Test loss: 208.14712524414062
Validation loss: 201.8685

-------------------- Epoch 135 --------------------
Train loss: 0.9969
Test loss: 201.8456516265869
Test loss: 208.12336413065592
New best validation loss: 201.8457, saving model weights to best_model_weights.pth

-------------------- Epoch 136 --------------------
Train loss: 0.9975
Test loss: 201.90677706400552
Test loss: 208.1863842010498
Validation loss: 201.9068

-------------------- Epoch 137 --------------------
Train loss: 1.0013
Test loss: 201.88772583007812
Test loss: 208.16620508829752
Validation loss: 201.8877

-------------------- Epoch 138 --------------------
Train loss: 1.0015
Test loss: 201.8528970082601
Test loss: 208.12972704569498
Validation loss: 201.8529

-------------------- Epoch 139 --------------------
Train loss: 0.9980
Test loss: 201.89614804585776
Test loss: 208.17471631368002
Validation loss: 201.8961

-------------------- Epoch 140 --------------------
Train loss: 0.9994
Test loss: 201.90576616923013
Test loss: 208.18496449788412
Validation loss: 201.9058

-------------------- Epoch 141 --------------------
Train loss: 0.9971
Test loss: 201.84157180786133
Test loss: 208.117919921875
New best validation loss: 201.8416, saving model weights to best_model_weights.pth

-------------------- Epoch 142 --------------------
Train loss: 1.0005
Test loss: 201.85568237304688
Test loss: 208.13281631469727
Validation loss: 201.8557

-------------------- Epoch 143 --------------------
Train loss: 0.9997
Test loss: 201.79052098592123
Test loss: 208.06487592061362
New best validation loss: 201.7905, saving model weights to best_model_weights.pth

-------------------- Epoch 144 --------------------
Train loss: 0.9995
Test loss: 201.87560653686523
Test loss: 208.15340932210287
Validation loss: 201.8756

-------------------- Epoch 145 --------------------
Train loss: 1.0035
Test loss: 201.8356704711914
Test loss: 208.11161104838052
Validation loss: 201.8357

-------------------- Epoch 146 --------------------
Train loss: 0.9962
Test loss: 201.79403495788574
Test loss: 208.06841405232748
Validation loss: 201.7940

-------------------- Epoch 147 --------------------
Train loss: 1.0003
Test loss: 201.77970186869302
Test loss: 208.05326207478842
New best validation loss: 201.7797, saving model weights to best_model_weights.pth

-------------------- Epoch 148 --------------------
Train loss: 0.9978
Test loss: 201.82859738667807
Test loss: 208.10417938232422
Validation loss: 201.8286

-------------------- Epoch 149 --------------------
Train loss: 0.9976
Test loss: 201.8351287841797
Test loss: 208.1108487447103
Validation loss: 201.8351

-------------------- Epoch 150 --------------------
Train loss: 0.9992
Test loss: 201.72296905517578
Test loss: 207.9940325419108
New best validation loss: 201.7230, saving model weights to best_model_weights.pth

-------------------- Epoch 151 --------------------
Train loss: 0.9983
Test loss: 201.76635233561197
Test loss: 208.03916041056314
Validation loss: 201.7664

-------------------- Epoch 152 --------------------
Train loss: 0.9988
Test loss: 201.8446782430013
Test loss: 208.120148340861
Validation loss: 201.8447

-------------------- Epoch 153 --------------------
Train loss: 0.9988
Test loss: 201.83731079101562
Test loss: 208.11255264282227
Validation loss: 201.8373

-------------------- Epoch 154 --------------------
Train loss: 0.9958
Test loss: 201.78571319580078
Test loss: 208.0587501525879
Validation loss: 201.7857

-------------------- Epoch 155 --------------------
Train loss: 0.9967
Test loss: 201.74168904622397
Test loss: 208.01259676615396
Validation loss: 201.7417

-------------------- Epoch 156 --------------------
Train loss: 0.9997
Test loss: 201.7664909362793
Test loss: 208.03797403971353
Validation loss: 201.7665

-------------------- Epoch 157 --------------------
Train loss: 0.9977
Test loss: 201.73222796122232
Test loss: 208.00225639343262
Validation loss: 201.7322

-------------------- Epoch 158 --------------------
Train loss: 0.9981
Test loss: 201.73342768351236
Test loss: 208.00333722432455
Validation loss: 201.7334

-------------------- Epoch 159 --------------------
Train loss: 0.9994
Test loss: 201.6801554361979
Test loss: 207.94778760274252
New best validation loss: 201.6802, saving model weights to best_model_weights.pth

-------------------- Epoch 160 --------------------
Train loss: 0.9983
Test loss: 201.7046267191569
Test loss: 207.9728800455729
Validation loss: 201.7046

-------------------- Epoch 161 --------------------
Train loss: 0.9972
Test loss: 201.6745408376058
Test loss: 207.9413038889567
New best validation loss: 201.6745, saving model weights to best_model_weights.pth

-------------------- Epoch 162 --------------------
Train loss: 0.9974
Test loss: 201.82108434041342
Test loss: 208.0931936899821
Validation loss: 201.8211

-------------------- Epoch 163 --------------------
Train loss: 0.9980
Test loss: 201.7135353088379
Test loss: 207.98102696736655
Validation loss: 201.7135

-------------------- Epoch 164 --------------------
Train loss: 0.9948
Test loss: 201.654296875
Test loss: 207.91921043395996
New best validation loss: 201.6543, saving model weights to best_model_weights.pth

-------------------- Epoch 165 --------------------
Train loss: 0.9990
Test loss: 201.65793228149414
Test loss: 207.92292976379395
Validation loss: 201.6579

-------------------- Epoch 166 --------------------
Train loss: 0.9985
Test loss: 201.6807072957357
Test loss: 207.9463882446289
Validation loss: 201.6807

-------------------- Epoch 167 --------------------
Train loss: 0.9953
Test loss: 201.69142214457193
Test loss: 207.95746485392252
Validation loss: 201.6914

-------------------- Epoch 168 --------------------
Train loss: 0.9986
Test loss: 201.68925603230795
Test loss: 207.9548740386963
Validation loss: 201.6893

-------------------- Epoch 169 --------------------
Train loss: 1.0000
Test loss: 201.644380569458
Test loss: 207.9079189300537
New best validation loss: 201.6444, saving model weights to best_model_weights.pth

-------------------- Epoch 170 --------------------
Train loss: 0.9983
Test loss: 201.75238672892252
Test loss: 208.0195509592692
Validation loss: 201.7524

-------------------- Epoch 171 --------------------
Train loss: 0.9969
Test loss: 201.62905883789062
Test loss: 207.89124870300293
New best validation loss: 201.6291, saving model weights to best_model_weights.pth

-------------------- Epoch 172 --------------------
Train loss: 0.9979
Test loss: 201.67230478922525
Test loss: 207.935791015625
Validation loss: 201.6723

-------------------- Epoch 173 --------------------
Train loss: 0.9988
Test loss: 201.63882128397623
Test loss: 207.90057500203451
Validation loss: 201.6388

-------------------- Epoch 174 --------------------
Train loss: 0.9988
Test loss: 201.684445699056
Test loss: 207.94747161865234
Validation loss: 201.6844

-------------------- Epoch 175 --------------------
Train loss: 0.9944
Test loss: 201.68324597676596
Test loss: 207.94571431477866
Validation loss: 201.6832

-------------------- Epoch 176 --------------------
Train loss: 0.9988
Test loss: 201.62847010294595
Test loss: 207.8887259165446
New best validation loss: 201.6285, saving model weights to best_model_weights.pth

-------------------- Epoch 177 --------------------
Train loss: 0.9966
Test loss: 201.62161763509116
Test loss: 207.88111368815103
New best validation loss: 201.6216, saving model weights to best_model_weights.pth

-------------------- Epoch 178 --------------------
Train loss: 0.9966
Test loss: 201.58511861165366
Test loss: 207.84285036722818
New best validation loss: 201.5851, saving model weights to best_model_weights.pth

-------------------- Epoch 179 --------------------
Train loss: 0.9975
Test loss: 201.681370417277
Test loss: 207.94231287638345
Validation loss: 201.6814

-------------------- Epoch 180 --------------------
Train loss: 0.9966
Test loss: 201.63522148132324
Test loss: 207.8940340677897
Validation loss: 201.6352

-------------------- Epoch 181 --------------------
Train loss: 0.9949
Test loss: 201.57758204142252
Test loss: 207.8337484995524
New best validation loss: 201.5776, saving model weights to best_model_weights.pth

-------------------- Epoch 182 --------------------
Train loss: 0.9984
Test loss: 201.6161994934082
Test loss: 207.87369664510092
Validation loss: 201.6162

-------------------- Epoch 183 --------------------
Train loss: 0.9945
Test loss: 201.5577653249105
Test loss: 207.81250699361166
New best validation loss: 201.5578, saving model weights to best_model_weights.pth

-------------------- Epoch 184 --------------------
Train loss: 0.9967
Test loss: 201.56559308369955
Test loss: 207.82039896647134
Validation loss: 201.5656

-------------------- Epoch 185 --------------------
Train loss: 0.9950
Test loss: 201.57491302490234
Test loss: 207.82979329427084
Validation loss: 201.5749

-------------------- Epoch 186 --------------------
Train loss: 1.0005
Test loss: 201.66670290629068
Test loss: 207.92453257242838
Validation loss: 201.6667

-------------------- Epoch 187 --------------------
Train loss: 0.9943
Test loss: 201.5625902811686
Test loss: 207.81650416056314
Validation loss: 201.5626

-------------------- Epoch 188 --------------------
Train loss: 1.0010
Test loss: 201.54594294230142
Test loss: 207.79921277364096
New best validation loss: 201.5459, saving model weights to best_model_weights.pth

-------------------- Epoch 189 --------------------
Train loss: 0.9948
Test loss: 201.54538536071777
Test loss: 207.79830169677734
New best validation loss: 201.5454, saving model weights to best_model_weights.pth

-------------------- Epoch 190 --------------------
Train loss: 0.9965
Test loss: 201.4700387318929
Test loss: 207.71957969665527
New best validation loss: 201.4700, saving model weights to best_model_weights.pth

-------------------- Epoch 191 --------------------
Train loss: 0.9953
Test loss: 201.5267105102539
Test loss: 207.7782039642334
Validation loss: 201.5267

-------------------- Epoch 192 --------------------
Train loss: 0.9962
Test loss: 201.49868138631186
Test loss: 207.74883651733398
Validation loss: 201.4987

-------------------- Epoch 193 --------------------
Train loss: 0.9938
Test loss: 201.43557612101236
Test loss: 207.68275133768717
New best validation loss: 201.4356, saving model weights to best_model_weights.pth

-------------------- Epoch 194 --------------------
Train loss: 0.9978
Test loss: 201.53075790405273
Test loss: 207.78114064534506
Validation loss: 201.5308

-------------------- Epoch 195 --------------------
Train loss: 0.9960
Test loss: 201.40736389160156
Test loss: 207.65267690022787
New best validation loss: 201.4074, saving model weights to best_model_weights.pth

-------------------- Epoch 196 --------------------
Train loss: 0.9950
Test loss: 201.4267946879069
Test loss: 207.67246182759604
Validation loss: 201.4268

-------------------- Epoch 197 --------------------
Train loss: 0.9965
Test loss: 201.48262659708658
Test loss: 207.73021252950033
Validation loss: 201.4826

-------------------- Epoch 198 --------------------
Train loss: 0.9968
Test loss: 201.4856160481771
Test loss: 207.73306465148926
Validation loss: 201.4856

-------------------- Epoch 199 --------------------
Train loss: 0.9971
Test loss: 201.41001892089844
Test loss: 207.654390335083
Validation loss: 201.4100

-------------------- Epoch 200 --------------------
Train loss: 0.9962
Test loss: 201.4043992360433
Test loss: 207.6481736501058
New best validation loss: 201.4044, saving model weights to best_model_weights.pth

-------------------- Epoch 201 --------------------
Train loss: 0.9913
Test loss: 201.40897115071616
Test loss: 207.65239651997885
Validation loss: 201.4090

-------------------- Epoch 202 --------------------
Train loss: 0.9933
Test loss: 201.4828084309896
Test loss: 207.7287254333496
Validation loss: 201.4828

-------------------- Epoch 203 --------------------
Train loss: 0.9943
Test loss: 201.30078887939453
Test loss: 207.5394713083903
New best validation loss: 201.3008, saving model weights to best_model_weights.pth

-------------------- Epoch 204 --------------------
Train loss: 0.9930
Test loss: 201.42159779866537
Test loss: 207.66466077168783
Validation loss: 201.4216

-------------------- Epoch 205 --------------------
Train loss: 0.9954
Test loss: 201.4892667134603
Test loss: 207.7342872619629
Validation loss: 201.4893

-------------------- Epoch 206 --------------------
Train loss: 0.9992
Test loss: 201.3922379811605
Test loss: 207.6336409250895
Validation loss: 201.3922

-------------------- Epoch 207 --------------------
Train loss: 0.9962
Test loss: 201.34099324544272
Test loss: 207.57997830708823
Validation loss: 201.3410

-------------------- Epoch 208 --------------------
Train loss: 0.9942
Test loss: 201.426487604777
Test loss: 207.6684398651123
Validation loss: 201.4265

-------------------- Epoch 209 --------------------
Train loss: 0.9930
Test loss: 201.28825505574545
Test loss: 207.52423032124838
New best validation loss: 201.2883, saving model weights to best_model_weights.pth

-------------------- Epoch 210 --------------------
Train loss: 0.9970
Test loss: 201.39503224690756
Test loss: 207.6350803375244
Validation loss: 201.3950

-------------------- Epoch 211 --------------------
Train loss: 0.9952
Test loss: 201.33074951171875
Test loss: 207.5679791768392
Validation loss: 201.3307

-------------------- Epoch 212 --------------------
Train loss: 0.9917
Test loss: 201.3501059214274
Test loss: 207.58763058980307
Validation loss: 201.3501

-------------------- Epoch 213 --------------------
Train loss: 0.9934
Test loss: 201.35373242696127
Test loss: 207.59096463521323
Validation loss: 201.3537

-------------------- Epoch 214 --------------------
Train loss: 0.9926
Test loss: 201.4094384511312
Test loss: 207.64799118041992
Validation loss: 201.4094

-------------------- Epoch 215 --------------------
Train loss: 0.9932
Test loss: 201.28906122843424
Test loss: 207.52300516764322
Validation loss: 201.2891

-------------------- Epoch 216 --------------------
Train loss: 0.9920
Test loss: 201.28695424397787
Test loss: 207.52033233642578
New best validation loss: 201.2870, saving model weights to best_model_weights.pth

-------------------- Epoch 217 --------------------
Train loss: 0.9954
Test loss: 201.3073476155599
Test loss: 207.54108810424805
Validation loss: 201.3073

-------------------- Epoch 218 --------------------
Train loss: 0.9936
Test loss: 201.2033259073893
Test loss: 207.43285751342773
New best validation loss: 201.2033, saving model weights to best_model_weights.pth

-------------------- Epoch 219 --------------------
Train loss: 0.9935
Test loss: 201.33151308695474
Test loss: 207.5653222401937
Validation loss: 201.3315

-------------------- Epoch 220 --------------------
Train loss: 0.9955
Test loss: 201.30093701680502
Test loss: 207.53315925598145
Validation loss: 201.3009

-------------------- Epoch 221 --------------------
Train loss: 0.9960
Test loss: 201.3495330810547
Test loss: 207.5826587677002
Validation loss: 201.3495

-------------------- Epoch 222 --------------------
Train loss: 0.9932
Test loss: 201.35578409830728
Test loss: 207.58854293823242
Validation loss: 201.3558

-------------------- Epoch 223 --------------------
Train loss: 0.9949
Test loss: 201.37277475992838
Test loss: 207.60561180114746
Validation loss: 201.3728

-------------------- Epoch 224 --------------------
Train loss: 0.9920
Test loss: 201.2287508646647
Test loss: 207.45636049906412
Validation loss: 201.2288

-------------------- Epoch 225 --------------------
Train loss: 0.9929
Test loss: 201.17510668436685
Test loss: 207.40056610107422
New best validation loss: 201.1751, saving model weights to best_model_weights.pth

-------------------- Epoch 226 --------------------
Train loss: 0.9931
Test loss: 201.2734661102295
Test loss: 207.50181325276694
Validation loss: 201.2735

-------------------- Epoch 227 --------------------
Train loss: 0.9915
Test loss: 201.25753593444824
Test loss: 207.48499615987143
Validation loss: 201.2575

-------------------- Epoch 228 --------------------
Train loss: 0.9956
Test loss: 201.27034123738608
Test loss: 207.497776667277
Validation loss: 201.2703

-------------------- Epoch 229 --------------------
Train loss: 0.9981
Test loss: 201.1681785583496
Test loss: 207.39155515034994
New best validation loss: 201.1682, saving model weights to best_model_weights.pth

-------------------- Epoch 230 --------------------
Train loss: 0.9920
Test loss: 201.22296078999838
Test loss: 207.44793574015299
Validation loss: 201.2230

-------------------- Epoch 231 --------------------
Train loss: 0.9934
Test loss: 201.27112515767416
Test loss: 207.4971440633138
Validation loss: 201.2711

-------------------- Epoch 232 --------------------
Train loss: 0.9921
Test loss: 201.30095672607422
Test loss: 207.52719497680664
Validation loss: 201.3010

-------------------- Epoch 233 --------------------
Train loss: 0.9924
Test loss: 201.14070828755698
Test loss: 207.36167271931967
New best validation loss: 201.1407, saving model weights to best_model_weights.pth

-------------------- Epoch 234 --------------------
Train loss: 0.9972
Test loss: 201.1853173573812
Test loss: 207.40733909606934
Validation loss: 201.1853

-------------------- Epoch 235 --------------------
Train loss: 0.9948
Test loss: 201.1744810740153
Test loss: 207.39564323425293
Validation loss: 201.1745

-------------------- Epoch 236 --------------------
Train loss: 0.9917
Test loss: 201.12715212504068
Test loss: 207.34630076090494
New best validation loss: 201.1272, saving model weights to best_model_weights.pth

-------------------- Epoch 237 --------------------
Train loss: 0.9916
Test loss: 201.23730023701987
Test loss: 207.45926666259766
Validation loss: 201.2373

-------------------- Epoch 238 --------------------
Train loss: 0.9929
Test loss: 201.22412808736166
Test loss: 207.4453010559082
Validation loss: 201.2241

-------------------- Epoch 239 --------------------
Train loss: 0.9944
Test loss: 201.07636578877768
Test loss: 207.29265530904135
New best validation loss: 201.0764, saving model weights to best_model_weights.pth

-------------------- Epoch 240 --------------------
Train loss: 0.9911
Test loss: 201.06151262919107
Test loss: 207.27668952941895
New best validation loss: 201.0615, saving model weights to best_model_weights.pth

-------------------- Epoch 241 --------------------
Train loss: 0.9934
Test loss: 201.08726692199707
Test loss: 207.3027858734131
Validation loss: 201.0873

-------------------- Epoch 242 --------------------
Train loss: 0.9911
Test loss: 201.07198270161948
Test loss: 207.28656069437662
Validation loss: 201.0720

-------------------- Epoch 243 --------------------
Train loss: 0.9933
Test loss: 201.1280485788981
Test loss: 207.3437410990397
Validation loss: 201.1280

-------------------- Epoch 244 --------------------
Train loss: 0.9937
Test loss: 201.17661794026694
Test loss: 207.39298375447592
Validation loss: 201.1766

-------------------- Epoch 245 --------------------
Train loss: 0.9964
Test loss: 201.07328669230142
Test loss: 207.28621610005698
Validation loss: 201.0733

-------------------- Epoch 246 --------------------
Train loss: 0.9954
Test loss: 201.14514605204263
Test loss: 207.35962549845377
Validation loss: 201.1451

-------------------- Epoch 247 --------------------
Train loss: 0.9921
Test loss: 201.15325037638345
Test loss: 207.36731147766113
Validation loss: 201.1533

-------------------- Epoch 248 --------------------
Train loss: 0.9919
Test loss: 201.1456782023112
Test loss: 207.3590456644694
Validation loss: 201.1457

-------------------- Epoch 249 --------------------
Train loss: 0.9939
Test loss: 201.07851791381836
Test loss: 207.2896556854248
Validation loss: 201.0785

-------------------- Epoch 250 --------------------
Train loss: 0.9976
Test loss: 201.02876091003418
Test loss: 207.2379347483317
New best validation loss: 201.0288, saving model weights to best_model_weights.pth

-------------------- Epoch 251 --------------------
Train loss: 0.9915
Test loss: 201.04025077819824
Test loss: 207.24925422668457
Validation loss: 201.0403

-------------------- Epoch 252 --------------------
Train loss: 0.9943
Test loss: 201.02642949422201
Test loss: 207.23443476359049
New best validation loss: 201.0264, saving model weights to best_model_weights.pth

-------------------- Epoch 253 --------------------
Train loss: 0.9926
Test loss: 200.9495309193929
Test loss: 207.15495745340982
New best validation loss: 200.9495, saving model weights to best_model_weights.pth

-------------------- Epoch 254 --------------------
Train loss: 0.9895
Test loss: 201.11661529541016
Test loss: 207.3255647023519
Validation loss: 201.1166

-------------------- Epoch 255 --------------------
Train loss: 0.9944
Test loss: 200.95094045003256
Test loss: 207.1552594502767
Validation loss: 200.9509

-------------------- Epoch 256 --------------------
Train loss: 0.9919
Test loss: 201.0848871866862
Test loss: 207.29195276896158
Validation loss: 201.0849

-------------------- Epoch 257 --------------------
Train loss: 0.9921
Test loss: 200.9893627166748
Test loss: 207.1934051513672
Validation loss: 200.9894

-------------------- Epoch 258 --------------------
Train loss: 0.9918
Test loss: 200.96215693155924
Test loss: 207.16486803690592
Validation loss: 200.9622

-------------------- Epoch 259 --------------------
Train loss: 0.9915
Test loss: 200.97497940063477
Test loss: 207.17734018961588
Validation loss: 200.9750

-------------------- Epoch 260 --------------------
Train loss: 0.9906
Test loss: 201.00994809468588
Test loss: 207.21264775594076
Validation loss: 201.0099

-------------------- Epoch 261 --------------------
Train loss: 0.9943
Test loss: 200.93845494588217
Test loss: 207.13848686218262
New best validation loss: 200.9385, saving model weights to best_model_weights.pth

-------------------- Epoch 262 --------------------
Train loss: 0.9984
Test loss: 200.95007451375326
Test loss: 207.1498260498047
Validation loss: 200.9501

-------------------- Epoch 263 --------------------
Train loss: 0.9905
Test loss: 200.9205805460612
Test loss: 207.11883481343588
New best validation loss: 200.9206, saving model weights to best_model_weights.pth

-------------------- Epoch 264 --------------------
Train loss: 0.9901
Test loss: 200.85474904378256
Test loss: 207.05055236816406
New best validation loss: 200.8547, saving model weights to best_model_weights.pth

-------------------- Epoch 265 --------------------
Train loss: 0.9901
Test loss: 200.94661966959634
Test loss: 207.14406458536783
Validation loss: 200.9466

-------------------- Epoch 266 --------------------
Train loss: 0.9902
Test loss: 200.93363825480142
Test loss: 207.130007425944
Validation loss: 200.9336

-------------------- Epoch 267 --------------------
Train loss: 0.9922
Test loss: 200.99933433532715
Test loss: 207.1964988708496
Validation loss: 200.9993

-------------------- Epoch 268 --------------------
Train loss: 0.9901
Test loss: 201.0515874226888
Test loss: 207.24912770589194
Validation loss: 201.0516

-------------------- Epoch 269 --------------------
Train loss: 0.9907
Test loss: 200.96709887186685
Test loss: 207.16207695007324
Validation loss: 200.9671

-------------------- Epoch 270 --------------------
Train loss: 0.9945
Test loss: 200.84778022766113
Test loss: 207.03935114542642
New best validation loss: 200.8478, saving model weights to best_model_weights.pth

-------------------- Epoch 271 --------------------
Train loss: 0.9896
Test loss: 200.79427528381348
Test loss: 206.98378562927246
New best validation loss: 200.7943, saving model weights to best_model_weights.pth

-------------------- Epoch 272 --------------------
Train loss: 0.9902
Test loss: 200.86808967590332
Test loss: 207.05856641133627
Validation loss: 200.8681

-------------------- Epoch 273 --------------------
Train loss: 0.9891
Test loss: 200.917355855306
Test loss: 207.10839080810547
Validation loss: 200.9174

-------------------- Epoch 274 --------------------
Train loss: 0.9929
Test loss: 200.81155649820963
Test loss: 206.999542872111
Validation loss: 200.8116

-------------------- Epoch 275 --------------------
Train loss: 0.9903
Test loss: 200.8073927561442
Test loss: 206.9946994781494
Validation loss: 200.8074

-------------------- Epoch 276 --------------------
Train loss: 0.9882
Test loss: 200.8889274597168
Test loss: 207.07749938964844
Validation loss: 200.8889

-------------------- Epoch 277 --------------------
Train loss: 0.9979
Test loss: 200.8216438293457
Test loss: 207.00807317097983
Validation loss: 200.8216

-------------------- Epoch 278 --------------------
Train loss: 0.9901
Test loss: 200.87805938720703
Test loss: 207.06530825297037
Validation loss: 200.8781

-------------------- Epoch 279 --------------------
Train loss: 0.9904
Test loss: 200.80977249145508
Test loss: 206.99477195739746
Validation loss: 200.8098

-------------------- Epoch 280 --------------------
Train loss: 0.9895
Test loss: 200.76251475016275
Test loss: 206.94582557678223
New best validation loss: 200.7625, saving model weights to best_model_weights.pth

-------------------- Epoch 281 --------------------
Train loss: 0.9884
Test loss: 200.83598454793295
Test loss: 207.02062225341797
Validation loss: 200.8360

-------------------- Epoch 282 --------------------
Train loss: 0.9948
Test loss: 200.73721885681152
Test loss: 206.91891034444174
New best validation loss: 200.7372, saving model weights to best_model_weights.pth

-------------------- Epoch 283 --------------------
Train loss: 0.9888
Test loss: 200.76016108194986
Test loss: 206.9418512980143
Validation loss: 200.7602

-------------------- Epoch 284 --------------------
Train loss: 0.9903
Test loss: 200.76616032918295
Test loss: 206.94750912984213
Validation loss: 200.7662

-------------------- Epoch 285 --------------------
Train loss: 0.9879
Test loss: 200.66501553853354
Test loss: 206.8433074951172
New best validation loss: 200.6650, saving model weights to best_model_weights.pth

-------------------- Epoch 286 --------------------
Train loss: 0.9900
Test loss: 200.71191787719727
Test loss: 206.8907553354899
Validation loss: 200.7119

-------------------- Epoch 287 --------------------
Train loss: 0.9867
Test loss: 200.78802935282388
Test loss: 206.968168258667
Validation loss: 200.7880

-------------------- Epoch 288 --------------------
Train loss: 0.9891
Test loss: 200.65638987223306
Test loss: 206.83270454406738
New best validation loss: 200.6564, saving model weights to best_model_weights.pth

-------------------- Epoch 289 --------------------
Train loss: 0.9881
Test loss: 200.6732260386149
Test loss: 206.8493626912435
Validation loss: 200.6732

-------------------- Epoch 290 --------------------
Train loss: 0.9884
Test loss: 200.64167594909668
Test loss: 206.81644757588705
New best validation loss: 200.6417, saving model weights to best_model_weights.pth

-------------------- Epoch 291 --------------------
Train loss: 0.9882
Test loss: 200.74470710754395
Test loss: 206.92145856221518
Validation loss: 200.7447

-------------------- Epoch 292 --------------------
Train loss: 0.9893
Test loss: 200.6188284556071
Test loss: 206.79188664754233
New best validation loss: 200.6188, saving model weights to best_model_weights.pth

-------------------- Epoch 293 --------------------
Train loss: 0.9866
Test loss: 200.6630827585856
Test loss: 206.83660252888998
Validation loss: 200.6631

-------------------- Epoch 294 --------------------
Train loss: 0.9923
Test loss: 200.67706743876138
Test loss: 206.85040918986002
Validation loss: 200.6771

-------------------- Epoch 295 --------------------
Train loss: 0.9889
Test loss: 200.8035545349121
Test loss: 206.97907829284668
Validation loss: 200.8036

-------------------- Epoch 296 --------------------
Train loss: 0.9887
Test loss: 200.65150515238443
Test loss: 206.8229465484619
Validation loss: 200.6515

-------------------- Epoch 297 --------------------
Train loss: 0.9891
Test loss: 200.59229278564453
Test loss: 206.76166025797525
New best validation loss: 200.5923, saving model weights to best_model_weights.pth

-------------------- Epoch 298 --------------------
Train loss: 0.9885
Test loss: 200.60653114318848
Test loss: 206.77556292215982
Validation loss: 200.6065

-------------------- Epoch 299 --------------------
Train loss: 0.9867
Test loss: 200.65580940246582
Test loss: 206.82527287801108
Validation loss: 200.6558

-------------------- Epoch 300 --------------------
Train loss: 0.9879
Test loss: 200.58476638793945
Test loss: 206.75188891092935
New best validation loss: 200.5848, saving model weights to best_model_weights.pth

-------------------- Epoch 301 --------------------
Train loss: 0.9910
Test loss: 200.60146204630533
Test loss: 206.76832008361816
Validation loss: 200.6015

-------------------- Epoch 302 --------------------
Train loss: 0.9880
Test loss: 200.64871788024902
Test loss: 206.8160572052002
Validation loss: 200.6487

-------------------- Epoch 303 --------------------
Train loss: 0.9883
Test loss: 200.74389457702637
Test loss: 206.91266695658365
Validation loss: 200.7439

-------------------- Epoch 304 --------------------
Train loss: 0.9882
Test loss: 200.65457089742026
Test loss: 206.82065773010254
Validation loss: 200.6546

-------------------- Epoch 305 --------------------
Train loss: 0.9906
Test loss: 200.61284828186035
Test loss: 206.7772216796875
Validation loss: 200.6128

-------------------- Epoch 306 --------------------
Train loss: 0.9931
Test loss: 200.58624839782715
Test loss: 206.74934514363608
Validation loss: 200.5862

-------------------- Epoch 307 --------------------
Train loss: 0.9907
Test loss: 200.6775220235189
Test loss: 206.84205945332846
Validation loss: 200.6775

-------------------- Epoch 308 --------------------
Train loss: 0.9892
Test loss: 200.52029927571616
Test loss: 206.68050384521484
New best validation loss: 200.5203, saving model weights to best_model_weights.pth

-------------------- Epoch 309 --------------------
Train loss: 0.9879
Test loss: 200.56075032552084
Test loss: 206.72122637430826
Validation loss: 200.5608

-------------------- Epoch 310 --------------------
Train loss: 0.9886
Test loss: 200.5707982381185
Test loss: 206.73090235392252
Validation loss: 200.5708

-------------------- Epoch 311 --------------------
Train loss: 0.9863
Test loss: 200.45699055989584
Test loss: 206.61375363667807
New best validation loss: 200.4570, saving model weights to best_model_weights.pth

-------------------- Epoch 312 --------------------
Train loss: 0.9871
Test loss: 200.53826395670572
Test loss: 206.69623311360678
Validation loss: 200.5383

-------------------- Epoch 313 --------------------
Train loss: 0.9894
Test loss: 200.5368684132894
Test loss: 206.69403902689615
Validation loss: 200.5369

-------------------- Epoch 314 --------------------
Train loss: 0.9930
Test loss: 200.53876050313315
Test loss: 206.69530804951987
Validation loss: 200.5388

-------------------- Epoch 315 --------------------
Train loss: 0.9874
Test loss: 200.54500516255698
Test loss: 206.70096397399902
Validation loss: 200.5450

-------------------- Epoch 316 --------------------
Train loss: 0.9873
Test loss: 200.3608767191569
Test loss: 206.51201820373535
New best validation loss: 200.3609, saving model weights to best_model_weights.pth

-------------------- Epoch 317 --------------------
Train loss: 0.9849
Test loss: 200.3669115702311
Test loss: 206.5174331665039
Validation loss: 200.3669

-------------------- Epoch 318 --------------------
Train loss: 0.9883
Test loss: 200.4282137552897
Test loss: 206.5793342590332
Validation loss: 200.4282

-------------------- Epoch 319 --------------------
Train loss: 0.9907
Test loss: 200.4940725962321
Test loss: 206.64604886372885
Validation loss: 200.4941

-------------------- Epoch 320 --------------------
Train loss: 0.9846
Test loss: 200.39991505940756
Test loss: 206.5489241282145
Validation loss: 200.3999

-------------------- Epoch 321 --------------------
Train loss: 0.9847
Test loss: 200.4639581044515
Test loss: 206.61367479960123
Validation loss: 200.4640

-------------------- Epoch 322 --------------------
Train loss: 0.9872
Test loss: 200.38851483662924
Test loss: 206.53582191467285
Validation loss: 200.3885

-------------------- Epoch 323 --------------------
Train loss: 0.9851
Test loss: 200.3579444885254
Test loss: 206.5037924448649
New best validation loss: 200.3579, saving model weights to best_model_weights.pth

-------------------- Epoch 324 --------------------
Train loss: 0.9873
Test loss: 200.3358414967855
Test loss: 206.48048210144043
New best validation loss: 200.3358, saving model weights to best_model_weights.pth

-------------------- Epoch 325 --------------------
Train loss: 0.9860
Test loss: 200.32386334737143
Test loss: 206.46755981445312
New best validation loss: 200.3239, saving model weights to best_model_weights.pth

-------------------- Epoch 326 --------------------
Train loss: 0.9920
Test loss: 200.35256703694662
Test loss: 206.4961986541748
Validation loss: 200.3526

-------------------- Epoch 327 --------------------
Train loss: 0.9897
Test loss: 200.40381304423013
Test loss: 206.5478630065918
Validation loss: 200.4038

-------------------- Epoch 328 --------------------
Train loss: 0.9865
Test loss: 200.27720006306967
Test loss: 206.41768264770508
New best validation loss: 200.2772, saving model weights to best_model_weights.pth

-------------------- Epoch 329 --------------------
Train loss: 0.9853
Test loss: 200.29096285502115
Test loss: 206.43092473347983
Validation loss: 200.2910

-------------------- Epoch 330 --------------------
Train loss: 0.9847
Test loss: 200.33276176452637
Test loss: 206.47294553120932
Validation loss: 200.3328

-------------------- Epoch 331 --------------------
Train loss: 0.9867
Test loss: 200.2895825703939
Test loss: 206.42803319295248
Validation loss: 200.2896

-------------------- Epoch 332 --------------------
Train loss: 0.9859
Test loss: 200.31000645955405
Test loss: 206.44824155171713
Validation loss: 200.3100

-------------------- Epoch 333 --------------------
Train loss: 0.9875
Test loss: 200.19563738505045
Test loss: 206.33073234558105
New best validation loss: 200.1956, saving model weights to best_model_weights.pth

-------------------- Epoch 334 --------------------
Train loss: 0.9878
Test loss: 200.23982429504395
Test loss: 206.37500190734863
Validation loss: 200.2398

-------------------- Epoch 335 --------------------
Train loss: 0.9859
Test loss: 200.26391983032227
Test loss: 206.39890480041504
Validation loss: 200.2639

-------------------- Epoch 336 --------------------
Train loss: 0.9887
Test loss: 200.26716105143228
Test loss: 206.40124638875326
Validation loss: 200.2672

-------------------- Epoch 337 --------------------
Train loss: 0.9862
Test loss: 200.27861467997232
Test loss: 206.41229184468588
Validation loss: 200.2786

-------------------- Epoch 338 --------------------
Train loss: 0.9882
Test loss: 200.28283754984537
Test loss: 206.41597048441568
Validation loss: 200.2828

-------------------- Epoch 339 --------------------
Train loss: 0.9859
Test loss: 200.21317863464355
Test loss: 206.3439261118571
Validation loss: 200.2132

-------------------- Epoch 340 --------------------
Train loss: 0.9862
Test loss: 200.1967887878418
Test loss: 206.32641537984213
Validation loss: 200.1968

-------------------- Epoch 341 --------------------
Train loss: 0.9860
Test loss: 200.22948137919107
Test loss: 206.3590513865153
Validation loss: 200.2295

-------------------- Epoch 342 --------------------
Train loss: 0.9876
Test loss: 200.18054389953613
Test loss: 206.3083553314209
New best validation loss: 200.1805, saving model weights to best_model_weights.pth

-------------------- Epoch 343 --------------------
Train loss: 0.9877
Test loss: 200.06908162434897
Test loss: 206.19397735595703
New best validation loss: 200.0691, saving model weights to best_model_weights.pth

-------------------- Epoch 344 --------------------
Train loss: 0.9850
Test loss: 200.26567459106445
Test loss: 206.39384651184082
Validation loss: 200.2657

-------------------- Epoch 345 --------------------
Train loss: 0.9849
Test loss: 200.14978472391763
Test loss: 206.27469889322916
Validation loss: 200.1498

-------------------- Epoch 346 --------------------
Train loss: 0.9868
Test loss: 200.13049952189127
Test loss: 206.25417264302573
Validation loss: 200.1305

-------------------- Epoch 347 --------------------
Train loss: 0.9852
Test loss: 200.33046595255533
Test loss: 206.4580332438151
Validation loss: 200.3305

-------------------- Epoch 348 --------------------
Train loss: 0.9868
Test loss: 200.1343994140625
Test loss: 206.2566089630127
Validation loss: 200.1344

-------------------- Epoch 349 --------------------
Train loss: 0.9834
Test loss: 200.08295122782388
Test loss: 206.2033659617106
Validation loss: 200.0830

-------------------- Epoch 350 --------------------
Train loss: 0.9850
Test loss: 200.1510149637858
Test loss: 206.27191225687662
Validation loss: 200.1510

-------------------- Epoch 351 --------------------
Train loss: 0.9877
Test loss: 200.0655085245768
Test loss: 206.18398094177246
New best validation loss: 200.0655, saving model weights to best_model_weights.pth

-------------------- Epoch 352 --------------------
Train loss: 0.9867
Test loss: 200.10397338867188
Test loss: 206.2224006652832
Validation loss: 200.1040

-------------------- Epoch 353 --------------------
Train loss: 0.9835
Test loss: 200.02467091878256
Test loss: 206.1406675974528
New best validation loss: 200.0247, saving model weights to best_model_weights.pth

-------------------- Epoch 354 --------------------
Train loss: 0.9855
Test loss: 200.03477223714194
Test loss: 206.15014012654623
Validation loss: 200.0348

-------------------- Epoch 355 --------------------
Train loss: 0.9839
Test loss: 200.09390513102213
Test loss: 206.20970598856607
Validation loss: 200.0939

-------------------- Epoch 356 --------------------
Train loss: 0.9843
Test loss: 200.05140940348306
Test loss: 206.1656176249186
Validation loss: 200.0514

-------------------- Epoch 357 --------------------
Train loss: 0.9883
Test loss: 200.08002344767252
Test loss: 206.1939951578776
Validation loss: 200.0800

-------------------- Epoch 358 --------------------
Train loss: 0.9861
Test loss: 200.15293629964194
Test loss: 206.26764488220215
Validation loss: 200.1529

-------------------- Epoch 359 --------------------
Train loss: 0.9850
Test loss: 200.12768363952637
Test loss: 206.24120012919107
Validation loss: 200.1277

-------------------- Epoch 360 --------------------
Train loss: 0.9849
Test loss: 199.8565216064453
Test loss: 205.96411641438803
New best validation loss: 199.8565, saving model weights to best_model_weights.pth

-------------------- Epoch 361 --------------------
Train loss: 0.9875
Test loss: 200.02521387736002
Test loss: 206.1351432800293
Validation loss: 200.0252

-------------------- Epoch 362 --------------------
Train loss: 0.9837
Test loss: 199.9959716796875
Test loss: 206.10453097025552
Validation loss: 199.9960

-------------------- Epoch 363 --------------------
Train loss: 0.9855
Test loss: 199.99700101216635
Test loss: 206.1047452290853
Validation loss: 199.9970

-------------------- Epoch 364 --------------------
Train loss: 0.9839
Test loss: 200.08569145202637
Test loss: 206.1944923400879
Validation loss: 200.0857

-------------------- Epoch 365 --------------------
Train loss: 0.9896
Test loss: 199.88275655110678
Test loss: 205.98665237426758
Validation loss: 199.8828

-------------------- Epoch 366 --------------------
Train loss: 0.9838
Test loss: 199.98515256245932
Test loss: 206.09031359354654
Validation loss: 199.9852

-------------------- Epoch 367 --------------------
Train loss: 0.9854
Test loss: 199.92062759399414
Test loss: 206.02373441060385
Validation loss: 199.9206

-------------------- Epoch 368 --------------------
Train loss: 0.9830
Test loss: 199.96572621663412
Test loss: 206.06895192464194
Validation loss: 199.9657

-------------------- Epoch 369 --------------------
Train loss: 0.9825
Test loss: 199.9340731302897
Test loss: 206.03591601053873
Validation loss: 199.9341

-------------------- Epoch 370 --------------------
Train loss: 0.9860
Test loss: 199.88960138956705
Test loss: 205.9897829691569
Validation loss: 199.8896

-------------------- Epoch 371 --------------------
Train loss: 0.9866
Test loss: 200.02358754475912
Test loss: 206.12568791707358
Validation loss: 200.0236

-------------------- Epoch 372 --------------------
Train loss: 0.9814
Test loss: 199.92417017618814
Test loss: 206.0236028035482
Validation loss: 199.9242

-------------------- Epoch 373 --------------------
Train loss: 0.9811
Test loss: 199.92256291707358
Test loss: 206.0211722056071
Validation loss: 199.9226

-------------------- Epoch 374 --------------------
Train loss: 0.9836
Test loss: 199.98238372802734
Test loss: 206.0812791188558
Validation loss: 199.9824

-------------------- Epoch 375 --------------------
Train loss: 0.9811
Test loss: 199.84276898701987
Test loss: 205.93823305765787
New best validation loss: 199.8428, saving model weights to best_model_weights.pth

-------------------- Epoch 376 --------------------
Train loss: 0.9847
Test loss: 199.912722269694
Test loss: 206.00870259602866
Validation loss: 199.9127

-------------------- Epoch 377 --------------------
Train loss: 0.9838
Test loss: 199.8254909515381
Test loss: 205.91908645629883
New best validation loss: 199.8255, saving model weights to best_model_weights.pth

-------------------- Epoch 378 --------------------
Train loss: 0.9869
Test loss: 199.81159083048502
Test loss: 205.9041322072347
New best validation loss: 199.8116, saving model weights to best_model_weights.pth

-------------------- Epoch 379 --------------------
Train loss: 0.9858
Test loss: 199.9611358642578
Test loss: 206.0558376312256
Validation loss: 199.9611

-------------------- Epoch 380 --------------------
Train loss: 0.9802
Test loss: 199.68741607666016
Test loss: 205.77613639831543
New best validation loss: 199.6874, saving model weights to best_model_weights.pth

-------------------- Epoch 381 --------------------
Train loss: 0.9820
Test loss: 199.85521125793457
Test loss: 205.9462547302246
Validation loss: 199.8552

-------------------- Epoch 382 --------------------
Train loss: 0.9845
Test loss: 199.97863006591797
Test loss: 206.07181040445963
Validation loss: 199.9786

-------------------- Epoch 383 --------------------
Train loss: 0.9838
Test loss: 199.89918518066406
Test loss: 205.98951848347983
Validation loss: 199.8992

-------------------- Epoch 384 --------------------
Train loss: 0.9814
Test loss: 199.80336125691733
Test loss: 205.8910026550293
Validation loss: 199.8034

-------------------- Epoch 385 --------------------
Train loss: 0.9819
Test loss: 199.8110866546631
Test loss: 205.89810498555502
Validation loss: 199.8111

-------------------- Epoch 386 --------------------
Train loss: 0.9827
Test loss: 199.76043128967285
Test loss: 205.84578323364258
Validation loss: 199.7604

-------------------- Epoch 387 --------------------
Train loss: 0.9838
Test loss: 199.8307819366455
Test loss: 205.91663233439127
Validation loss: 199.8308

-------------------- Epoch 388 --------------------
Train loss: 0.9844
Test loss: 199.71031125386557
Test loss: 205.79308700561523
Validation loss: 199.7103

-------------------- Epoch 389 --------------------
Train loss: 0.9850
Test loss: 199.87154261271158
Test loss: 205.9567082722982
Validation loss: 199.8715

-------------------- Epoch 390 --------------------
Train loss: 0.9824
Test loss: 199.777130762736
Test loss: 205.85958544413248
Validation loss: 199.7771

-------------------- Epoch 391 --------------------
Train loss: 0.9832
Test loss: 199.7812271118164
Test loss: 205.86302757263184
Validation loss: 199.7812

-------------------- Epoch 392 --------------------
Train loss: 0.9810
Test loss: 199.72237078348795
Test loss: 205.802277247111
Validation loss: 199.7224

-------------------- Epoch 393 --------------------
Train loss: 0.9826
Test loss: 199.6476567586263
Test loss: 205.72540283203125
New best validation loss: 199.6477, saving model weights to best_model_weights.pth

-------------------- Epoch 394 --------------------
Train loss: 0.9836
Test loss: 199.73090744018555
Test loss: 205.80950419108072
Validation loss: 199.7309

-------------------- Epoch 395 --------------------
Train loss: 0.9836
Test loss: 199.72744941711426
Test loss: 205.80519231160483
Validation loss: 199.7274

-------------------- Epoch 396 --------------------
Train loss: 0.9815
Test loss: 199.7662156422933
Test loss: 205.8438294728597
Validation loss: 199.7662

-------------------- Epoch 397 --------------------
Train loss: 0.9836
Test loss: 199.75282669067383
Test loss: 205.82943153381348
Validation loss: 199.7528

-------------------- Epoch 398 --------------------
Train loss: 0.9822
Test loss: 199.62077395121256
Test loss: 205.69423294067383
New best validation loss: 199.6208, saving model weights to best_model_weights.pth

-------------------- Epoch 399 --------------------
Train loss: 0.9878
Test loss: 199.78540484110513
Test loss: 205.86118825276694
Validation loss: 199.7854

-------------------- Epoch 400 --------------------
Train loss: 0.9793
Test loss: 199.64454778035483
Test loss: 205.71686935424805
Validation loss: 199.6445

-------------------- Epoch 401 --------------------
Train loss: 0.9821
Test loss: 199.6083838144938
Test loss: 205.67920049031576
New best validation loss: 199.6084, saving model weights to best_model_weights.pth

-------------------- Epoch 402 --------------------
Train loss: 0.9789
Test loss: 199.62574005126953
Test loss: 205.6962490081787
Validation loss: 199.6257

-------------------- Epoch 403 --------------------
Train loss: 0.9833
Test loss: 199.65257263183594
Test loss: 205.72274335225424
Validation loss: 199.6526

-------------------- Epoch 404 --------------------
Train loss: 0.9816
Test loss: 199.70383389790854
Test loss: 205.7742131551107
Validation loss: 199.7038

-------------------- Epoch 405 --------------------
Train loss: 0.9804
Test loss: 199.61601320902506
Test loss: 205.68398729960123
Validation loss: 199.6160

-------------------- Epoch 406 --------------------
Train loss: 0.9792
Test loss: 199.59334818522134
Test loss: 205.66018358866373
New best validation loss: 199.5933, saving model weights to best_model_weights.pth

-------------------- Epoch 407 --------------------
Train loss: 0.9813
Test loss: 199.6006228129069
Test loss: 205.66686058044434
Validation loss: 199.6006

-------------------- Epoch 408 --------------------
Train loss: 0.9794
Test loss: 199.60078303019205
Test loss: 205.6662451426188
Validation loss: 199.6008

-------------------- Epoch 409 --------------------
Train loss: 0.9826
Test loss: 199.67957560221353
Test loss: 205.74577140808105
Validation loss: 199.6796

-------------------- Epoch 410 --------------------
Train loss: 0.9810
Test loss: 199.47178586324057
Test loss: 205.53342628479004
New best validation loss: 199.4718, saving model weights to best_model_weights.pth

-------------------- Epoch 411 --------------------
Train loss: 0.9812
Test loss: 199.52439181009927
Test loss: 205.58628590901694
Validation loss: 199.5244

-------------------- Epoch 412 --------------------
Train loss: 0.9827
Test loss: 199.55787785847983
Test loss: 205.619597752889
Validation loss: 199.5579

-------------------- Epoch 413 --------------------
Train loss: 0.9821
Test loss: 199.51402727762857
Test loss: 205.57428487141928
Validation loss: 199.5140

-------------------- Epoch 414 --------------------
Train loss: 0.9828
Test loss: 199.5237890879313
Test loss: 205.58333778381348
Validation loss: 199.5238

-------------------- Epoch 415 --------------------
Train loss: 0.9824
Test loss: 199.53204854329428
Test loss: 205.59098752339682
Validation loss: 199.5320

-------------------- Epoch 416 --------------------
Train loss: 0.9844
Test loss: 199.51933352152506
Test loss: 205.5773550669352
Validation loss: 199.5193

-------------------- Epoch 417 --------------------
Train loss: 0.9837
Test loss: 199.50166956583658
Test loss: 205.55852381388345
Validation loss: 199.5017

-------------------- Epoch 418 --------------------
Train loss: 0.9799
Test loss: 199.57563718159994
Test loss: 205.63308143615723
Validation loss: 199.5756

-------------------- Epoch 419 --------------------
Train loss: 0.9797
Test loss: 199.5536206563314
Test loss: 205.60991223653158
Validation loss: 199.5536

-------------------- Epoch 420 --------------------
Train loss: 0.9785
Test loss: 199.54620869954428
Test loss: 205.60165087381998
Validation loss: 199.5462

-------------------- Epoch 421 --------------------
Train loss: 0.9846
Test loss: 199.46098518371582
Test loss: 205.5143076578776
New best validation loss: 199.4610, saving model weights to best_model_weights.pth

-------------------- Epoch 422 --------------------
Train loss: 0.9847
Test loss: 199.4531764984131
Test loss: 205.50559298197427
New best validation loss: 199.4532, saving model weights to best_model_weights.pth

-------------------- Epoch 423 --------------------
Train loss: 0.9816
Test loss: 199.4629332224528
Test loss: 205.51479721069336
Validation loss: 199.4629

-------------------- Epoch 424 --------------------
Train loss: 0.9813
Test loss: 199.3966884613037
Test loss: 205.4467945098877
New best validation loss: 199.3967, saving model weights to best_model_weights.pth

-------------------- Epoch 425 --------------------
Train loss: 0.9815
Test loss: 199.42193094889322
Test loss: 205.47168604532877
Validation loss: 199.4219

-------------------- Epoch 426 --------------------
Train loss: 0.9811
Test loss: 199.45886675516763
Test loss: 205.50843556722006
Validation loss: 199.4589

-------------------- Epoch 427 --------------------
Train loss: 0.9818
Test loss: 199.45557276407877
Test loss: 205.50436147054037
Validation loss: 199.4556

-------------------- Epoch 428 --------------------
Train loss: 0.9852
Test loss: 199.46685473124185
Test loss: 205.515162785848
Validation loss: 199.4669

-------------------- Epoch 429 --------------------
Train loss: 0.9826
Test loss: 199.38442993164062
Test loss: 205.4308064778646
New best validation loss: 199.3844, saving model weights to best_model_weights.pth

-------------------- Epoch 430 --------------------
Train loss: 0.9803
Test loss: 199.49398549397787
Test loss: 205.54140281677246
Validation loss: 199.4940

-------------------- Epoch 431 --------------------
Train loss: 0.9805
Test loss: 199.36914443969727
Test loss: 205.41376940409342
New best validation loss: 199.3691, saving model weights to best_model_weights.pth

-------------------- Epoch 432 --------------------
Train loss: 0.9809
Test loss: 199.49611218770346
Test loss: 205.542085647583
Validation loss: 199.4961

-------------------- Epoch 433 --------------------
Train loss: 0.9771
Test loss: 199.27681032816568
Test loss: 205.3183110555013
New best validation loss: 199.2768, saving model weights to best_model_weights.pth

-------------------- Epoch 434 --------------------
Train loss: 0.9815
Test loss: 199.31051381429037
Test loss: 205.35191853841147
Validation loss: 199.3105

-------------------- Epoch 435 --------------------
Train loss: 0.9825
Test loss: 199.2691968282064
Test loss: 205.30920473734537
New best validation loss: 199.2692, saving model weights to best_model_weights.pth

-------------------- Epoch 436 --------------------
Train loss: 0.9825
Test loss: 199.35884602864584
Test loss: 205.39955774943033
Validation loss: 199.3588

-------------------- Epoch 437 --------------------
Train loss: 0.9796
Test loss: 199.39207712809244
Test loss: 205.43272717793783
Validation loss: 199.3921

-------------------- Epoch 438 --------------------
Train loss: 0.9791
Test loss: 199.3076140085856
Test loss: 205.3461538950602
Validation loss: 199.3076

-------------------- Epoch 439 --------------------
Train loss: 0.9803
Test loss: 199.32376543680826
Test loss: 205.36188952128092
Validation loss: 199.3238

-------------------- Epoch 440 --------------------
Train loss: 0.9809
Test loss: 199.32944107055664
Test loss: 205.36688995361328
Validation loss: 199.3294

-------------------- Epoch 441 --------------------
Train loss: 0.9815
Test loss: 199.3398551940918
Test loss: 205.376740137736
Validation loss: 199.3399

-------------------- Epoch 442 --------------------
Train loss: 0.9801
Test loss: 199.33727391560873
Test loss: 205.3735434214274
Validation loss: 199.3373

-------------------- Epoch 443 --------------------
Train loss: 0.9847
Test loss: 199.37653350830078
Test loss: 205.41266377766928
Validation loss: 199.3765

-------------------- Epoch 444 --------------------
Train loss: 0.9814
Test loss: 199.33349100748697
Test loss: 205.36818313598633
Validation loss: 199.3335

-------------------- Epoch 445 --------------------
Train loss: 0.9852
Test loss: 199.27045313517252
Test loss: 205.3034413655599
Validation loss: 199.2705

-------------------- Epoch 446 --------------------
Train loss: 0.9837
Test loss: 199.36568450927734
Test loss: 205.39963467915854
Validation loss: 199.3657

-------------------- Epoch 447 --------------------
Train loss: 0.9787
Test loss: 199.30453491210938
Test loss: 205.3366584777832
Validation loss: 199.3045

-------------------- Epoch 448 --------------------
Train loss: 0.9799
Test loss: 199.1689535776774
Test loss: 205.19810422261557
New best validation loss: 199.1690, saving model weights to best_model_weights.pth

-------------------- Epoch 449 --------------------
Train loss: 0.9766
Test loss: 199.25367482503256
Test loss: 205.2835807800293
Validation loss: 199.2537

-------------------- Epoch 450 --------------------
Train loss: 0.9793
Test loss: 199.20942497253418
Test loss: 205.23799260457358
Validation loss: 199.2094

-------------------- Epoch 451 --------------------
Train loss: 0.9826
Test loss: 199.13987096150717
Test loss: 205.16654841105142
New best validation loss: 199.1399, saving model weights to best_model_weights.pth

-------------------- Epoch 452 --------------------
Train loss: 0.9797
Test loss: 199.1302719116211
Test loss: 205.15605354309082
New best validation loss: 199.1303, saving model weights to best_model_weights.pth

-------------------- Epoch 453 --------------------
Train loss: 0.9817
Test loss: 199.1387710571289
Test loss: 205.163942972819
Validation loss: 199.1388

-------------------- Epoch 454 --------------------
Train loss: 0.9780
Test loss: 199.2465445200602
Test loss: 205.2728182474772
Validation loss: 199.2465

-------------------- Epoch 455 --------------------
Train loss: 0.9793
Test loss: 199.19214312235513
Test loss: 205.2168935139974
Validation loss: 199.1921

-------------------- Epoch 456 --------------------
Train loss: 0.9813
Test loss: 199.25592104593912
Test loss: 205.28098424275717
Validation loss: 199.2559

-------------------- Epoch 457 --------------------
Train loss: 0.9794
Test loss: 199.2715892791748
Test loss: 205.29633649190268
Validation loss: 199.2716

-------------------- Epoch 458 --------------------
Train loss: 0.9796
Test loss: 199.25699615478516
Test loss: 205.28079795837402
Validation loss: 199.2570

-------------------- Epoch 459 --------------------
Train loss: 0.9778
Test loss: 199.17826398213705
Test loss: 205.20008405049643
Validation loss: 199.1783

-------------------- Epoch 460 --------------------
Train loss: 0.9757
Test loss: 199.17697207132974
Test loss: 205.19809595743814
Validation loss: 199.1770

-------------------- Epoch 461 --------------------
Train loss: 0.9796
Test loss: 199.194948832194
Test loss: 205.21559778849283
Validation loss: 199.1949

-------------------- Epoch 462 --------------------
Train loss: 0.9807
Test loss: 199.12080065409342
Test loss: 205.13962427775064
New best validation loss: 199.1208, saving model weights to best_model_weights.pth

-------------------- Epoch 463 --------------------
Train loss: 0.9832
Test loss: 199.18958536783853
Test loss: 205.20888392130533
Validation loss: 199.1896

-------------------- Epoch 464 --------------------
Train loss: 0.9851
Test loss: 199.14436149597168
Test loss: 205.16224416097006
Validation loss: 199.1444

-------------------- Epoch 465 --------------------
Train loss: 0.9773
Test loss: 199.13904762268066
Test loss: 205.1562296549479
Validation loss: 199.1390

-------------------- Epoch 466 --------------------
Train loss: 0.9789
Test loss: 199.13251495361328
Test loss: 205.1489461263021
Validation loss: 199.1325

-------------------- Epoch 467 --------------------
Train loss: 0.9766
Test loss: 199.2002271016439
Test loss: 205.2171427408854
Validation loss: 199.2002

-------------------- Epoch 468 --------------------
Train loss: 0.9774
Test loss: 199.07594617207846
Test loss: 205.09016227722168
New best validation loss: 199.0759, saving model weights to best_model_weights.pth

-------------------- Epoch 469 --------------------
Train loss: 0.9789
Test loss: 199.0383358001709
Test loss: 205.05122057596842
New best validation loss: 199.0383, saving model weights to best_model_weights.pth

-------------------- Epoch 470 --------------------
Train loss: 0.9792
Test loss: 199.10428174336752
Test loss: 205.1176382700602
Validation loss: 199.1043

-------------------- Epoch 471 --------------------
Train loss: 0.9764
Test loss: 199.14112281799316
Test loss: 205.15439732869467
Validation loss: 199.1411

-------------------- Epoch 472 --------------------
Train loss: 0.9772
Test loss: 199.07283147176108
Test loss: 205.0844268798828
Validation loss: 199.0728

-------------------- Epoch 473 --------------------
Train loss: 0.9782
Test loss: 199.1137015024821
Test loss: 205.12523969014487
Validation loss: 199.1137

-------------------- Epoch 474 --------------------
Train loss: 0.9786
Test loss: 199.0927530924479
Test loss: 205.1032911936442
Validation loss: 199.0928

-------------------- Epoch 475 --------------------
Train loss: 0.9819
Test loss: 199.06499799092612
Test loss: 205.07450803120932
Validation loss: 199.0650

-------------------- Epoch 476 --------------------
Train loss: 0.9784
Test loss: 199.035187403361
Test loss: 205.04368782043457
New best validation loss: 199.0352, saving model weights to best_model_weights.pth

-------------------- Epoch 477 --------------------
Train loss: 0.9799
Test loss: 199.09217071533203
Test loss: 205.10085487365723
Validation loss: 199.0922

-------------------- Epoch 478 --------------------
Train loss: 0.9788
Test loss: 199.12025833129883
Test loss: 205.12883186340332
Validation loss: 199.1203

-------------------- Epoch 479 --------------------
Train loss: 0.9789
Test loss: 199.0185890197754
Test loss: 205.02493222554526
New best validation loss: 199.0186, saving model weights to best_model_weights.pth

-------------------- Epoch 480 --------------------
Train loss: 0.9775
Test loss: 199.12049674987793
Test loss: 205.12779235839844
Validation loss: 199.1205

-------------------- Epoch 481 --------------------
Train loss: 0.9765
Test loss: 199.11656188964844
Test loss: 205.12323252360025
Validation loss: 199.1166

-------------------- Epoch 482 --------------------
Train loss: 0.9760
Test loss: 199.0227076212565
Test loss: 205.027130762736
Validation loss: 199.0227

-------------------- Epoch 483 --------------------
Train loss: 0.9783
Test loss: 198.98887379964194
Test loss: 204.99225616455078
New best validation loss: 198.9889, saving model weights to best_model_weights.pth

-------------------- Epoch 484 --------------------
Train loss: 0.9777
Test loss: 199.02794965108237
Test loss: 205.03132565816244
Validation loss: 199.0279

-------------------- Epoch 485 --------------------
Train loss: 0.9789
Test loss: 198.9218209584554
Test loss: 204.92302703857422
New best validation loss: 198.9218, saving model weights to best_model_weights.pth

-------------------- Epoch 486 --------------------
Train loss: 0.9799
Test loss: 199.0119825998942
Test loss: 205.01387786865234
Validation loss: 199.0120

-------------------- Epoch 487 --------------------
Train loss: 0.9756
Test loss: 199.00490697224936
Test loss: 205.0061092376709
Validation loss: 199.0049

-------------------- Epoch 488 --------------------
Train loss: 0.9759
Test loss: 199.0260149637858
Test loss: 205.026980082194
Validation loss: 199.0260

-------------------- Epoch 489 --------------------
Train loss: 0.9785
Test loss: 199.03596051534018
Test loss: 205.03644116719565
Validation loss: 199.0360

-------------------- Epoch 490 --------------------
Train loss: 0.9760
Test loss: 198.9496364593506
Test loss: 204.94817097981772
Validation loss: 198.9496

-------------------- Epoch 491 --------------------
Train loss: 0.9798
Test loss: 198.9886391957601
Test loss: 204.98711967468262
Validation loss: 198.9886

-------------------- Epoch 492 --------------------
Train loss: 0.9791
Test loss: 198.94593302408853
Test loss: 204.9431578318278
Validation loss: 198.9459

-------------------- Epoch 493 --------------------
Train loss: 0.9791
Test loss: 198.99732144673666
Test loss: 204.99486923217773
Validation loss: 198.9973

-------------------- Epoch 494 --------------------
Train loss: 0.9786
Test loss: 198.97348658243814
Test loss: 204.97007369995117
Validation loss: 198.9735

-------------------- Epoch 495 --------------------
Train loss: 0.9804
Test loss: 199.0345261891683
Test loss: 205.03169759114584
Validation loss: 199.0345

-------------------- Epoch 496 --------------------
Train loss: 0.9779
Test loss: 198.94870885213217
Test loss: 204.9439182281494
Validation loss: 198.9487

-------------------- Epoch 497 --------------------
Train loss: 0.9777
Test loss: 198.82739384969076
Test loss: 204.82026163736978
New best validation loss: 198.8274, saving model weights to best_model_weights.pth

-------------------- Epoch 498 --------------------
Train loss: 0.9742
Test loss: 198.86834335327148
Test loss: 204.8612372080485
Validation loss: 198.8683

-------------------- Epoch 499 --------------------
Train loss: 0.9753
Test loss: 198.96555264790854
Test loss: 204.95925331115723
Validation loss: 198.9656

-------------------- Epoch 500 --------------------
Train loss: 0.9768
Test loss: 198.87616793314615
Test loss: 204.86802609761557
Validation loss: 198.8762

-------------------- Epoch 501 --------------------
Train loss: 0.9794
Test loss: 198.82898139953613
Test loss: 204.8196201324463
Validation loss: 198.8290

-------------------- Epoch 502 --------------------
Train loss: 0.9758
Test loss: 198.94481404622397
Test loss: 204.93648401896158
Validation loss: 198.9448

-------------------- Epoch 503 --------------------
Train loss: 0.9782
Test loss: 198.81892903645834
Test loss: 204.80831082661948
New best validation loss: 198.8189, saving model weights to best_model_weights.pth

-------------------- Epoch 504 --------------------
Train loss: 0.9776
Test loss: 198.89662233988443
Test loss: 204.88658396402994
Validation loss: 198.8966

-------------------- Epoch 505 --------------------
Train loss: 0.9768
Test loss: 198.81555811564127
Test loss: 204.80390421549478
New best validation loss: 198.8156, saving model weights to best_model_weights.pth

-------------------- Epoch 506 --------------------
Train loss: 0.9745
Test loss: 198.95103136698404
Test loss: 204.9407901763916
Validation loss: 198.9510

-------------------- Epoch 507 --------------------
Train loss: 0.9800
Test loss: 198.82150840759277
Test loss: 204.80881118774414
Validation loss: 198.8215

-------------------- Epoch 508 --------------------
Train loss: 0.9766
Test loss: 198.87432670593262
Test loss: 204.86192576090494
Validation loss: 198.8743

-------------------- Epoch 509 --------------------
Train loss: 0.9756
Test loss: 198.89880879720053
Test loss: 204.8862279256185
Validation loss: 198.8988

-------------------- Epoch 510 --------------------
Train loss: 0.9782
Test loss: 198.9535427093506
Test loss: 204.94144121805826
Validation loss: 198.9535

-------------------- Epoch 511 --------------------
Train loss: 0.9761
Test loss: 198.83231608072916
Test loss: 204.81775283813477
Validation loss: 198.8323

-------------------- Epoch 512 --------------------
Train loss: 0.9784
Test loss: 198.85962422688803
Test loss: 204.84498850504556
Validation loss: 198.8596

-------------------- Epoch 513 --------------------
Train loss: 0.9761
Test loss: 198.78890736897787
Test loss: 204.77279154459634
New best validation loss: 198.7889, saving model weights to best_model_weights.pth

-------------------- Epoch 514 --------------------
Train loss: 0.9749
Test loss: 198.86606470743814
Test loss: 204.85052299499512
Validation loss: 198.8661

-------------------- Epoch 515 --------------------
Train loss: 0.9786
Test loss: 198.91236368815103
Test loss: 204.89714177449545
Validation loss: 198.9124

-------------------- Epoch 516 --------------------
Train loss: 0.9778
Test loss: 198.81145858764648
Test loss: 204.7942803700765
Validation loss: 198.8115

-------------------- Epoch 517 --------------------
Train loss: 0.9741
Test loss: 198.83664894104004
Test loss: 204.81930669148764
Validation loss: 198.8366

-------------------- Epoch 518 --------------------
Train loss: 0.9768
Test loss: 198.79204305013022
Test loss: 204.77355511983237
Validation loss: 198.7920

-------------------- Epoch 519 --------------------
Train loss: 0.9846
Test loss: 198.84797541300455
Test loss: 204.82978121439615
Validation loss: 198.8480

-------------------- Epoch 520 --------------------
Train loss: 0.9767
Test loss: 198.80775705973306
Test loss: 204.78853352864584
Validation loss: 198.8078

-------------------- Epoch 521 --------------------
Train loss: 0.9773
Test loss: 198.86535517374674
Test loss: 204.84655316670737
Validation loss: 198.8654

-------------------- Epoch 522 --------------------
Train loss: 0.9767
Test loss: 198.79379971822104
Test loss: 204.77346420288086
Validation loss: 198.7938

-------------------- Epoch 523 --------------------
Train loss: 0.9795
Test loss: 198.73565864562988
Test loss: 204.7141145070394
New best validation loss: 198.7357, saving model weights to best_model_weights.pth

-------------------- Epoch 524 --------------------
Train loss: 0.9759
Test loss: 198.8173344930013
Test loss: 204.79637336730957
Validation loss: 198.8173

-------------------- Epoch 525 --------------------
Train loss: 0.9744
Test loss: 198.8428986867269
Test loss: 204.82193183898926
Validation loss: 198.8429

-------------------- Epoch 526 --------------------
Train loss: 0.9750
Test loss: 198.79034614562988
Test loss: 204.76814715067545
Validation loss: 198.7903

-------------------- Epoch 527 --------------------
Train loss: 0.9758
Test loss: 198.7458782196045
Test loss: 204.72265497843424
Validation loss: 198.7459

-------------------- Epoch 528 --------------------
Train loss: 0.9777
Test loss: 198.78145217895508
Test loss: 204.75826835632324
Validation loss: 198.7815

-------------------- Epoch 529 --------------------
Train loss: 0.9752
Test loss: 198.7786947886149
Test loss: 204.75507926940918
Validation loss: 198.7787

-------------------- Epoch 530 --------------------
Train loss: 0.9765
Test loss: 198.75788815816244
Test loss: 204.73350779215494
Validation loss: 198.7579

-------------------- Epoch 531 --------------------
Train loss: 0.9753
Test loss: 198.79938634236655
Test loss: 204.77512550354004
Validation loss: 198.7994

-------------------- Epoch 532 --------------------
Train loss: 0.9753
Test loss: 198.73170852661133
Test loss: 204.70614115397134
New best validation loss: 198.7317, saving model weights to best_model_weights.pth

-------------------- Epoch 533 --------------------
Train loss: 0.9776
Test loss: 198.68908818562826
Test loss: 204.66247749328613
New best validation loss: 198.6891, saving model weights to best_model_weights.pth

-------------------- Epoch 534 --------------------
Train loss: 0.9766
Test loss: 198.7855084737142
Test loss: 204.75982475280762
Validation loss: 198.7855

-------------------- Epoch 535 --------------------
Train loss: 0.9765
Test loss: 198.72850481669107
Test loss: 204.70164680480957
Validation loss: 198.7285

-------------------- Epoch 536 --------------------
Train loss: 0.9789
Test loss: 198.72588793436685
Test loss: 204.69858678181967
Validation loss: 198.7259

-------------------- Epoch 537 --------------------
Train loss: 0.9736
Test loss: 198.7577419281006
Test loss: 204.73047383626303
Validation loss: 198.7577

-------------------- Epoch 538 --------------------
Train loss: 0.9765
Test loss: 198.7702522277832
Test loss: 204.74275334676108
Validation loss: 198.7703

-------------------- Epoch 539 --------------------
Train loss: 0.9779
Test loss: 198.7483107248942
Test loss: 204.72010231018066
Validation loss: 198.7483

-------------------- Epoch 540 --------------------
Train loss: 0.9746
Test loss: 198.7600975036621
Test loss: 204.7316919962565
Validation loss: 198.7601

-------------------- Epoch 541 --------------------
Train loss: 0.9754
Test loss: 198.68134053548178
Test loss: 204.65145556131998
New best validation loss: 198.6813, saving model weights to best_model_weights.pth

-------------------- Epoch 542 --------------------
Train loss: 0.9743
Test loss: 198.69576136271158
Test loss: 204.6656812032064
Validation loss: 198.6958

-------------------- Epoch 543 --------------------
Train loss: 0.9815
Test loss: 198.74282201131186
Test loss: 204.71297327677408
Validation loss: 198.7428

-------------------- Epoch 544 --------------------
Train loss: 0.9762
Test loss: 198.70466804504395
Test loss: 204.6738961537679
Validation loss: 198.7047

-------------------- Epoch 545 --------------------
Train loss: 0.9756
Test loss: 198.73911348978677
Test loss: 204.70843251546225
Validation loss: 198.7391

-------------------- Epoch 546 --------------------
Train loss: 0.9751
Test loss: 198.68926747639975
Test loss: 204.65750122070312
Validation loss: 198.6893

-------------------- Epoch 547 --------------------
Train loss: 0.9763
Test loss: 198.7413190205892
Test loss: 204.7099526723226
Validation loss: 198.7413

-------------------- Epoch 548 --------------------
Train loss: 0.9742
Test loss: 198.75143686930338
Test loss: 204.71989822387695
Validation loss: 198.7514

-------------------- Epoch 549 --------------------
Train loss: 0.9762
Test loss: 198.7298952738444
Test loss: 204.6975975036621
Validation loss: 198.7299

-------------------- Epoch 550 --------------------
Train loss: 0.9732
Test loss: 198.73523076375326
Test loss: 204.7026424407959
Validation loss: 198.7352

-------------------- Epoch 551 --------------------
Train loss: 0.9736
Test loss: 198.70457649230957
Test loss: 204.67112986246744
Validation loss: 198.7046

-------------------- Epoch 552 --------------------
Train loss: 0.9755
Test loss: 198.693084081014
Test loss: 204.65910275777182
Validation loss: 198.6931

-------------------- Epoch 553 --------------------
Train loss: 0.9782
Test loss: 198.62141927083334
Test loss: 204.58613777160645
New best validation loss: 198.6214, saving model weights to best_model_weights.pth

-------------------- Epoch 554 --------------------
Train loss: 0.9738
Test loss: 198.6346238454183
Test loss: 204.59918022155762
Validation loss: 198.6346

-------------------- Epoch 555 --------------------
Train loss: 0.9765
Test loss: 198.65972836812338
Test loss: 204.62424914042154
Validation loss: 198.6597

-------------------- Epoch 556 --------------------
Train loss: 0.9735
Test loss: 198.63884035746256
Test loss: 204.6027692159017
Validation loss: 198.6388

-------------------- Epoch 557 --------------------
Train loss: 0.9760
Test loss: 198.67571576436362
Test loss: 204.6397959391276
Validation loss: 198.6757

-------------------- Epoch 558 --------------------
Train loss: 0.9763
Test loss: 198.60975774129233
Test loss: 204.5725529988607
New best validation loss: 198.6098, saving model weights to best_model_weights.pth

-------------------- Epoch 559 --------------------
Train loss: 0.9748
Test loss: 198.65253130594888
Test loss: 204.61555608113608
Validation loss: 198.6525

-------------------- Epoch 560 --------------------
Train loss: 0.9758
Test loss: 198.64934539794922
Test loss: 204.61197408040366
Validation loss: 198.6493

-------------------- Epoch 561 --------------------
Train loss: 0.9745
Test loss: 198.67137654622397
Test loss: 204.63400395711264
Validation loss: 198.6714

-------------------- Epoch 562 --------------------
Train loss: 0.9761
Test loss: 198.63651084899902
Test loss: 204.59829394022623
Validation loss: 198.6365

-------------------- Epoch 563 --------------------
Train loss: 0.9757
Test loss: 198.6197770436605
Test loss: 204.58099810282388
Validation loss: 198.6198

-------------------- Epoch 564 --------------------
Train loss: 0.9774
Test loss: 198.69368426005045
Test loss: 204.65577189127603
Validation loss: 198.6937

-------------------- Epoch 565 --------------------
Train loss: 0.9729
Test loss: 198.61640421549478
Test loss: 204.57694816589355
Validation loss: 198.6164

-------------------- Epoch 566 --------------------
Train loss: 0.9744
Test loss: 198.6506665547689
Test loss: 204.61139551798502
Validation loss: 198.6507

-------------------- Epoch 567 --------------------
Train loss: 0.9725
Test loss: 198.62014643351236
Test loss: 204.58014233907065
Validation loss: 198.6201

-------------------- Epoch 568 --------------------
Train loss: 0.9789
Test loss: 198.59671020507812
Test loss: 204.55604616800943
New best validation loss: 198.5967, saving model weights to best_model_weights.pth

-------------------- Epoch 569 --------------------
Train loss: 0.9752
Test loss: 198.57531929016113
Test loss: 204.53408114115396
New best validation loss: 198.5753, saving model weights to best_model_weights.pth

-------------------- Epoch 570 --------------------
Train loss: 0.9728
Test loss: 198.62678146362305
Test loss: 204.58587201436362
Validation loss: 198.6268

-------------------- Epoch 571 --------------------
Train loss: 0.9728
Test loss: 198.62653986612955
Test loss: 204.58533414204916
Validation loss: 198.6265

-------------------- Epoch 572 --------------------
Train loss: 0.9751
Test loss: 198.59726587931314
Test loss: 204.55535825093588
Validation loss: 198.5973

-------------------- Epoch 573 --------------------
Train loss: 0.9767
Test loss: 198.5923817952474
Test loss: 204.55011622111002
Validation loss: 198.5924

-------------------- Epoch 574 --------------------
Train loss: 0.9784
Test loss: 198.5741284688314
Test loss: 204.5313460032145
New best validation loss: 198.5741, saving model weights to best_model_weights.pth

-------------------- Epoch 575 --------------------
Train loss: 0.9758
Test loss: 198.58559862772623
Test loss: 204.5426870981852
Validation loss: 198.5856

-------------------- Epoch 576 --------------------
Train loss: 0.9741
Test loss: 198.56530062357584
Test loss: 204.52185122172037
New best validation loss: 198.5653, saving model weights to best_model_weights.pth

-------------------- Epoch 577 --------------------
Train loss: 0.9749
Test loss: 198.59238942464194
Test loss: 204.54903856913248
Validation loss: 198.5924

-------------------- Epoch 578 --------------------
Train loss: 0.9734
Test loss: 198.5887908935547
Test loss: 204.54511324564615
Validation loss: 198.5888

-------------------- Epoch 579 --------------------
Train loss: 0.9809
Test loss: 198.63496843973795
Test loss: 204.5917205810547
Validation loss: 198.6350

-------------------- Epoch 580 --------------------
Train loss: 0.9733
Test loss: 198.5784371693929
Test loss: 204.53407414754233
Validation loss: 198.5784

-------------------- Epoch 581 --------------------
Train loss: 0.9743
Test loss: 198.51181729634604
Test loss: 204.46636072794595
New best validation loss: 198.5118, saving model weights to best_model_weights.pth

-------------------- Epoch 582 --------------------
Train loss: 0.9797
Test loss: 198.5317497253418
Test loss: 204.48625818888345
Validation loss: 198.5317

-------------------- Epoch 583 --------------------
Train loss: 0.9755
Test loss: 198.5602684020996
Test loss: 204.51487731933594
Validation loss: 198.5603

-------------------- Epoch 584 --------------------
Train loss: 0.9733
Test loss: 198.58005587259927
Test loss: 204.53471438090006
Validation loss: 198.5801

-------------------- Epoch 585 --------------------
Train loss: 0.9722
Test loss: 198.5631192525228
Test loss: 204.5173110961914
Validation loss: 198.5631

-------------------- Epoch 586 --------------------
Train loss: 0.9740
Test loss: 198.5828539530436
Test loss: 204.53704579671225
Validation loss: 198.5829

-------------------- Epoch 587 --------------------
Train loss: 0.9731
Test loss: 198.58608881632486
Test loss: 204.5400931040446
Validation loss: 198.5861

-------------------- Epoch 588 --------------------
Train loss: 0.9742
Test loss: 198.54872385660806
Test loss: 204.50195693969727
Validation loss: 198.5487

-------------------- Epoch 589 --------------------
Train loss: 0.9736
Test loss: 198.55197270711264
Test loss: 204.50498390197754
Validation loss: 198.5520

-------------------- Epoch 590 --------------------
Train loss: 0.9730
Test loss: 198.5690066019694
Test loss: 204.52203877766928
Validation loss: 198.5690

-------------------- Epoch 591 --------------------
Train loss: 0.9733
Test loss: 198.55363591512045
Test loss: 204.50622431437174
Validation loss: 198.5536

-------------------- Epoch 592 --------------------
Train loss: 0.9736
Test loss: 198.53292973836264
Test loss: 204.48501841227213
Validation loss: 198.5329

-------------------- Epoch 593 --------------------
Train loss: 0.9755
Test loss: 198.55406188964844
Test loss: 204.50622940063477
Validation loss: 198.5541

-------------------- Epoch 594 --------------------
Train loss: 0.9745
Test loss: 198.55251502990723
Test loss: 204.50442441304526
Validation loss: 198.5525

-------------------- Epoch 595 --------------------
Train loss: 0.9747
Test loss: 198.55914179484049
Test loss: 204.5109462738037
Validation loss: 198.5591

-------------------- Epoch 596 --------------------
Train loss: 0.9744
Test loss: 198.51493390401205
Test loss: 204.46590614318848
Validation loss: 198.5149

-------------------- Epoch 597 --------------------
Train loss: 0.9745
Test loss: 198.54332415262857
Test loss: 204.49449030558267
Validation loss: 198.5433

-------------------- Epoch 598 --------------------
Train loss: 0.9762
Test loss: 198.54597981770834
Test loss: 204.49697240193686
Validation loss: 198.5460

-------------------- Epoch 599 --------------------
Train loss: 0.9775
Test loss: 198.56320889790854
Test loss: 204.51424916585287
Validation loss: 198.5632

-------------------- Epoch 600 --------------------
Train loss: 0.9727
Test loss: 198.53801472981772
Test loss: 204.48848088582358
Validation loss: 198.5380

-------------------- Epoch 601 --------------------
Train loss: 0.9740
Test loss: 198.53696378072104
Test loss: 204.48722712198892
Validation loss: 198.5370

-------------------- Epoch 602 --------------------
Train loss: 0.9802
Test loss: 198.5262762705485
Test loss: 204.47616895039877
Validation loss: 198.5263

-------------------- Epoch 603 --------------------
Train loss: 0.9756
Test loss: 198.53516832987467
Test loss: 204.48497517903647
Validation loss: 198.5352

-------------------- Epoch 604 --------------------
Train loss: 0.9761
Test loss: 198.56174278259277
Test loss: 204.5117613474528
Validation loss: 198.5617

-------------------- Epoch 605 --------------------
Train loss: 0.9731
Test loss: 198.5251210530599
Test loss: 204.47439765930176
Validation loss: 198.5251

-------------------- Epoch 606 --------------------
Train loss: 0.9731
Test loss: 198.51996930440268
Test loss: 204.4689826965332
Validation loss: 198.5200

-------------------- Epoch 607 --------------------
Train loss: 0.9801
Test loss: 198.52459208170572
Test loss: 204.4734878540039
Validation loss: 198.5246

-------------------- Epoch 608 --------------------
Train loss: 0.9734
Test loss: 198.5380318959554
Test loss: 204.48692639668783
Validation loss: 198.5380

-------------------- Epoch 609 --------------------
Train loss: 0.9735
Test loss: 198.51774215698242
Test loss: 204.46615982055664
Validation loss: 198.5177

-------------------- Epoch 610 --------------------
Train loss: 0.9765
Test loss: 198.4936408996582
Test loss: 204.4415429433187
New best validation loss: 198.4936, saving model weights to best_model_weights.pth

-------------------- Epoch 611 --------------------
Train loss: 0.9742
Test loss: 198.52674420674643
Test loss: 204.47491772969565
Validation loss: 198.5267

-------------------- Epoch 612 --------------------
Train loss: 0.9750
Test loss: 198.50493748982748
Test loss: 204.45263735453287
Validation loss: 198.5049

-------------------- Epoch 613 --------------------
Train loss: 0.9763
Test loss: 198.4962189992269
Test loss: 204.44361368815103
Validation loss: 198.4962

-------------------- Epoch 614 --------------------
Train loss: 0.9746
Test loss: 198.47541364034018
Test loss: 204.4223836263021
New best validation loss: 198.4754, saving model weights to best_model_weights.pth

-------------------- Epoch 615 --------------------
Train loss: 0.9729
Test loss: 198.50574747721353
Test loss: 204.45295206705728
Validation loss: 198.5057

-------------------- Epoch 616 --------------------
Train loss: 0.9749
Test loss: 198.49978319803873
Test loss: 204.44674173990884
Validation loss: 198.4998

-------------------- Epoch 617 --------------------
Train loss: 0.9729
Test loss: 198.5034523010254
Test loss: 204.45030466715494
Validation loss: 198.5035

-------------------- Epoch 618 --------------------
Train loss: 0.9747
Test loss: 198.507537206014
Test loss: 204.45428530375162
Validation loss: 198.5075

-------------------- Epoch 619 --------------------
Train loss: 0.9743
Test loss: 198.50495211283365
Test loss: 204.451535542806
Validation loss: 198.5050

-------------------- Epoch 620 --------------------
Train loss: 0.9761
Test loss: 198.5013656616211
Test loss: 204.44774373372397
Validation loss: 198.5014

-------------------- Epoch 621 --------------------
Train loss: 0.9762
Test loss: 198.49951553344727
Test loss: 204.44572893778482
Validation loss: 198.4995

-------------------- Epoch 622 --------------------
Train loss: 0.9755
Test loss: 198.50887171427408
Test loss: 204.45508257548013
Validation loss: 198.5089

-------------------- Epoch 623 --------------------
Train loss: 0.9754
Test loss: 198.49665196736655
Test loss: 204.44252141316733
Validation loss: 198.4967

-------------------- Epoch 624 --------------------
Train loss: 0.9744
Test loss: 198.50320688883463
Test loss: 204.44903628031412
Validation loss: 198.5032

-------------------- Epoch 625 --------------------
Train loss: 0.9748
Test loss: 198.48987007141113
Test loss: 204.4353510538737
Validation loss: 198.4899

-------------------- Epoch 626 --------------------
Train loss: 0.9810
Test loss: 198.4904588063558
Test loss: 204.435817082723
Validation loss: 198.4905

-------------------- Epoch 627 --------------------
Train loss: 0.9749
Test loss: 198.49486351013184
Test loss: 204.44015630086264
Validation loss: 198.4949

-------------------- Epoch 628 --------------------
Train loss: 0.9722
Test loss: 198.4944750467936
Test loss: 204.43962478637695
Validation loss: 198.4945

-------------------- Epoch 629 --------------------
Train loss: 0.9747
Test loss: 198.47727902730307
Test loss: 204.42204984029135
Validation loss: 198.4773

-------------------- Epoch 630 --------------------
Train loss: 0.9777
Test loss: 198.48770141601562
Test loss: 204.43250528971353
Validation loss: 198.4877

-------------------- Epoch 631 --------------------
Train loss: 0.9735
Test loss: 198.46796735127768
Test loss: 204.41233126322427
New best validation loss: 198.4680, saving model weights to best_model_weights.pth

-------------------- Epoch 632 --------------------
Train loss: 0.9758
Test loss: 198.46527290344238
Test loss: 204.40947087605795
New best validation loss: 198.4653, saving model weights to best_model_weights.pth

-------------------- Epoch 633 --------------------
Train loss: 0.9723
Test loss: 198.46816698710123
Test loss: 204.41229438781738
Validation loss: 198.4682

-------------------- Epoch 634 --------------------
Train loss: 0.9738
Test loss: 198.4694677988688
Test loss: 204.41349347432455
Validation loss: 198.4695

-------------------- Epoch 635 --------------------
Train loss: 0.9775
Test loss: 198.4738629659017
Test loss: 204.41785049438477
Validation loss: 198.4739

-------------------- Epoch 636 --------------------
Train loss: 0.9732
Test loss: 198.48247273763022
Test loss: 204.4264933268229
Validation loss: 198.4825

-------------------- Epoch 637 --------------------
Train loss: 0.9760
Test loss: 198.45794296264648
Test loss: 204.4014638264974
New best validation loss: 198.4579, saving model weights to best_model_weights.pth

-------------------- Epoch 638 --------------------
Train loss: 0.9734
Test loss: 198.465305964152
Test loss: 204.4088331858317
Validation loss: 198.4653

-------------------- Epoch 639 --------------------
Train loss: 0.9747
Test loss: 198.4662882486979
Test loss: 204.40973281860352
Validation loss: 198.4663

-------------------- Epoch 640 --------------------
Train loss: 0.9748
Test loss: 198.45502535502115
Test loss: 204.3981876373291
New best validation loss: 198.4550, saving model weights to best_model_weights.pth

-------------------- Epoch 641 --------------------
Train loss: 0.9743
Test loss: 198.4667936960856
Test loss: 204.41003799438477
Validation loss: 198.4668

-------------------- Epoch 642 --------------------
Train loss: 0.9737
Test loss: 198.4559529622396
Test loss: 204.39892705281576
Validation loss: 198.4560

-------------------- Epoch 643 --------------------
Train loss: 0.9768
Test loss: 198.47045771280924
Test loss: 204.41356976826987
Validation loss: 198.4705

-------------------- Epoch 644 --------------------
Train loss: 0.9764
Test loss: 198.46454111735025
Test loss: 204.40746434529623
Validation loss: 198.4645

-------------------- Epoch 645 --------------------
Train loss: 0.9771
Test loss: 198.4664077758789
Test loss: 204.40926806131998
Validation loss: 198.4664

-------------------- Epoch 646 --------------------
Train loss: 0.9761
Test loss: 198.45996157328287
Test loss: 204.40263811747232
Validation loss: 198.4600

-------------------- Epoch 647 --------------------
Train loss: 0.9836
Test loss: 198.4765256245931
Test loss: 204.4193515777588
Validation loss: 198.4765

-------------------- Epoch 648 --------------------
Train loss: 0.9772
Test loss: 198.4903049468994
Test loss: 204.4332815806071
Validation loss: 198.4903

-------------------- Epoch 649 --------------------
Train loss: 0.9737
Test loss: 198.47286542256674
Test loss: 204.41548220316568
Validation loss: 198.4729

-------------------- Epoch 650 --------------------
Train loss: 0.9732
Test loss: 198.4711596171061
Test loss: 204.41366958618164
Validation loss: 198.4712

-------------------- Epoch 651 --------------------
Train loss: 0.9766
Test loss: 198.46290397644043
Test loss: 204.40520604451498
Validation loss: 198.4629

-------------------- Epoch 652 --------------------
Train loss: 0.9726
Test loss: 198.45110893249512
Test loss: 204.39314905802408
New best validation loss: 198.4511, saving model weights to best_model_weights.pth

-------------------- Epoch 653 --------------------
Train loss: 0.9726
Test loss: 198.46574846903482
Test loss: 204.4079418182373
Validation loss: 198.4657

-------------------- Epoch 654 --------------------
Train loss: 0.9749
Test loss: 198.46880658467612
Test loss: 204.41098149617514
Validation loss: 198.4688

-------------------- Epoch 655 --------------------
Train loss: 0.9742
Test loss: 198.45865631103516
Test loss: 204.40058517456055
Validation loss: 198.4587

-------------------- Epoch 656 --------------------
Train loss: 0.9748
Test loss: 198.4376392364502
Test loss: 204.3791732788086
New best validation loss: 198.4376, saving model weights to best_model_weights.pth

-------------------- Epoch 657 --------------------
Train loss: 0.9765
Test loss: 198.45197741190592
Test loss: 204.39368184407553
Validation loss: 198.4520

-------------------- Epoch 658 --------------------
Train loss: 0.9780
Test loss: 198.4593505859375
Test loss: 204.4011058807373
Validation loss: 198.4594

-------------------- Epoch 659 --------------------
Train loss: 0.9721
Test loss: 198.46676890055338
Test loss: 204.4085807800293
Validation loss: 198.4668

-------------------- Epoch 660 --------------------
Train loss: 0.9759
Test loss: 198.45740445454916
Test loss: 204.39900652567545
Validation loss: 198.4574

-------------------- Epoch 661 --------------------
Train loss: 0.9735
Test loss: 198.44675827026367
Test loss: 204.38812700907388
Validation loss: 198.4468

-------------------- Epoch 662 --------------------
Train loss: 0.9763
Test loss: 198.45614433288574
Test loss: 204.3975919087728
Validation loss: 198.4561

-------------------- Epoch 663 --------------------
Train loss: 0.9726
Test loss: 198.4502944946289
Test loss: 204.3915926615397
Validation loss: 198.4503

-------------------- Epoch 664 --------------------
Train loss: 0.9758
Test loss: 198.44878832499185
Test loss: 204.39000956217447
Validation loss: 198.4488

-------------------- Epoch 665 --------------------
Train loss: 0.9740
Test loss: 198.44524574279785
Test loss: 204.3863582611084
Validation loss: 198.4452

-------------------- Epoch 666 --------------------
Train loss: 0.9742
Test loss: 198.45034154256186
Test loss: 204.39148457845053
Validation loss: 198.4503

-------------------- Epoch 667 --------------------
Train loss: 0.9746
Test loss: 198.4519329071045
Test loss: 204.39304733276367
Validation loss: 198.4519

-------------------- Epoch 668 --------------------
Train loss: 0.9764
Test loss: 198.45807075500488
Test loss: 204.39923095703125
Validation loss: 198.4581

-------------------- Epoch 669 --------------------
Train loss: 0.9781
Test loss: 198.4476515452067
Test loss: 204.3886013031006
Validation loss: 198.4477

-------------------- Epoch 670 --------------------
Train loss: 0.9762
Test loss: 198.44578552246094
Test loss: 204.38665644327799
Validation loss: 198.4458

-------------------- Epoch 671 --------------------
Train loss: 0.9809
Test loss: 198.44945653279623
Test loss: 204.39034016927084
Validation loss: 198.4495

-------------------- Epoch 672 --------------------
Train loss: 0.9767
Test loss: 198.4483896891276
Test loss: 204.38921546936035
Validation loss: 198.4484

-------------------- Epoch 673 --------------------
Train loss: 0.9758
Test loss: 198.45547231038412
Test loss: 204.3963737487793
Validation loss: 198.4555

-------------------- Epoch 674 --------------------
Train loss: 0.9758
Test loss: 198.44272677103677
Test loss: 204.38338152567545
Validation loss: 198.4427

-------------------- Epoch 675 --------------------
Train loss: 0.9742
Test loss: 198.44166374206543
Test loss: 204.38226954142252
Validation loss: 198.4417

-------------------- Epoch 676 --------------------
Train loss: 0.9796
Test loss: 198.44742711385092
Test loss: 204.38808568318686
Validation loss: 198.4474

-------------------- Epoch 677 --------------------
Train loss: 0.9750
Test loss: 198.4433250427246
Test loss: 204.38388888041177
Validation loss: 198.4433

-------------------- Epoch 678 --------------------
Train loss: 0.9727
Test loss: 198.43969917297363
Test loss: 204.38016510009766
Validation loss: 198.4397

-------------------- Epoch 679 --------------------
Train loss: 0.9740
Test loss: 198.4364693959554
Test loss: 204.3768507639567
New best validation loss: 198.4365, saving model weights to best_model_weights.pth

-------------------- Epoch 680 --------------------
Train loss: 0.9756
Test loss: 198.43320274353027
Test loss: 204.37350018819174
New best validation loss: 198.4332, saving model weights to best_model_weights.pth

-------------------- Epoch 681 --------------------
Train loss: 0.9757
Test loss: 198.43267885843912
Test loss: 204.37293815612793
New best validation loss: 198.4327, saving model weights to best_model_weights.pth

-------------------- Epoch 682 --------------------
Train loss: 0.9789
Test loss: 198.43427975972494
Test loss: 204.374542872111
Validation loss: 198.4343

-------------------- Epoch 683 --------------------
Train loss: 0.9731
Test loss: 198.4326171875
Test loss: 204.3728345235189
New best validation loss: 198.4326, saving model weights to best_model_weights.pth

-------------------- Epoch 684 --------------------
Train loss: 0.9769
Test loss: 198.43835894266763
Test loss: 204.37863222757974
Validation loss: 198.4384

-------------------- Epoch 685 --------------------
Train loss: 0.9752
Test loss: 198.4308649698893
Test loss: 204.3709913889567
New best validation loss: 198.4309, saving model weights to best_model_weights.pth

-------------------- Epoch 686 --------------------
Train loss: 0.9774
Test loss: 198.43493715922037
Test loss: 204.37510871887207
Validation loss: 198.4349

-------------------- Epoch 687 --------------------
Train loss: 0.9741
Test loss: 198.43575159708658
Test loss: 204.37591616312662
Validation loss: 198.4358

-------------------- Epoch 688 --------------------
Train loss: 0.9751
Test loss: 198.43823051452637
Test loss: 204.3784205118815
Validation loss: 198.4382

-------------------- Epoch 689 --------------------
Train loss: 0.9772
Test loss: 198.44489542643228
Test loss: 204.3851687113444
Validation loss: 198.4449

-------------------- Epoch 690 --------------------
Train loss: 0.9725
Test loss: 198.4425080617269
Test loss: 204.38272603352866
Validation loss: 198.4425

-------------------- Epoch 691 --------------------
Train loss: 0.9753
Test loss: 198.4399013519287
Test loss: 204.38005701700845
Validation loss: 198.4399

-------------------- Epoch 692 --------------------
Train loss: 0.9738
Test loss: 198.44235801696777
Test loss: 204.3825340270996
Validation loss: 198.4424

-------------------- Epoch 693 --------------------
Train loss: 0.9766
Test loss: 198.4409376780192
Test loss: 204.3810691833496
Validation loss: 198.4409

-------------------- Epoch 694 --------------------
Train loss: 0.9758
Test loss: 198.4381529490153
Test loss: 204.37822659810385
Validation loss: 198.4382

-------------------- Epoch 695 --------------------
Train loss: 0.9755
Test loss: 198.43924967447916
Test loss: 204.37932523091635
Validation loss: 198.4392

-------------------- Epoch 696 --------------------
Train loss: 0.9743
Test loss: 198.44270960489908
Test loss: 204.38282903035483
Validation loss: 198.4427

-------------------- Epoch 697 --------------------
Train loss: 0.9754
Test loss: 198.4411137898763
Test loss: 204.3811937967936
Validation loss: 198.4411

-------------------- Epoch 698 --------------------
Train loss: 0.9760
Test loss: 198.4388739267985
Test loss: 204.3789037068685
Validation loss: 198.4389

-------------------- Epoch 699 --------------------
Train loss: 0.9737
Test loss: 198.4357058207194
Test loss: 204.37567583719888
Validation loss: 198.4357

-------------------- Epoch 700 --------------------
Train loss: 0.9750
Test loss: 198.43635050455728
Test loss: 204.37631861368814
Validation loss: 198.4364

-------------------- Epoch 701 --------------------
Train loss: 0.9741
Test loss: 198.43822733561197
Test loss: 204.37821261088052
Validation loss: 198.4382

-------------------- Epoch 702 --------------------
Train loss: 0.9796
Test loss: 198.43705940246582
Test loss: 204.37701988220215
Validation loss: 198.4371

-------------------- Epoch 703 --------------------
Train loss: 0.9737
Test loss: 198.43711217244467
Test loss: 204.3770637512207
Validation loss: 198.4371

-------------------- Epoch 704 --------------------
Train loss: 0.9740
Test loss: 198.43737157185873
Test loss: 204.3773161570231
Validation loss: 198.4374

-------------------- Epoch 705 --------------------
Train loss: 0.9736
Test loss: 198.43740463256836
Test loss: 204.37734349568686
Validation loss: 198.4374

-------------------- Epoch 706 --------------------
Train loss: 0.9741
Test loss: 198.4360211690267
Test loss: 204.37592951456705
Validation loss: 198.4360

-------------------- Epoch 707 --------------------
Train loss: 0.9774
Test loss: 198.43453788757324
Test loss: 204.37441762288412
Validation loss: 198.4345

-------------------- Epoch 708 --------------------
Train loss: 0.9740
Test loss: 198.43657811482748
Test loss: 204.3764820098877
Validation loss: 198.4366

-------------------- Epoch 709 --------------------
Train loss: 0.9809
Test loss: 198.43822224934897
Test loss: 204.37814903259277
Validation loss: 198.4382

-------------------- Epoch 710 --------------------
Train loss: 0.9753
Test loss: 198.43763160705566
Test loss: 204.37754440307617
Validation loss: 198.4376

-------------------- Epoch 711 --------------------
Train loss: 0.9753
Test loss: 198.4378229777018
Test loss: 204.37773068745932
Validation loss: 198.4378

-------------------- Epoch 712 --------------------
Train loss: 0.9739
Test loss: 198.43737411499023
Test loss: 204.37727228800455
Validation loss: 198.4374

-------------------- Epoch 713 --------------------
Train loss: 0.9749
Test loss: 198.4368381500244
Test loss: 204.3767261505127
Validation loss: 198.4368

-------------------- Epoch 714 --------------------
Train loss: 0.9735
Test loss: 198.43560409545898
Test loss: 204.37546920776367
Validation loss: 198.4356

-------------------- Epoch 715 --------------------
Train loss: 0.9764
Test loss: 198.43566767374674
Test loss: 204.37552452087402
Validation loss: 198.4357

-------------------- Epoch 716 --------------------
Train loss: 0.9720
Test loss: 198.43512725830078
Test loss: 204.37497838338217
Validation loss: 198.4351

-------------------- Epoch 717 --------------------
Train loss: 0.9735
Test loss: 198.43459765116373
Test loss: 204.3744328816732
Validation loss: 198.4346

-------------------- Epoch 718 --------------------
Train loss: 0.9726
Test loss: 198.4341608683268
Test loss: 204.37399101257324
Validation loss: 198.4342

-------------------- Epoch 719 --------------------
Train loss: 0.9735
Test loss: 198.4345703125
Test loss: 204.37440554300943
Validation loss: 198.4346

-------------------- Epoch 720 --------------------
Train loss: 0.9757
Test loss: 198.43496322631836
Test loss: 204.37480354309082
Validation loss: 198.4350

-------------------- Epoch 721 --------------------
Train loss: 0.9781
Test loss: 198.43447240193686
Test loss: 204.37430254618326
Validation loss: 198.4345

-------------------- Epoch 722 --------------------
Train loss: 0.9755
Test loss: 198.43527793884277
Test loss: 204.3751163482666
Validation loss: 198.4353

-------------------- Epoch 723 --------------------
Train loss: 0.9724
Test loss: 198.43550173441568
Test loss: 204.37534141540527
Validation loss: 198.4355

-------------------- Epoch 724 --------------------
Train loss: 0.9798
Test loss: 198.4344164530436
Test loss: 204.37424087524414
Validation loss: 198.4344

-------------------- Epoch 725 --------------------
Train loss: 0.9755
Test loss: 198.43473052978516
Test loss: 204.37455876668295
Validation loss: 198.4347

-------------------- Epoch 726 --------------------
Train loss: 0.9761
Test loss: 198.4349708557129
Test loss: 204.37480227152506
Validation loss: 198.4350

-------------------- Epoch 727 --------------------
Train loss: 0.9723
Test loss: 198.43473434448242
Test loss: 204.3745600382487
Validation loss: 198.4347

-------------------- Epoch 728 --------------------
Train loss: 0.9750
Test loss: 198.43443298339844
Test loss: 204.3742504119873
Validation loss: 198.4344

-------------------- Epoch 729 --------------------
Train loss: 0.9739
Test loss: 198.43477884928384
Test loss: 204.37460327148438
Validation loss: 198.4348

-------------------- Epoch 730 --------------------
Train loss: 0.9804
Test loss: 198.43473116556802
Test loss: 204.37455240885416
Validation loss: 198.4347

-------------------- Epoch 731 --------------------
Train loss: 0.9720
Test loss: 198.4348347981771
Test loss: 204.37466049194336
Validation loss: 198.4348

-------------------- Epoch 732 --------------------
Train loss: 0.9807
Test loss: 198.43478647867838
Test loss: 204.3746109008789
Validation loss: 198.4348

-------------------- Epoch 733 --------------------
Train loss: 0.9742
Test loss: 198.43477884928384
Test loss: 204.3746019999186
Validation loss: 198.4348

-------------------- Epoch 734 --------------------
Train loss: 0.9789
Test loss: 198.4348290761312
Test loss: 204.37465222676596
Validation loss: 198.4348

-------------------- Epoch 735 --------------------
Train loss: 0.9719
Test loss: 198.43476804097494
Test loss: 204.37458992004395
Validation loss: 198.4348

-------------------- Epoch 736 --------------------
Train loss: 0.9738
Test loss: 198.43476549784342
Test loss: 204.3745880126953
Validation loss: 198.4348

-------------------- Epoch 737 --------------------
Train loss: 0.9735
Test loss: 198.43474833170572
Test loss: 204.37457402547201
Validation loss: 198.4347

-------------------- Epoch 738 --------------------
Train loss: 0.9776
Test loss: 198.43475914001465
Test loss: 204.37458483378092
Validation loss: 198.4348

-------------------- Epoch 739 --------------------
Train loss: 0.9766
Test loss: 198.43475850423178
Test loss: 204.37458292643228
Validation loss: 198.4348

-------------------- Epoch 740 --------------------
Train loss: 0.9708
Test loss: 198.43476549784342
Test loss: 204.37458737691244
Validation loss: 198.4348

-------------------- Epoch 741 --------------------
Train loss: 0.9754
Test loss: 198.38705190022787
Test loss: 204.32568359375
New best validation loss: 198.3871, saving model weights to best_model_weights.pth

-------------------- Epoch 742 --------------------
Train loss: 0.9744
Test loss: 198.38432947794595
Test loss: 204.32228787740073
New best validation loss: 198.3843, saving model weights to best_model_weights.pth

-------------------- Epoch 743 --------------------
Train loss: 0.9773
Test loss: 198.39033190409342
Test loss: 204.3277333577474
Validation loss: 198.3903

-------------------- Epoch 744 --------------------
Train loss: 0.9733
Test loss: 198.40090052286783
Test loss: 204.3379306793213
Validation loss: 198.4009

-------------------- Epoch 745 --------------------
Train loss: 0.9765
Test loss: 198.4465357462565
Test loss: 204.38372802734375
Validation loss: 198.4465

-------------------- Epoch 746 --------------------
Train loss: 0.9745
Test loss: 198.4368044535319
Test loss: 204.37330182393393
Validation loss: 198.4368

-------------------- Epoch 747 --------------------
Train loss: 0.9741
Test loss: 198.44845835367838
Test loss: 204.3845755259196
Validation loss: 198.4485

-------------------- Epoch 748 --------------------
Train loss: 0.9710
Test loss: 198.45890998840332
Test loss: 204.39472516377768
Validation loss: 198.4589

-------------------- Epoch 749 --------------------
Train loss: 0.9783
Test loss: 198.35946083068848
Test loss: 204.29289372762045
New best validation loss: 198.3595, saving model weights to best_model_weights.pth

-------------------- Epoch 750 --------------------
Train loss: 0.9734
Test loss: 198.45136006673178
Test loss: 204.38581657409668
Validation loss: 198.4514

-------------------- Epoch 751 --------------------
Train loss: 0.9729
Test loss: 198.44042269388834
Test loss: 204.37412452697754
Validation loss: 198.4404

-------------------- Epoch 752 --------------------
Train loss: 0.9729
Test loss: 198.44659614562988
Test loss: 204.37983576456705
Validation loss: 198.4466

-------------------- Epoch 753 --------------------
Train loss: 0.9725
Test loss: 198.34216499328613
Test loss: 204.27301088968912
New best validation loss: 198.3422, saving model weights to best_model_weights.pth

-------------------- Epoch 754 --------------------
Train loss: 0.9734
Test loss: 198.3017603556315
Test loss: 204.23150889078775
New best validation loss: 198.3018, saving model weights to best_model_weights.pth

-------------------- Epoch 755 --------------------
Train loss: 0.9728
Test loss: 198.32030296325684
Test loss: 204.2497189839681
Validation loss: 198.3203

-------------------- Epoch 756 --------------------
Train loss: 0.9749
Test loss: 198.27505429585776
Test loss: 204.20326042175293
New best validation loss: 198.2751, saving model weights to best_model_weights.pth

-------------------- Epoch 757 --------------------
Train loss: 0.9737
Test loss: 198.2540651957194
Test loss: 204.1814982096354
New best validation loss: 198.2541, saving model weights to best_model_weights.pth

-------------------- Epoch 758 --------------------
Train loss: 0.9744
Test loss: 198.3511905670166
Test loss: 204.27927462259927
Validation loss: 198.3512

-------------------- Epoch 759 --------------------
Train loss: 0.9725
Test loss: 198.26069704691568
Test loss: 204.1869068145752
Validation loss: 198.2607

-------------------- Epoch 760 --------------------
Train loss: 0.9739
Test loss: 198.26676559448242
Test loss: 204.19234911600748
Validation loss: 198.2668

-------------------- Epoch 761 --------------------
Train loss: 0.9745
Test loss: 198.30408986409506
Test loss: 204.22955703735352
Validation loss: 198.3041

-------------------- Epoch 762 --------------------
Train loss: 0.9776
Test loss: 198.33076858520508
Test loss: 204.25617345174155
Validation loss: 198.3308

-------------------- Epoch 763 --------------------
Train loss: 0.9716
Test loss: 198.32655461629233
Test loss: 204.25128046671549
Validation loss: 198.3266

-------------------- Epoch 764 --------------------
Train loss: 0.9740
Test loss: 198.3633975982666
Test loss: 204.28825823465982
Validation loss: 198.3634

-------------------- Epoch 765 --------------------
Train loss: 0.9712
Test loss: 198.15415064493814
Test loss: 204.07571093241373
New best validation loss: 198.1542, saving model weights to best_model_weights.pth

-------------------- Epoch 766 --------------------
Train loss: 0.9722
Test loss: 198.30733935038248
Test loss: 204.23000780741373
Validation loss: 198.3073

-------------------- Epoch 767 --------------------
Train loss: 0.9733
Test loss: 198.2499853769938
Test loss: 204.17130279541016
Validation loss: 198.2500

-------------------- Epoch 768 --------------------
Train loss: 0.9730
Test loss: 198.2976474761963
Test loss: 204.21901766459146
Validation loss: 198.2976

-------------------- Epoch 769 --------------------
Train loss: 0.9744
Test loss: 198.21004168192545
Test loss: 204.12971687316895
Validation loss: 198.2100

-------------------- Epoch 770 --------------------
Train loss: 0.9719
Test loss: 198.18718719482422
Test loss: 204.10612042744955
Validation loss: 198.1872

-------------------- Epoch 771 --------------------
Train loss: 0.9709
Test loss: 198.25625356038412
Test loss: 204.1753069559733
Validation loss: 198.2563

-------------------- Epoch 772 --------------------
Train loss: 0.9714
Test loss: 198.30084737141928
Test loss: 204.2201042175293
Validation loss: 198.3008

-------------------- Epoch 773 --------------------
Train loss: 0.9718
Test loss: 198.1601390838623
Test loss: 204.07680447896323
Validation loss: 198.1601

-------------------- Epoch 774 --------------------
Train loss: 0.9728
Test loss: 198.21269925435385
Test loss: 204.1293404897054
Validation loss: 198.2127

-------------------- Epoch 775 --------------------
Train loss: 0.9797
Test loss: 198.21970176696777
Test loss: 204.1358470916748
Validation loss: 198.2197

-------------------- Epoch 776 --------------------
Train loss: 0.9742
Test loss: 198.2725601196289
Test loss: 204.18896865844727
Validation loss: 198.2726

-------------------- Epoch 777 --------------------
Train loss: 0.9731
Test loss: 198.129913965861
Test loss: 204.0439020792643
New best validation loss: 198.1299, saving model weights to best_model_weights.pth

-------------------- Epoch 778 --------------------
Train loss: 0.9758
Test loss: 198.213654200236
Test loss: 204.12795639038086
Validation loss: 198.2137

-------------------- Epoch 779 --------------------
Train loss: 0.9731
Test loss: 198.19728215535483
Test loss: 204.11073303222656
Validation loss: 198.1973

-------------------- Epoch 780 --------------------
Train loss: 0.9730
Test loss: 198.08012771606445
Test loss: 203.9917081197103
New best validation loss: 198.0801, saving model weights to best_model_weights.pth

-------------------- Epoch 781 --------------------
Train loss: 0.9704
Test loss: 198.12990442911783
Test loss: 204.04134623209634
Validation loss: 198.1299

-------------------- Epoch 782 --------------------
Train loss: 0.9744
Test loss: 198.19802729288736
Test loss: 204.10966682434082
Validation loss: 198.1980

-------------------- Epoch 783 --------------------
Train loss: 0.9734
Test loss: 198.09424591064453
Test loss: 204.0040988922119
Validation loss: 198.0942

-------------------- Epoch 784 --------------------
Train loss: 0.9781
Test loss: 198.13886006673178
Test loss: 204.0484619140625
Validation loss: 198.1389

-------------------- Epoch 785 --------------------
Train loss: 0.9756
Test loss: 198.1562557220459
Test loss: 204.06561787923178
Validation loss: 198.1563

-------------------- Epoch 786 --------------------
Train loss: 0.9757
Test loss: 198.1964988708496
Test loss: 204.10588455200195
Validation loss: 198.1965

-------------------- Epoch 787 --------------------
Train loss: 0.9739
Test loss: 198.1657543182373
Test loss: 204.0740795135498
Validation loss: 198.1658

-------------------- Epoch 788 --------------------
Train loss: 0.9708
Test loss: 198.06255849202475
Test loss: 203.9691244761149
New best validation loss: 198.0626, saving model weights to best_model_weights.pth

-------------------- Epoch 789 --------------------
Train loss: 0.9706
Test loss: 198.23112106323242
Test loss: 204.13949394226074
Validation loss: 198.2311

-------------------- Epoch 790 --------------------
Train loss: 0.9724
Test loss: 198.1544278462728
Test loss: 204.06079864501953
Validation loss: 198.1544

-------------------- Epoch 791 --------------------
Train loss: 0.9726
Test loss: 198.15321667989096
Test loss: 204.05894470214844
Validation loss: 198.1532

-------------------- Epoch 792 --------------------
Train loss: 0.9712
Test loss: 198.12911224365234
Test loss: 204.03394635518393
Validation loss: 198.1291

-------------------- Epoch 793 --------------------
Train loss: 0.9760
Test loss: 198.18129857381186
Test loss: 204.08644167582193
Validation loss: 198.1813

-------------------- Epoch 794 --------------------
Train loss: 0.9735
Test loss: 198.03213246663412
Test loss: 203.93463643391928
New best validation loss: 198.0321, saving model weights to best_model_weights.pth

-------------------- Epoch 795 --------------------
Train loss: 0.9713
Test loss: 198.16233698527017
Test loss: 204.06604957580566
Validation loss: 198.1623

-------------------- Epoch 796 --------------------
Train loss: 0.9742
Test loss: 197.90232594807944
Test loss: 203.80253156026205
New best validation loss: 197.9023, saving model weights to best_model_weights.pth

-------------------- Epoch 797 --------------------
Train loss: 0.9741
Test loss: 198.12885348002115
Test loss: 204.03075091044107
Validation loss: 198.1289

-------------------- Epoch 798 --------------------
Train loss: 0.9728
Test loss: 198.12264251708984
Test loss: 204.02393786112467
Validation loss: 198.1226

-------------------- Epoch 799 --------------------
Train loss: 0.9771
Test loss: 198.0726286570231
Test loss: 203.97258694966635
Validation loss: 198.0726

-------------------- Epoch 800 --------------------
Train loss: 0.9737
Test loss: 198.03211212158203
Test loss: 203.93106396993002
Validation loss: 198.0321

-------------------- Epoch 801 --------------------
Train loss: 0.9710
Test loss: 198.11561584472656
Test loss: 204.01507123311362
Validation loss: 198.1156

-------------------- Epoch 802 --------------------
Train loss: 0.9715
Test loss: 198.1152858734131
Test loss: 204.01424280802408
Validation loss: 198.1153

-------------------- Epoch 803 --------------------
Train loss: 0.9743
Test loss: 198.18671035766602
Test loss: 204.08640352884927
Validation loss: 198.1867

-------------------- Epoch 804 --------------------
Train loss: 0.9728
Test loss: 198.0413621266683
Test loss: 203.93796475728354
Validation loss: 198.0414

-------------------- Epoch 805 --------------------
Train loss: 0.9693
Test loss: 197.98417854309082
Test loss: 203.8795134226481
Validation loss: 197.9842

-------------------- Epoch 806 --------------------
Train loss: 0.9726
Test loss: 198.09486134847006
Test loss: 203.991091410319
Validation loss: 198.0949

-------------------- Epoch 807 --------------------
Train loss: 0.9729
Test loss: 198.0346819559733
Test loss: 203.92951202392578
Validation loss: 198.0347

-------------------- Epoch 808 --------------------
Train loss: 0.9734
Test loss: 197.98175048828125
Test loss: 203.8754482269287
Validation loss: 197.9818

-------------------- Epoch 809 --------------------
Train loss: 0.9714
Test loss: 198.0468947092692
Test loss: 203.94075647989908
Validation loss: 198.0469

-------------------- Epoch 810 --------------------
Train loss: 0.9725
Test loss: 198.13815625508627
Test loss: 204.0331179300944
Validation loss: 198.1382

-------------------- Epoch 811 --------------------
Train loss: 0.9725
Test loss: 197.9832623799642
Test loss: 203.87507502237955
Validation loss: 197.9833

-------------------- Epoch 812 --------------------
Train loss: 0.9748
Test loss: 197.97395133972168
Test loss: 203.86506271362305
Validation loss: 197.9740

-------------------- Epoch 813 --------------------
Train loss: 0.9721
Test loss: 198.0205898284912
Test loss: 203.91169039408365
Validation loss: 198.0206

-------------------- Epoch 814 --------------------
Train loss: 0.9722
Test loss: 198.0104662577311
Test loss: 203.90081342061362
Validation loss: 198.0105

-------------------- Epoch 815 --------------------
Train loss: 0.9703
Test loss: 197.9074338277181
Test loss: 203.79607772827148
Validation loss: 197.9074

-------------------- Epoch 816 --------------------
Train loss: 0.9706
Test loss: 197.99139340718588
Test loss: 203.88038317362467
Validation loss: 197.9914

-------------------- Epoch 817 --------------------
Train loss: 0.9701
Test loss: 197.97577285766602
Test loss: 203.86391894022623
Validation loss: 197.9758

-------------------- Epoch 818 --------------------
Train loss: 0.9698
Test loss: 198.05350494384766
Test loss: 203.94246037801108
Validation loss: 198.0535

-------------------- Epoch 819 --------------------
Train loss: 0.9697
Test loss: 197.95458539326987
Test loss: 203.84135945638022
Validation loss: 197.9546

-------------------- Epoch 820 --------------------
Train loss: 0.9705
Test loss: 197.89620971679688
Test loss: 203.78167152404785
New best validation loss: 197.8962, saving model weights to best_model_weights.pth

-------------------- Epoch 821 --------------------
Train loss: 0.9721
Test loss: 197.97297477722168
Test loss: 203.85885302225748
Validation loss: 197.9730

-------------------- Epoch 822 --------------------
Train loss: 0.9710
Test loss: 197.97661972045898
Test loss: 203.86179987589517
Validation loss: 197.9766

-------------------- Epoch 823 --------------------
Train loss: 0.9696
Test loss: 197.9417870839437
Test loss: 203.82597732543945
Validation loss: 197.9418

-------------------- Epoch 824 --------------------
Train loss: 0.9728
Test loss: 197.95214970906576
Test loss: 203.83591588338217
Validation loss: 197.9521

-------------------- Epoch 825 --------------------
Train loss: 0.9719
Test loss: 197.8209025065104
Test loss: 203.7024408976237
New best validation loss: 197.8209, saving model weights to best_model_weights.pth

-------------------- Epoch 826 --------------------
Train loss: 0.9736
Test loss: 197.90614446004233
Test loss: 203.78799438476562
Validation loss: 197.9061

-------------------- Epoch 827 --------------------
Train loss: 0.9733
Test loss: 197.81720987955728
Test loss: 203.6974639892578
New best validation loss: 197.8172, saving model weights to best_model_weights.pth

-------------------- Epoch 828 --------------------
Train loss: 0.9728
Test loss: 197.97825495402017
Test loss: 203.86015510559082
Validation loss: 197.9783

-------------------- Epoch 829 --------------------
Train loss: 0.9713
Test loss: 197.8964049021403
Test loss: 203.7763500213623
Validation loss: 197.8964

-------------------- Epoch 830 --------------------
Train loss: 0.9733
Test loss: 197.85763041178384
Test loss: 203.73674519856772
Validation loss: 197.8576

-------------------- Epoch 831 --------------------
Train loss: 0.9732
Test loss: 197.91419728597006
Test loss: 203.7936166127523
Validation loss: 197.9142

-------------------- Epoch 832 --------------------
Train loss: 0.9705
Test loss: 197.80849075317383
Test loss: 203.68599001566568
New best validation loss: 197.8085, saving model weights to best_model_weights.pth

-------------------- Epoch 833 --------------------
Train loss: 0.9713
Test loss: 197.9886391957601
Test loss: 203.8682950337728
Validation loss: 197.9886

-------------------- Epoch 834 --------------------
Train loss: 0.9689
Test loss: 197.64747746785483
Test loss: 203.5224151611328
New best validation loss: 197.6475, saving model weights to best_model_weights.pth

-------------------- Epoch 835 --------------------
Train loss: 0.9783
Test loss: 198.01606114705405
Test loss: 203.8951161702474
Validation loss: 198.0161

-------------------- Epoch 836 --------------------
Train loss: 0.9734
Test loss: 197.79301389058432
Test loss: 203.66797574361166
Validation loss: 197.7930

-------------------- Epoch 837 --------------------
Train loss: 0.9707
Test loss: 197.78494834899902
Test loss: 203.65920639038086
Validation loss: 197.7849

-------------------- Epoch 838 --------------------
Train loss: 0.9709
Test loss: 197.8123238881429
Test loss: 203.68622016906738
Validation loss: 197.8123

-------------------- Epoch 839 --------------------
Train loss: 0.9713
Test loss: 197.87462107340494
Test loss: 203.74876721700033
Validation loss: 197.8746

-------------------- Epoch 840 --------------------
Train loss: 0.9715
Test loss: 197.88967068990073
Test loss: 203.76368713378906
Validation loss: 197.8897

-------------------- Epoch 841 --------------------
Train loss: 0.9785
Test loss: 197.85134633382162
Test loss: 203.72397168477377
Validation loss: 197.8513

-------------------- Epoch 842 --------------------
Train loss: 0.9741
Test loss: 197.83898480733237
Test loss: 203.71095275878906
Validation loss: 197.8390

-------------------- Epoch 843 --------------------
Train loss: 0.9696
Test loss: 197.8644650777181
Test loss: 203.73609987894693
Validation loss: 197.8645

-------------------- Epoch 844 --------------------
Train loss: 0.9707
Test loss: 197.78532218933105
Test loss: 203.65545018513998
Validation loss: 197.7853

-------------------- Epoch 845 --------------------
Train loss: 0.9718
Test loss: 197.67468388875326
Test loss: 203.543093363444
Validation loss: 197.6747

-------------------- Epoch 846 --------------------
Train loss: 0.9702
Test loss: 197.7641773223877
Test loss: 203.63276163736978
Validation loss: 197.7642

-------------------- Epoch 847 --------------------
Train loss: 0.9738
Test loss: 197.75007502237955
Test loss: 203.6178658803304
Validation loss: 197.7501

-------------------- Epoch 848 --------------------
Train loss: 0.9700
Test loss: 197.76273918151855
Test loss: 203.63025029500326
Validation loss: 197.7627

-------------------- Epoch 849 --------------------
Train loss: 0.9708
Test loss: 197.84306971232095
Test loss: 203.71128273010254
Validation loss: 197.8431

-------------------- Epoch 850 --------------------
Train loss: 0.9711
Test loss: 197.74622599283853
Test loss: 203.61250686645508
Validation loss: 197.7462

-------------------- Epoch 851 --------------------
Train loss: 0.9715
Test loss: 197.8058064778646
Test loss: 203.67233339945474
Validation loss: 197.8058

-------------------- Epoch 852 --------------------
Train loss: 0.9709
Test loss: 197.82599067687988
Test loss: 203.69228299458823
Validation loss: 197.8260

-------------------- Epoch 853 --------------------
Train loss: 0.9727
Test loss: 197.77495702107748
Test loss: 203.63989130655924
Validation loss: 197.7750

-------------------- Epoch 854 --------------------
Train loss: 0.9688
Test loss: 197.8229465484619
Test loss: 203.68818346659342
Validation loss: 197.8229

-------------------- Epoch 855 --------------------
Train loss: 0.9725
Test loss: 197.87051391601562
Test loss: 203.73612276713052
Validation loss: 197.8705

-------------------- Epoch 856 --------------------
Train loss: 0.9706
Test loss: 197.77245394388834
Test loss: 203.6357479095459
Validation loss: 197.7725

-------------------- Epoch 857 --------------------
Train loss: 0.9690
Test loss: 197.77928924560547
Test loss: 203.642115910848
Validation loss: 197.7793

-------------------- Epoch 858 --------------------
Train loss: 0.9718
Test loss: 197.69965426127115
Test loss: 203.5607089996338
Validation loss: 197.6997

-------------------- Epoch 859 --------------------
Train loss: 0.9734
Test loss: 197.58600298563638
Test loss: 203.44548479715982
New best validation loss: 197.5860, saving model weights to best_model_weights.pth

-------------------- Epoch 860 --------------------
Train loss: 0.9760
Test loss: 197.65782101949057
Test loss: 203.51726977030435
Validation loss: 197.6578

-------------------- Epoch 861 --------------------
Train loss: 0.9755
Test loss: 197.6632874806722
Test loss: 203.522216796875
Validation loss: 197.6633

-------------------- Epoch 862 --------------------
Train loss: 0.9698
Test loss: 197.60594367980957
Test loss: 203.46384811401367
Validation loss: 197.6059

-------------------- Epoch 863 --------------------
Train loss: 0.9689
Test loss: 197.59483083089194
Test loss: 203.45210075378418
Validation loss: 197.5948

-------------------- Epoch 864 --------------------
Train loss: 0.9713
Test loss: 197.67042668660483
Test loss: 203.52781422932944
Validation loss: 197.6704

-------------------- Epoch 865 --------------------
Train loss: 0.9718
Test loss: 197.71684074401855
Test loss: 203.57429313659668
Validation loss: 197.7168

-------------------- Epoch 866 --------------------
Train loss: 0.9718
Test loss: 197.6292864481608
Test loss: 203.4851360321045
Validation loss: 197.6293

-------------------- Epoch 867 --------------------
Train loss: 0.9748
Test loss: 197.5956153869629
Test loss: 203.45063273111978
Validation loss: 197.5956

-------------------- Epoch 868 --------------------
Train loss: 0.9721
Test loss: 197.65145619710287
Test loss: 203.5065129597982
Validation loss: 197.6515

-------------------- Epoch 869 --------------------
Train loss: 0.9721
Test loss: 197.5789909362793
Test loss: 203.43278058369955
New best validation loss: 197.5790, saving model weights to best_model_weights.pth

-------------------- Epoch 870 --------------------
Train loss: 0.9712
Test loss: 197.62632179260254
Test loss: 203.47990226745605
Validation loss: 197.6263

-------------------- Epoch 871 --------------------
Train loss: 0.9707
Test loss: 197.6476936340332
Test loss: 203.50097529093424
Validation loss: 197.6477

-------------------- Epoch 872 --------------------
Train loss: 0.9697
Test loss: 197.66389020284018
Test loss: 203.51686731974283
Validation loss: 197.6639

-------------------- Epoch 873 --------------------
Train loss: 0.9694
Test loss: 197.6656068166097
Test loss: 203.51823361714682
Validation loss: 197.6656

-------------------- Epoch 874 --------------------
Train loss: 0.9708
Test loss: 197.6346238454183
Test loss: 203.4862206776937
Validation loss: 197.6346

-------------------- Epoch 875 --------------------
Train loss: 0.9750
Test loss: 197.58877436319986
Test loss: 203.4392433166504
Validation loss: 197.5888

-------------------- Epoch 876 --------------------
Train loss: 0.9682
Test loss: 197.59236780802408
Test loss: 203.44220352172852
Validation loss: 197.5924

-------------------- Epoch 877 --------------------
Train loss: 0.9672
Test loss: 197.67084757486978
Test loss: 203.5213540395101
Validation loss: 197.6708

-------------------- Epoch 878 --------------------
Train loss: 0.9705
Test loss: 197.597136815389
Test loss: 203.446044921875
Validation loss: 197.5971

-------------------- Epoch 879 --------------------
Train loss: 0.9742
Test loss: 197.54468536376953
Test loss: 203.39240582784018
New best validation loss: 197.5447, saving model weights to best_model_weights.pth

-------------------- Epoch 880 --------------------
Train loss: 0.9690
Test loss: 197.5809154510498
Test loss: 203.4285545349121
Validation loss: 197.5809

-------------------- Epoch 881 --------------------
Train loss: 0.9691
Test loss: 197.53756459554037
Test loss: 203.38415018717447
New best validation loss: 197.5376, saving model weights to best_model_weights.pth

-------------------- Epoch 882 --------------------
Train loss: 0.9694
Test loss: 197.5294329325358
Test loss: 203.37548700968424
New best validation loss: 197.5294, saving model weights to best_model_weights.pth

-------------------- Epoch 883 --------------------
Train loss: 0.9701
Test loss: 197.61418851216635
Test loss: 203.46084022521973
Validation loss: 197.6142

-------------------- Epoch 884 --------------------
Train loss: 0.9698
Test loss: 197.49499575297037
Test loss: 203.3394603729248
New best validation loss: 197.4950, saving model weights to best_model_weights.pth

-------------------- Epoch 885 --------------------
Train loss: 0.9677
Test loss: 197.548064549764
Test loss: 203.3926855723063
Validation loss: 197.5481

-------------------- Epoch 886 --------------------
Train loss: 0.9681
Test loss: 197.56041145324707
Test loss: 203.40444819132486
Validation loss: 197.5604

-------------------- Epoch 887 --------------------
Train loss: 0.9684
Test loss: 197.63751475016275
Test loss: 203.4823144276937
Validation loss: 197.6375

-------------------- Epoch 888 --------------------
Train loss: 0.9716
Test loss: 197.60693868001303
Test loss: 203.4505990346273
Validation loss: 197.6069

-------------------- Epoch 889 --------------------
Train loss: 0.9671
Test loss: 197.54851150512695
Test loss: 203.39068794250488
Validation loss: 197.5485

-------------------- Epoch 890 --------------------
Train loss: 0.9683
Test loss: 197.46549606323242
Test loss: 203.30605125427246
New best validation loss: 197.4655, saving model weights to best_model_weights.pth

-------------------- Epoch 891 --------------------
Train loss: 0.9698
Test loss: 197.5357411702474
Test loss: 203.376584370931
Validation loss: 197.5357

-------------------- Epoch 892 --------------------
Train loss: 0.9707
Test loss: 197.42895062764487
Test loss: 203.26815923055014
New best validation loss: 197.4290, saving model weights to best_model_weights.pth

-------------------- Epoch 893 --------------------
Train loss: 0.9739
Test loss: 197.43517939249674
Test loss: 203.2737579345703
Validation loss: 197.4352

-------------------- Epoch 894 --------------------
Train loss: 0.9687
Test loss: 197.44035657246908
Test loss: 203.2783883412679
Validation loss: 197.4404

-------------------- Epoch 895 --------------------
Train loss: 0.9697
Test loss: 197.58515421549478
Test loss: 203.4246451059977
Validation loss: 197.5852

-------------------- Epoch 896 --------------------
Train loss: 0.9675
Test loss: 197.57083129882812
Test loss: 203.40947151184082
Validation loss: 197.5708

-------------------- Epoch 897 --------------------
Train loss: 0.9737
Test loss: 197.48340797424316
Test loss: 203.32028198242188
Validation loss: 197.4834

-------------------- Epoch 898 --------------------
Train loss: 0.9739
Test loss: 197.52372805277506
Test loss: 203.3607546488444
Validation loss: 197.5237

-------------------- Epoch 899 --------------------
Train loss: 0.9741
Test loss: 197.54394149780273
Test loss: 203.38066736857095
Validation loss: 197.5439

-------------------- Epoch 900 --------------------
Train loss: 0.9699
Test loss: 197.52989069620767
Test loss: 203.36583201090494
Validation loss: 197.5299

-------------------- Epoch 901 --------------------
Train loss: 0.9697
Test loss: 197.47886339823404
Test loss: 203.3136043548584
Validation loss: 197.4789

-------------------- Epoch 902 --------------------
Train loss: 1.2186
Test loss: 196.84671020507812
Test loss: 202.67486317952475
New best validation loss: 196.8467, saving model weights to best_model_weights.pth

-------------------- Epoch 903 --------------------
Train loss: 1.4631
Test loss: 195.91322898864746
Test loss: 201.73993682861328
New best validation loss: 195.9132, saving model weights to best_model_weights.pth

-------------------- Epoch 904 --------------------
Train loss: 1.7097
Test loss: 194.24819564819336
Test loss: 200.0850461324056
New best validation loss: 194.2482, saving model weights to best_model_weights.pth

-------------------- Epoch 905 --------------------
Train loss: 1.9433
Test loss: 192.46865018208823
Test loss: 198.31035168965658
New best validation loss: 192.4687, saving model weights to best_model_weights.pth

-------------------- Epoch 906 --------------------
Train loss: 2.1860
Test loss: 190.49187151590982
Test loss: 196.3784211476644
New best validation loss: 190.4919, saving model weights to best_model_weights.pth

-------------------- Epoch 907 --------------------
Train loss: 2.4041
Test loss: 188.47896194458008
Test loss: 194.41264979044595
New best validation loss: 188.4790, saving model weights to best_model_weights.pth

-------------------- Epoch 908 --------------------
Train loss: 2.6379
Test loss: 186.44702847798666
Test loss: 192.3975632985433
New best validation loss: 186.4470, saving model weights to best_model_weights.pth

-------------------- Epoch 909 --------------------
Train loss: 2.8652
Test loss: 184.71573193868002
Test loss: 190.65485699971518
New best validation loss: 184.7157, saving model weights to best_model_weights.pth

-------------------- Epoch 910 --------------------
Train loss: 3.0767
Test loss: 182.70678265889487
Test loss: 188.6306349436442
New best validation loss: 182.7068, saving model weights to best_model_weights.pth

-------------------- Epoch 911 --------------------
Train loss: 3.2931
Test loss: 180.6002629597982
Test loss: 186.4972349802653
New best validation loss: 180.6003, saving model weights to best_model_weights.pth

-------------------- Epoch 912 --------------------
Train loss: 3.4937
Test loss: 178.12805112202963
Test loss: 183.99001185099283
New best validation loss: 178.1281, saving model weights to best_model_weights.pth

-------------------- Epoch 913 --------------------
Train loss: 3.6752
Test loss: 175.26184145609537
Test loss: 181.08155568440756
New best validation loss: 175.2618, saving model weights to best_model_weights.pth

-------------------- Epoch 914 --------------------
Train loss: 3.8493
Test loss: 171.91517130533853
Test loss: 177.6796989440918
New best validation loss: 171.9152, saving model weights to best_model_weights.pth

-------------------- Epoch 915 --------------------
Train loss: 4.0133
Test loss: 167.83934020996094
Test loss: 173.53518994649252
New best validation loss: 167.8393, saving model weights to best_model_weights.pth

-------------------- Epoch 916 --------------------
Train loss: 4.1563
Test loss: 163.16576766967773
Test loss: 168.76662826538086
New best validation loss: 163.1658, saving model weights to best_model_weights.pth

-------------------- Epoch 917 --------------------
Train loss: 4.2743
Test loss: 157.45171292622885
Test loss: 162.9243392944336
New best validation loss: 157.4517, saving model weights to best_model_weights.pth

-------------------- Epoch 918 --------------------
Train loss: 4.3440
Test loss: 149.98152828216553
Test loss: 155.27560965220133
New best validation loss: 149.9815, saving model weights to best_model_weights.pth

-------------------- Epoch 919 --------------------
Train loss: 4.3608
Test loss: 140.2056271235148
Test loss: 145.25070222218832
New best validation loss: 140.2056, saving model weights to best_model_weights.pth

-------------------- Epoch 920 --------------------
Train loss: 4.2647
Test loss: 126.07803916931152
Test loss: 130.72711594899496
New best validation loss: 126.0780, saving model weights to best_model_weights.pth

-------------------- Epoch 921 --------------------
Train loss: 4.0067
Test loss: 103.80863126118977
Test loss: 107.58618545532227
New best validation loss: 103.8086, saving model weights to best_model_weights.pth

-------------------- Epoch 922 --------------------
Train loss: 3.4244
Test loss: 69.14952166875203
Test loss: 70.92849540710449
New best validation loss: 69.1495, saving model weights to best_model_weights.pth

-------------------- Epoch 923 --------------------
Train loss: 2.6205
Test loss: 45.8432567914327
Test loss: 44.47495079040527
New best validation loss: 45.8433, saving model weights to best_model_weights.pth

-------------------- Epoch 924 --------------------
Train loss: 2.1925
Test loss: 32.576171477635704
Test loss: 30.856744289398193
New best validation loss: 32.5762, saving model weights to best_model_weights.pth

-------------------- Epoch 925 --------------------
Train loss: 1.9958
Test loss: 25.99151062965393
Test loss: 23.786739746729534
New best validation loss: 25.9915, saving model weights to best_model_weights.pth

-------------------- Epoch 926 --------------------
Train loss: 1.8588
Test loss: 22.642749428749084
Test loss: 20.478322943051655
New best validation loss: 22.6427, saving model weights to best_model_weights.pth

-------------------- Epoch 927 --------------------
Train loss: 1.8166
Test loss: 19.666600823402405
Test loss: 17.395725965499878
New best validation loss: 19.6666, saving model weights to best_model_weights.pth

-------------------- Epoch 928 --------------------
Train loss: 1.7598
Test loss: 18.009270270665485
Test loss: 15.645730217297872
New best validation loss: 18.0093, saving model weights to best_model_weights.pth

-------------------- Epoch 929 --------------------
Train loss: 1.7608
Test loss: 17.577855149904888
Test loss: 15.281120936075846
New best validation loss: 17.5779, saving model weights to best_model_weights.pth

-------------------- Epoch 930 --------------------
Train loss: 1.8591
Test loss: 33.77965466181437
Test loss: 32.88508971532186
Validation loss: 33.7797

-------------------- Epoch 931 --------------------
Train loss: 1.9306
Test loss: 22.478185335795086
Test loss: 20.4120454788208
Validation loss: 22.4782

-------------------- Epoch 932 --------------------
Train loss: 1.8125
Test loss: 63.69562005996704
Test loss: 64.65764856338501
Validation loss: 63.6956

-------------------- Epoch 933 --------------------
Train loss: 1.9780
Test loss: 18.288354833920796
Test loss: 15.94527260462443
Validation loss: 18.2884

-------------------- Epoch 934 --------------------
Train loss: 2.1793
Test loss: 15.316363056500753
Test loss: 12.87398592631022
New best validation loss: 15.3164, saving model weights to best_model_weights.pth

-------------------- Epoch 935 --------------------
Train loss: 1.8536
Test loss: 14.36562450726827
Test loss: 11.786625862121582
New best validation loss: 14.3656, saving model weights to best_model_weights.pth

-------------------- Epoch 936 --------------------
Train loss: 1.8629
Test loss: 20.584482272466023
Test loss: 18.95952852567037
Validation loss: 20.5845

-------------------- Epoch 937 --------------------
Train loss: 1.9330
Test loss: 15.185727874437967
Test loss: 13.084319233894348
Validation loss: 15.1857

-------------------- Epoch 938 --------------------
Train loss: 1.9079
Test loss: 14.551739692687988
Test loss: 12.033965229988098
Validation loss: 14.5517

-------------------- Epoch 939 --------------------
Train loss: 2.0036
Test loss: 19.348432858784992
Test loss: 17.186710397402447
Validation loss: 19.3484

-------------------- Epoch 940 --------------------
Train loss: 1.7786
Test loss: 24.33704161643982
Test loss: 23.07305359840393
Validation loss: 24.3370

-------------------- Epoch 941 --------------------
Train loss: 1.8705
Test loss: 13.85958961645762
Test loss: 11.86121928691864
New best validation loss: 13.8596, saving model weights to best_model_weights.pth

-------------------- Epoch 942 --------------------
Train loss: 2.0357
Test loss: 12.358621795972189
Test loss: 9.856911619504293
New best validation loss: 12.3586, saving model weights to best_model_weights.pth

-------------------- Epoch 943 --------------------
Train loss: 2.0083
Test loss: 66.96059703826904
Test loss: 67.83156410853069
Validation loss: 66.9606

-------------------- Epoch 944 --------------------
Train loss: 2.2169
Test loss: 12.108957866827646
Test loss: 9.872980038324991
New best validation loss: 12.1090, saving model weights to best_model_weights.pth

-------------------- Epoch 945 --------------------
Train loss: 2.3612
Test loss: 17.97129253546397
Test loss: 16.34634570280711
Validation loss: 17.9713

-------------------- Epoch 946 --------------------
Train loss: 1.7791
Test loss: 15.103547215461731
Test loss: 12.854867299397787
Validation loss: 15.1035

-------------------- Epoch 947 --------------------
Train loss: 2.4391
Test loss: 29.43015996615092
Test loss: 28.653996149698894
Validation loss: 29.4302

-------------------- Epoch 948 --------------------
Train loss: 2.1747
Test loss: 20.540637373924255
Test loss: 19.14897100130717
Validation loss: 20.5406

-------------------- Epoch 949 --------------------
Train loss: 1.9512
Test loss: 15.610738277435303
Test loss: 13.847149809201559
Validation loss: 15.6107

-------------------- Epoch 950 --------------------
Train loss: 2.0872
Test loss: 11.829671422640482
Test loss: 9.466586748758951
New best validation loss: 11.8297, saving model weights to best_model_weights.pth

-------------------- Epoch 951 --------------------
Train loss: 2.2643
Test loss: 22.121988375981648
Test loss: 20.171305894851685
Validation loss: 22.1220

-------------------- Epoch 952 --------------------
Train loss: 2.2681
Test loss: 14.438213388125101
Test loss: 12.184255560239157
Validation loss: 14.4382

-------------------- Epoch 953 --------------------
Train loss: 2.0685
Test loss: 20.290037155151367
Test loss: 18.87243429819743
Validation loss: 20.2900

-------------------- Epoch 954 --------------------
Train loss: 2.2973
Test loss: 17.77691940466563
Test loss: 16.194908261299133
Validation loss: 17.7769

-------------------- Epoch 955 --------------------
Train loss: 2.0671
Test loss: 10.137112061182657
Test loss: 7.903621256351471
New best validation loss: 10.1371, saving model weights to best_model_weights.pth

-------------------- Epoch 956 --------------------
Train loss: 2.1725
Test loss: 13.48450662692388
Test loss: 11.830251177151998
Validation loss: 13.4845

-------------------- Epoch 957 --------------------
Train loss: 2.2500
Test loss: 18.25469144185384
Test loss: 16.257022460301716
Validation loss: 18.2547

-------------------- Epoch 958 --------------------
Train loss: 2.6490
Test loss: 60.736027240753174
Test loss: 61.49452034632365
Validation loss: 60.7360

-------------------- Epoch 959 --------------------
Train loss: 2.3688
Test loss: 10.335840781529745
Test loss: 8.083073198795319
Validation loss: 10.3358

-------------------- Epoch 960 --------------------
Train loss: 1.9420
Test loss: 21.789281845092773
Test loss: 20.23839791615804
Validation loss: 21.7893

-------------------- Epoch 961 --------------------
Train loss: 1.9746
Test loss: 12.528196175893148
Test loss: 10.271713852882385
Validation loss: 12.5282

-------------------- Epoch 962 --------------------
Train loss: 2.2210
Test loss: 12.661348144213358
Test loss: 10.57158374786377
Validation loss: 12.6613

-------------------- Epoch 963 --------------------
Train loss: 2.0992
Test loss: 9.722701450188955
Test loss: 7.549681504567464
New best validation loss: 9.7227, saving model weights to best_model_weights.pth

-------------------- Epoch 964 --------------------
Train loss: 2.5163
Test loss: 10.999492744604746
Test loss: 9.022243638833364
Validation loss: 10.9995

-------------------- Epoch 965 --------------------
Train loss: 2.5082
Test loss: 31.339659293492634
Test loss: 30.016978184382122
Validation loss: 31.3397

-------------------- Epoch 966 --------------------
Train loss: 2.3844
Test loss: 27.53016185760498
Test loss: 26.083648602167766
Validation loss: 27.5302

-------------------- Epoch 967 --------------------
Train loss: 1.9346
Test loss: 8.881036162376404
Test loss: 6.704530636469523
New best validation loss: 8.8810, saving model weights to best_model_weights.pth

-------------------- Epoch 968 --------------------
Train loss: 2.0645
Test loss: 14.11686603228251
Test loss: 12.232293407122294
Validation loss: 14.1169

-------------------- Epoch 969 --------------------
Train loss: 2.7974
Test loss: 13.067703286806742
Test loss: 11.733131170272827
Validation loss: 13.0677

-------------------- Epoch 970 --------------------
Train loss: 2.3730
Test loss: 20.191623767217
Test loss: 19.172035058339436
Validation loss: 20.1916

-------------------- Epoch 971 --------------------
Train loss: 2.1278
Test loss: 14.902093211809794
Test loss: 13.405499339103699
Validation loss: 14.9021

-------------------- Epoch 972 --------------------
Train loss: 1.9864
Test loss: 25.291436592737835
Test loss: 23.97945284843445
Validation loss: 25.2914

-------------------- Epoch 973 --------------------
Train loss: 2.0228
Test loss: 13.936611890792847
Test loss: 11.965228279431662
Validation loss: 13.9366

-------------------- Epoch 974 --------------------
Train loss: 2.6651
Test loss: 11.753981073697409
Test loss: 9.795678655306498
Validation loss: 11.7540

-------------------- Epoch 975 --------------------
Train loss: 2.1826
Test loss: 28.664825518925984
Test loss: 27.39534616470337
Validation loss: 28.6648

-------------------- Epoch 976 --------------------
Train loss: 2.7586
Test loss: 18.92874546845754
Test loss: 17.2753510872523
Validation loss: 18.9287

-------------------- Epoch 977 --------------------
Train loss: 2.0981
Test loss: 8.232061525185904
Test loss: 6.079225242137909
New best validation loss: 8.2321, saving model weights to best_model_weights.pth

-------------------- Epoch 978 --------------------
Train loss: 2.5839
Test loss: 26.727954387664795
Test loss: 26.041869640350342
Validation loss: 26.7280

-------------------- Epoch 979 --------------------
Train loss: 2.6671
Test loss: 8.105868260065714
Test loss: 6.022037625312805
New best validation loss: 8.1059, saving model weights to best_model_weights.pth

-------------------- Epoch 980 --------------------
Train loss: 1.8351
Test loss: 8.096583088239035
Test loss: 6.027312556902568
New best validation loss: 8.0966, saving model weights to best_model_weights.pth

-------------------- Epoch 981 --------------------
Train loss: 2.2292
Test loss: 14.961104909578959
Test loss: 13.734966158866882
Validation loss: 14.9611

-------------------- Epoch 982 --------------------
Train loss: 2.6905
Test loss: 35.29300991694132
Test loss: 34.45510292053223
Validation loss: 35.2930

-------------------- Epoch 983 --------------------
Train loss: 2.2706
Test loss: 41.33232720692953
Test loss: 40.66860167185465
Validation loss: 41.3323

-------------------- Epoch 984 --------------------
Train loss: 2.8282
Test loss: 16.395615458488464
Test loss: 15.300466895103455
Validation loss: 16.3956

-------------------- Epoch 985 --------------------
Train loss: 2.3253
Test loss: 15.178635915120443
Test loss: 13.845946113268534
Validation loss: 15.1786

-------------------- Epoch 986 --------------------
Train loss: 2.5387
Test loss: 8.430150111516317
Test loss: 6.514641284942627
Validation loss: 8.4302

-------------------- Epoch 987 --------------------
Train loss: 2.5406
Test loss: 16.244319438934326
Test loss: 15.167502482732138
Validation loss: 16.2443

-------------------- Epoch 988 --------------------
Train loss: 2.2679
Test loss: 20.818015654881794
Test loss: 19.573549111684162
Validation loss: 20.8180

-------------------- Epoch 989 --------------------
Train loss: 2.5831
Test loss: 17.811823844909668
Test loss: 16.35415454705556
Validation loss: 17.8118

-------------------- Epoch 990 --------------------
Train loss: 2.5993
Test loss: 35.28472884496053
Test loss: 34.707789182662964
Validation loss: 35.2847

-------------------- Epoch 991 --------------------
Train loss: 2.6189
Test loss: 22.551467180252075
Test loss: 22.01351507504781
Validation loss: 22.5515

-------------------- Epoch 992 --------------------
Train loss: 2.5934
Test loss: 18.395180344581604
Test loss: 16.913097540537517
Validation loss: 18.3952

-------------------- Epoch 993 --------------------
Train loss: 2.4624
Test loss: 13.77437929312388
Test loss: 12.677419662475586
Validation loss: 13.7744

-------------------- Epoch 994 --------------------
Train loss: 2.6361
Test loss: 14.121405522028605
Test loss: 12.993948022524515
Validation loss: 14.1214

-------------------- Epoch 995 --------------------
Train loss: 2.5235
Test loss: 21.911383469899494
Test loss: 21.37296724319458
Validation loss: 21.9114

-------------------- Epoch 996 --------------------
Train loss: 2.2418
Test loss: 9.995052893956503
Test loss: 8.289486328760782
Validation loss: 9.9951

-------------------- Epoch 997 --------------------
Train loss: 2.0917
Test loss: 13.399882515271505
Test loss: 12.000137209892273
Validation loss: 13.3999

-------------------- Epoch 998 --------------------
Train loss: 2.5645
Test loss: 7.6268609166145325
Test loss: 6.1431025465329485
New best validation loss: 7.6269, saving model weights to best_model_weights.pth

-------------------- Epoch 999 --------------------
Train loss: 2.6217
Test loss: 8.676346043745676
Test loss: 6.93570061524709
Validation loss: 8.6763

-------------------- Epoch 1000 --------------------
Train loss: 2.3767
Test loss: 10.50352774063746
Test loss: 9.28452354669571
Validation loss: 10.5035

-------------------- Epoch 1001 --------------------
Train loss: 2.3474
Test loss: 10.20528531074524
Test loss: 8.939511398474375
Validation loss: 10.2053

-------------------- Epoch 1002 --------------------
Train loss: 3.3665
Test loss: 8.8133731285731
Test loss: 7.1236425836881
Validation loss: 8.8134

-------------------- Epoch 1003 --------------------
Train loss: 2.3368
Test loss: 8.409529745578766
Test loss: 6.773828248182933
Validation loss: 8.4095

-------------------- Epoch 1004 --------------------
Train loss: 2.3678
Test loss: 30.104192972183228
Test loss: 29.27245839436849
Validation loss: 30.1042

-------------------- Epoch 1005 --------------------
Train loss: 2.3369
Test loss: 11.269857486089071
Test loss: 10.300716598828634
Validation loss: 11.2699

-------------------- Epoch 1006 --------------------
Train loss: 2.4225
Test loss: 6.952252308527629
Test loss: 5.4990232189496355
New best validation loss: 6.9523, saving model weights to best_model_weights.pth

-------------------- Epoch 1007 --------------------
Train loss: 2.6350
Test loss: 16.383358200391132
Test loss: 15.075790325800577
Validation loss: 16.3834

-------------------- Epoch 1008 --------------------
Train loss: 2.4551
Test loss: 15.18144408861796
Test loss: 13.931034763654074
Validation loss: 15.1814

-------------------- Epoch 1009 --------------------
Train loss: 2.9762
Test loss: 15.213948885599772
Test loss: 14.010987679163614
Validation loss: 15.2139

-------------------- Epoch 1010 --------------------
Train loss: 2.1450
Test loss: 29.32798933982849
Test loss: 28.684911568959553
Validation loss: 29.3280

-------------------- Epoch 1011 --------------------
Train loss: 2.5808
Test loss: 7.842888871828715
Test loss: 6.630090634028117
Validation loss: 7.8429

-------------------- Epoch 1012 --------------------
Train loss: 3.3466
Test loss: 17.940608382225037
Test loss: 17.004618962605793
Validation loss: 17.9406

-------------------- Epoch 1013 --------------------
Train loss: 3.3311
Test loss: 11.018065373102823
Test loss: 9.646165748437246
Validation loss: 11.0181

-------------------- Epoch 1014 --------------------
Train loss: 2.7378
Test loss: 7.2410451372464495
Test loss: 5.6543429891268415
Validation loss: 7.2410

-------------------- Epoch 1015 --------------------
Train loss: 2.2900
Test loss: 15.571030418078104
Test loss: 14.53588835398356
Validation loss: 15.5710

-------------------- Epoch 1016 --------------------
Train loss: 2.6456
Test loss: 17.485912919044495
Test loss: 16.51058332125346
Validation loss: 17.4859

-------------------- Epoch 1017 --------------------
Train loss: 2.1567
Test loss: 13.673100233078003
Test loss: 12.98330040772756
Validation loss: 13.6731

-------------------- Epoch 1018 --------------------
Train loss: 2.6734
Test loss: 13.513365705808004
Test loss: 12.467428962389628
Validation loss: 13.5134

-------------------- Epoch 1019 --------------------
Train loss: 2.5378
Test loss: 15.103925307591757
Test loss: 14.206965406735739
Validation loss: 15.1039

-------------------- Epoch 1020 --------------------
Train loss: 2.3990
Test loss: 6.148281733194987
Test loss: 4.748658229907353
New best validation loss: 6.1483, saving model weights to best_model_weights.pth

-------------------- Epoch 1021 --------------------
Train loss: 2.6357
Test loss: 5.87279486656189
Test loss: 4.598699649175008
New best validation loss: 5.8728, saving model weights to best_model_weights.pth

-------------------- Epoch 1022 --------------------
Train loss: 2.4554
Test loss: 6.223979324102402
Test loss: 4.993523518244426
Validation loss: 6.2240

-------------------- Epoch 1023 --------------------
Train loss: 2.6597
Test loss: 29.20838173230489
Test loss: 29.1444890499115
Validation loss: 29.2084

-------------------- Epoch 1024 --------------------
Train loss: 3.1274
Test loss: 14.339690089225769
Test loss: 13.719916502634684
Validation loss: 14.3397

-------------------- Epoch 1025 --------------------
Train loss: 2.6386
Test loss: 5.581478118896484
Test loss: 4.245312710603078
New best validation loss: 5.5815, saving model weights to best_model_weights.pth

-------------------- Epoch 1026 --------------------
Train loss: 2.2411
Test loss: 8.959028919537863
Test loss: 8.026844143867493
Validation loss: 8.9590

-------------------- Epoch 1027 --------------------
Train loss: 2.2493
Test loss: 15.527001659075419
Test loss: 14.739020744959513
Validation loss: 15.5270

-------------------- Epoch 1028 --------------------
Train loss: 2.6633
Test loss: 30.647955020268757
Test loss: 30.482561190923054
Validation loss: 30.6480

-------------------- Epoch 1029 --------------------
Train loss: 2.3749
Test loss: 7.950760821501414
Test loss: 6.72651884953181
Validation loss: 7.9508

-------------------- Epoch 1030 --------------------
Train loss: 2.8855
Test loss: 13.315705815951029
Test loss: 12.638214151064554
Validation loss: 13.3157

-------------------- Epoch 1031 --------------------
Train loss: 2.4102
Test loss: 5.537308047215144
Test loss: 4.239541381597519
New best validation loss: 5.5373, saving model weights to best_model_weights.pth

-------------------- Epoch 1032 --------------------
Train loss: 2.7436
Test loss: 16.37961546579997
Test loss: 15.71655809879303
Validation loss: 16.3796

-------------------- Epoch 1033 --------------------
Train loss: 3.0006
Test loss: 12.058214783668518
Test loss: 11.426192084948221
Validation loss: 12.0582

-------------------- Epoch 1034 --------------------
Train loss: 2.3314
Test loss: 5.053800145785014
Test loss: 3.89726456006368
New best validation loss: 5.0538, saving model weights to best_model_weights.pth

-------------------- Epoch 1035 --------------------
Train loss: 2.6334
Test loss: 12.2617400487264
Test loss: 11.577017943064371
Validation loss: 12.2617

-------------------- Epoch 1036 --------------------
Train loss: 2.1851
Test loss: 11.850913484891256
Test loss: 10.918990890185038
Validation loss: 11.8509

-------------------- Epoch 1037 --------------------
Train loss: 2.5284
Test loss: 14.114810307820639
Test loss: 13.532897790273031
Validation loss: 14.1148

-------------------- Epoch 1038 --------------------
Train loss: 2.9679
Test loss: 5.922254969676335
Test loss: 4.841434607903163
Validation loss: 5.9223

-------------------- Epoch 1039 --------------------
Train loss: 3.0593
Test loss: 15.159634033838907
Test loss: 14.223490715026855
Validation loss: 15.1596

-------------------- Epoch 1040 --------------------
Train loss: 2.7049
Test loss: 11.90501836935679
Test loss: 11.371135115623474
Validation loss: 11.9050

-------------------- Epoch 1041 --------------------
Train loss: 2.4026
Test loss: 10.447928587595621
Test loss: 9.525160113970438
Validation loss: 10.4479

-------------------- Epoch 1042 --------------------
Train loss: 2.6336
Test loss: 8.345320721467337
Test loss: 7.633477369944255
Validation loss: 8.3453

-------------------- Epoch 1043 --------------------
Train loss: 3.4156
Test loss: 7.327405909697215
Test loss: 6.381290952364604
Validation loss: 7.3274

-------------------- Epoch 1044 --------------------
Train loss: 2.5254
Test loss: 15.121969938278198
Test loss: 14.41862690448761
Validation loss: 15.1220

-------------------- Epoch 1045 --------------------
Train loss: 2.5637
Test loss: 9.336309850215912
Test loss: 8.42475281159083
Validation loss: 9.3363

-------------------- Epoch 1046 --------------------
Train loss: 2.5606
Test loss: 5.196186731259028
Test loss: 4.112060248851776
Validation loss: 5.1962

-------------------- Epoch 1047 --------------------
Train loss: 2.4191
Test loss: 5.884349544843038
Test loss: 4.935892750819524
Validation loss: 5.8843

-------------------- Epoch 1048 --------------------
Train loss: 2.5992
Test loss: 12.366581519444784
Test loss: 11.511268973350525
Validation loss: 12.3666

-------------------- Epoch 1049 --------------------
Train loss: 3.2112
Test loss: 8.603274941444397
Test loss: 7.861386934916179
Validation loss: 8.6033

-------------------- Epoch 1050 --------------------
Train loss: 2.5128
Test loss: 7.0407870809237165
Test loss: 6.097046673297882
Validation loss: 7.0408

-------------------- Epoch 1051 --------------------
Train loss: 2.4565
Test loss: 9.32974362373352
Test loss: 8.483906666437784
Validation loss: 9.3297

-------------------- Epoch 1052 --------------------
Train loss: 3.5055
Test loss: 6.491060694058736
Test loss: 5.452554384867351
Validation loss: 6.4911

-------------------- Epoch 1053 --------------------
Train loss: 2.3954
Test loss: 22.491658846537273
Test loss: 22.052438259124756
Validation loss: 22.4917

-------------------- Epoch 1054 --------------------
Train loss: 3.0269
Test loss: 8.724964459737143
Test loss: 7.740078687667847
Validation loss: 8.7250

-------------------- Epoch 1055 --------------------
Train loss: 2.8133
Test loss: 15.42081614335378
Test loss: 14.738191405932108
Validation loss: 15.4208

-------------------- Epoch 1056 --------------------
Train loss: 2.8589
Test loss: 7.480495750904083
Test loss: 6.477653046449025
Validation loss: 7.4805

-------------------- Epoch 1057 --------------------
Train loss: 2.8380
Test loss: 11.502212842305502
Test loss: 10.718067725499472
Validation loss: 11.5022

-------------------- Epoch 1058 --------------------
Train loss: 3.4910
Test loss: 4.687040209770203
Test loss: 3.7092944780985513
New best validation loss: 4.6870, saving model weights to best_model_weights.pth

-------------------- Epoch 1059 --------------------
Train loss: 2.5413
Test loss: 26.017578442891438
Test loss: 26.10218119621277
Validation loss: 26.0176

-------------------- Epoch 1060 --------------------
Train loss: 4.2783
Test loss: 13.762529770533243
Test loss: 13.482362469037374
Validation loss: 13.7625

-------------------- Epoch 1061 --------------------
Train loss: 2.4518
Test loss: 7.876921196778615
Test loss: 7.364802499612172
Validation loss: 7.8769

-------------------- Epoch 1062 --------------------
Train loss: 2.7480
Test loss: 9.959548910458883
Test loss: 9.474713365236918
Validation loss: 9.9595

-------------------- Epoch 1063 --------------------
Train loss: 2.9513
Test loss: 4.723410129547119
Test loss: 3.7194914519786835
Validation loss: 4.7234

-------------------- Epoch 1064 --------------------
Train loss: 2.7567
Test loss: 8.27287099758784
Test loss: 7.489596724510193
Validation loss: 8.2729

-------------------- Epoch 1065 --------------------
Train loss: 2.5208
Test loss: 5.592421700557073
Test loss: 4.799674242734909
Validation loss: 5.5924

-------------------- Epoch 1066 --------------------
Train loss: 2.3505
Test loss: 7.792994062105815
Test loss: 7.054363012313843
Validation loss: 7.7930

-------------------- Epoch 1067 --------------------
Train loss: 2.2446
Test loss: 5.844129363695781
Test loss: 5.094748437404633
Validation loss: 5.8441

-------------------- Epoch 1068 --------------------
Train loss: 3.0534
Test loss: 5.181666046380997
Test loss: 4.557261695464452
Validation loss: 5.1817

-------------------- Epoch 1069 --------------------
Train loss: 2.5139
Test loss: 5.5865573187669115
Test loss: 4.866293291250865
Validation loss: 5.5866

-------------------- Epoch 1070 --------------------
Train loss: 2.5214
Test loss: 21.707796176274616
Test loss: 21.69335349400838
Validation loss: 21.7078

-------------------- Epoch 1071 --------------------
Train loss: 2.6517
Test loss: 6.4434478878974915
Test loss: 5.759232183297475
Validation loss: 6.4434

-------------------- Epoch 1072 --------------------
Train loss: 3.2936
Test loss: 4.505768458048503
Test loss: 3.8392289678255715
New best validation loss: 4.5058, saving model weights to best_model_weights.pth

-------------------- Epoch 1073 --------------------
Train loss: 2.8818
Test loss: 4.477581262588501
Test loss: 3.7240886787573495
New best validation loss: 4.4776, saving model weights to best_model_weights.pth

-------------------- Epoch 1074 --------------------
Train loss: 2.4213
Test loss: 8.736379226048788
Test loss: 8.080388188362122
Validation loss: 8.7364

-------------------- Epoch 1075 --------------------
Train loss: 3.0374
Test loss: 7.426638921101888
Test loss: 6.915492415428162
Validation loss: 7.4266

-------------------- Epoch 1076 --------------------
Train loss: 3.0224
Test loss: 16.219344973564148
Test loss: 15.811244487762451
Validation loss: 16.2193

-------------------- Epoch 1077 --------------------
Train loss: 2.8933
Test loss: 15.195046663284302
Test loss: 14.878111322720846
Validation loss: 15.1950

-------------------- Epoch 1078 --------------------
Train loss: 2.4804
Test loss: 5.012234836816788
Test loss: 4.304982056220372
Validation loss: 5.0122

-------------------- Epoch 1079 --------------------
Train loss: 2.5179
Test loss: 4.144444316625595
Test loss: 3.47355717420578
New best validation loss: 4.1444, saving model weights to best_model_weights.pth

-------------------- Epoch 1080 --------------------
Train loss: 2.3864
Test loss: 4.388442873954773
Test loss: 3.5940775175889335
Validation loss: 4.3884

-------------------- Epoch 1081 --------------------
Train loss: 2.1744
Test loss: 12.231341560681662
Test loss: 11.826999505360922
Validation loss: 12.2313

-------------------- Epoch 1082 --------------------
Train loss: 3.2147
Test loss: 3.7067655523618064
Test loss: 3.0805315176645913
New best validation loss: 3.7068, saving model weights to best_model_weights.pth

-------------------- Epoch 1083 --------------------
Train loss: 2.2975
Test loss: 9.479179521401724
Test loss: 9.010175208250681
Validation loss: 9.4792

-------------------- Epoch 1084 --------------------
Train loss: 3.1693
Test loss: 4.822106907765071
Test loss: 4.170190821091334
Validation loss: 4.8221

-------------------- Epoch 1085 --------------------
Train loss: 2.8723
Test loss: 4.321100701888402
Test loss: 3.7130460143089294
Validation loss: 4.3211

-------------------- Epoch 1086 --------------------
Train loss: 2.6501
Test loss: 5.843549569447835
Test loss: 5.438497980435689
Validation loss: 5.8435

-------------------- Epoch 1087 --------------------
Train loss: 2.8034
Test loss: 13.21836225191752
Test loss: 12.85043195883433
Validation loss: 13.2184

-------------------- Epoch 1088 --------------------
Train loss: 2.8973
Test loss: 9.1443882783254
Test loss: 8.687396685282389
Validation loss: 9.1444

-------------------- Epoch 1089 --------------------
Train loss: 2.9876
Test loss: 4.334278891483943
Test loss: 3.7917719582716622
Validation loss: 4.3343

-------------------- Epoch 1090 --------------------
Train loss: 2.5179
Test loss: 7.049856921037038
Test loss: 6.704189558823903
Validation loss: 7.0499

-------------------- Epoch 1091 --------------------
Train loss: 2.8582
Test loss: 4.5857827464739485
Test loss: 4.085833857456843
Validation loss: 4.5858

-------------------- Epoch 1092 --------------------
Train loss: 2.4858
Test loss: 7.627049048741658
Test loss: 7.333276629447937
Validation loss: 7.6270

-------------------- Epoch 1093 --------------------
Train loss: 2.5752
Test loss: 4.2967095871766405
Test loss: 3.670437882343928
Validation loss: 4.2967

-------------------- Epoch 1094 --------------------
Train loss: 2.6230
Test loss: 6.719539741675059
Test loss: 6.438374996185303
Validation loss: 6.7195

-------------------- Epoch 1095 --------------------
Train loss: 2.5215
Test loss: 6.293402473131816
Test loss: 5.87243523200353
Validation loss: 6.2934

-------------------- Epoch 1096 --------------------
Train loss: 3.2971
Test loss: 35.45856952667236
Test loss: 35.76401662826538
Validation loss: 35.4586

-------------------- Epoch 1097 --------------------
Train loss: 2.7595
Test loss: 4.887292305628459
Test loss: 4.225518733263016
Validation loss: 4.8873

-------------------- Epoch 1098 --------------------
Train loss: 2.7745
Test loss: 16.046085913976032
Test loss: 15.992085854212442
Validation loss: 16.0461

-------------------- Epoch 1099 --------------------
Train loss: 2.6884
Test loss: 5.605439861615499
Test loss: 5.22755624850591
Validation loss: 5.6054

-------------------- Epoch 1100 --------------------
Train loss: 2.6563
Test loss: 4.165715883175532
Test loss: 3.6118325293064117
Validation loss: 4.1657

-------------------- Epoch 1101 --------------------
Train loss: 2.3852
Test loss: 5.934233129024506
Test loss: 5.530106027921041
Validation loss: 5.9342

-------------------- Epoch 1102 --------------------
Train loss: 2.6965
Test loss: 21.3816290696462
Test loss: 21.38367748260498
Validation loss: 21.3816

-------------------- Epoch 1103 --------------------
Train loss: 2.9086
Test loss: 8.090485592683157
Test loss: 7.85182664791743
Validation loss: 8.0905

-------------------- Epoch 1104 --------------------
Train loss: 2.7125
Test loss: 4.3254106144110365
Test loss: 3.7836079200108848
Validation loss: 4.3254

-------------------- Epoch 1105 --------------------
Train loss: 2.3231
Test loss: 3.411572208007177
Test loss: 2.8812757432460785
New best validation loss: 3.4116, saving model weights to best_model_weights.pth

-------------------- Epoch 1106 --------------------
Train loss: 2.5171
Test loss: 3.2135600397984185
Test loss: 2.6895612527926764
New best validation loss: 3.2136, saving model weights to best_model_weights.pth

-------------------- Epoch 1107 --------------------
Train loss: 2.4752
Test loss: 13.172830780347189
Test loss: 13.064608971277872
Validation loss: 13.1728

-------------------- Epoch 1108 --------------------
Train loss: 2.9420
Test loss: 3.989070415496826
Test loss: 3.341103285551071
Validation loss: 3.9891

-------------------- Epoch 1109 --------------------
Train loss: 3.1782
Test loss: 7.805664459864299
Test loss: 7.577811360359192
Validation loss: 7.8057

-------------------- Epoch 1110 --------------------
Train loss: 2.2268
Test loss: 7.147268692652385
Test loss: 6.747413138548533
Validation loss: 7.1473

-------------------- Epoch 1111 --------------------
Train loss: 3.3756
Test loss: 4.369828820228577
Test loss: 3.966538985570272
Validation loss: 4.3698

-------------------- Epoch 1112 --------------------
Train loss: 2.5013
Test loss: 3.8965386549631753
Test loss: 3.4775740802288055
Validation loss: 3.8965

-------------------- Epoch 1113 --------------------
Train loss: 2.5797
Test loss: 5.435682008663814
Test loss: 4.972856283187866
Validation loss: 5.4357

-------------------- Epoch 1114 --------------------
Train loss: 2.4741
Test loss: 3.7167953650156655
Test loss: 3.3162341316541037
Validation loss: 3.7168

-------------------- Epoch 1115 --------------------
Train loss: 2.8420
Test loss: 4.381112764279048
Test loss: 3.923479348421097
Validation loss: 4.3811

-------------------- Epoch 1116 --------------------
Train loss: 2.6040
Test loss: 7.383311967055003
Test loss: 6.8852574825286865
Validation loss: 7.3833

-------------------- Epoch 1117 --------------------
Train loss: 2.6361
Test loss: 6.209550062815349
Test loss: 5.63072254260381
Validation loss: 6.2096

-------------------- Epoch 1118 --------------------
Train loss: 2.7674
Test loss: 10.175374627113342
Test loss: 10.121052304903666
Validation loss: 10.1754

-------------------- Epoch 1119 --------------------
Train loss: 2.7837
Test loss: 10.437278985977173
Test loss: 10.345710158348083
Validation loss: 10.4373

-------------------- Epoch 1120 --------------------
Train loss: 2.5933
Test loss: 3.4681791365146637
Test loss: 2.959669460852941
Validation loss: 3.4682

-------------------- Epoch 1121 --------------------
Train loss: 2.5103
Test loss: 9.93577629327774
Test loss: 9.729335824648539
Validation loss: 9.9358

-------------------- Epoch 1122 --------------------
Train loss: 2.4931
Test loss: 6.927804847558339
Test loss: 6.506024479866028
Validation loss: 6.9278

-------------------- Epoch 1123 --------------------
Train loss: 2.2271
Test loss: 7.39922692378362
Test loss: 7.1248050928115845
Validation loss: 7.3992

-------------------- Epoch 1124 --------------------
Train loss: 2.5652
Test loss: 6.1164911190668745
Test loss: 5.6981096267700195
Validation loss: 6.1165

-------------------- Epoch 1125 --------------------
Train loss: 2.5975
Test loss: 9.35846577088038
Test loss: 9.036133527755737
Validation loss: 9.3585

-------------------- Epoch 1126 --------------------
Train loss: 2.4174
Test loss: 6.283497770627339
Test loss: 5.897470831871033
Validation loss: 6.2835

-------------------- Epoch 1127 --------------------
Train loss: 2.7066
Test loss: 5.832327683766683
Test loss: 5.422581235567729
Validation loss: 5.8323

-------------------- Epoch 1128 --------------------
Train loss: 2.2864
Test loss: 7.296525915463765
Test loss: 7.154411633809407
Validation loss: 7.2965

-------------------- Epoch 1129 --------------------
Train loss: 2.7322
Test loss: 7.815427978833516
Test loss: 7.604849656422933
Validation loss: 7.8154

-------------------- Epoch 1130 --------------------
Train loss: 2.2017
Test loss: 4.9561812579631805
Test loss: 4.472104360659917
Validation loss: 4.9562

-------------------- Epoch 1131 --------------------
Train loss: 2.3993
Test loss: 6.661075989405314
Test loss: 6.323192854722341
Validation loss: 6.6611

-------------------- Epoch 1132 --------------------
Train loss: 2.5165
Test loss: 3.1977836589018502
Test loss: 2.7797088672717414
New best validation loss: 3.1978, saving model weights to best_model_weights.pth

-------------------- Epoch 1133 --------------------
Train loss: 2.7330
Test loss: 5.301298340161641
Test loss: 5.018104334672292
Validation loss: 5.3013

-------------------- Epoch 1134 --------------------
Train loss: 2.5664
Test loss: 5.28472716609637
Test loss: 5.068213939666748
Validation loss: 5.2847

-------------------- Epoch 1135 --------------------
Train loss: 3.5974
Test loss: 14.159595171610514
Test loss: 14.091113209724426
Validation loss: 14.1596

-------------------- Epoch 1136 --------------------
Train loss: 3.8889
Test loss: 15.637527704238892
Test loss: 15.600227157274881
Validation loss: 15.6375

-------------------- Epoch 1137 --------------------
Train loss: 2.9398
Test loss: 5.7054324348767596
Test loss: 5.416414260864258
Validation loss: 5.7054

-------------------- Epoch 1138 --------------------
Train loss: 2.5314
Test loss: 9.755689342816671
Test loss: 9.56822899977366
Validation loss: 9.7557

-------------------- Epoch 1139 --------------------
Train loss: 3.0534
Test loss: 3.5842220783233643
Test loss: 3.1628219187259674
Validation loss: 3.5842

-------------------- Epoch 1140 --------------------
Train loss: 3.3681
Test loss: 8.661298712094625
Test loss: 8.403987805048624
Validation loss: 8.6613

-------------------- Epoch 1141 --------------------
Train loss: 2.6325
Test loss: 6.067539433638255
Test loss: 5.89655480782191
Validation loss: 6.0675

-------------------- Epoch 1142 --------------------
Train loss: 3.2038
Test loss: 8.176294445991516
Test loss: 7.977983812491099
Validation loss: 8.1763

-------------------- Epoch 1143 --------------------
Train loss: 2.7751
Test loss: 3.170829544464747
Test loss: 2.856727888186773
New best validation loss: 3.1708, saving model weights to best_model_weights.pth

-------------------- Epoch 1144 --------------------
Train loss: 2.4101
Test loss: 7.947344402472178
Test loss: 7.8924252192179365
Validation loss: 7.9473

-------------------- Epoch 1145 --------------------
Train loss: 2.6061
Test loss: 3.3051649729410806
Test loss: 2.9851465622584024
Validation loss: 3.3052

-------------------- Epoch 1146 --------------------
Train loss: 2.7583
Test loss: 6.114577035109202
Test loss: 5.912486473719279
Validation loss: 6.1146

-------------------- Epoch 1147 --------------------
Train loss: 2.3626
Test loss: 6.501024842262268
Test loss: 6.334697425365448
Validation loss: 6.5010

-------------------- Epoch 1148 --------------------
Train loss: 2.7245
Test loss: 8.920145253340403
Test loss: 8.686484853426615
Validation loss: 8.9201

-------------------- Epoch 1149 --------------------
Train loss: 2.4849
Test loss: 3.621380557616552
Test loss: 3.2803418139616647
Validation loss: 3.6214

-------------------- Epoch 1150 --------------------
Train loss: 2.6145
Test loss: 11.720834771792093
Test loss: 11.651922941207886
Validation loss: 11.7208

-------------------- Epoch 1151 --------------------
Train loss: 2.8136
Test loss: 6.753293871879578
Test loss: 6.599767943223317
Validation loss: 6.7533

-------------------- Epoch 1152 --------------------
Train loss: 2.4149
Test loss: 2.763965224226316
Test loss: 2.3782082001368203
New best validation loss: 2.7640, saving model weights to best_model_weights.pth

-------------------- Epoch 1153 --------------------
Train loss: 3.4667
Test loss: 21.11108644803365
Test loss: 21.332175970077515
Validation loss: 21.1111

-------------------- Epoch 1154 --------------------
Train loss: 3.7578
Test loss: 11.00132660071055
Test loss: 10.764747738838196
Validation loss: 11.0013

-------------------- Epoch 1155 --------------------
Train loss: 3.1825
Test loss: 5.050245404243469
Test loss: 4.899862885475159
Validation loss: 5.0502

-------------------- Epoch 1156 --------------------
Train loss: 2.6237
Test loss: 4.051491896311442
Test loss: 3.8201909561951957
Validation loss: 4.0515

-------------------- Epoch 1157 --------------------
Train loss: 3.1100
Test loss: 6.055171350638072
Test loss: 5.877566476662953
Validation loss: 6.0552

-------------------- Epoch 1158 --------------------
Train loss: 2.8732
Test loss: 28.343263387680054
Test loss: 28.664397716522217
Validation loss: 28.3433

-------------------- Epoch 1159 --------------------
Train loss: 2.9721
Test loss: 5.829345623652141
Test loss: 5.506824195384979
Validation loss: 5.8293

-------------------- Epoch 1160 --------------------
Train loss: 2.5660
Test loss: 6.805763920148213
Test loss: 6.699586073557536
Validation loss: 6.8058

-------------------- Epoch 1161 --------------------
Train loss: 3.0580
Test loss: 6.334142565727234
Test loss: 6.210137685139974
Validation loss: 6.3341

-------------------- Epoch 1162 --------------------
Train loss: 2.8359
Test loss: 8.13346379995346
Test loss: 8.019771834214529
Validation loss: 8.1335

-------------------- Epoch 1163 --------------------
Train loss: 2.6562
Test loss: 6.626058717568715
Test loss: 6.4616291125615435
Validation loss: 6.6261

-------------------- Epoch 1164 --------------------
Train loss: 2.4424
Test loss: 3.8266366124153137
Test loss: 3.5041118959585824
Validation loss: 3.8266

-------------------- Epoch 1165 --------------------
Train loss: 2.1643
Test loss: 3.3692315419514975
Test loss: 3.1770997246106467
Validation loss: 3.3692

-------------------- Epoch 1166 --------------------
Train loss: 2.6598
Test loss: 10.94492773214976
Test loss: 10.883075674374899
Validation loss: 10.9449

-------------------- Epoch 1167 --------------------
Train loss: 3.5242
Test loss: 2.788359353939692
Test loss: 2.4387651781241098
Validation loss: 2.7884

-------------------- Epoch 1168 --------------------
Train loss: 2.3725
Test loss: 4.120681653420131
Test loss: 3.847289562225342
Validation loss: 4.1207

-------------------- Epoch 1169 --------------------
Train loss: 2.5864
Test loss: 4.470884591341019
Test loss: 4.3324664533138275
Validation loss: 4.4709

-------------------- Epoch 1170 --------------------
Train loss: 2.3544
Test loss: 6.7378538846969604
Test loss: 6.477367043495178
Validation loss: 6.7379

-------------------- Epoch 1171 --------------------
Train loss: 2.3001
Test loss: 7.169077416261037
Test loss: 7.048363109429677
Validation loss: 7.1691

-------------------- Epoch 1172 --------------------
Train loss: 3.4058
Test loss: 12.254028995831808
Test loss: 12.24295949935913
Validation loss: 12.2540

-------------------- Epoch 1173 --------------------
Train loss: 3.4388
Test loss: 6.9439325133959455
Test loss: 6.96985403696696
Validation loss: 6.9439

-------------------- Epoch 1174 --------------------
Train loss: 2.6830
Test loss: 4.29088372985522
Test loss: 4.023786703745524
Validation loss: 4.2909

-------------------- Epoch 1175 --------------------
Train loss: 2.4887
Test loss: 3.162795086701711
Test loss: 2.8667716483275094
Validation loss: 3.1628

-------------------- Epoch 1176 --------------------
Train loss: 2.3939
Test loss: 3.363499383131663
Test loss: 3.1641232073307037
Validation loss: 3.3635

-------------------- Epoch 1177 --------------------
Train loss: 2.6024
Test loss: 5.796248555183411
Test loss: 5.6953409512837725
Validation loss: 5.7962

-------------------- Epoch 1178 --------------------
Train loss: 2.6006
Test loss: 2.6011523604393005
Test loss: 2.360714559753736
New best validation loss: 2.6012, saving model weights to best_model_weights.pth

-------------------- Epoch 1179 --------------------
Train loss: 2.4119
Test loss: 9.25730554262797
Test loss: 9.267082611719767
Validation loss: 9.2573

-------------------- Epoch 1180 --------------------
Train loss: 4.0490
Test loss: 9.080079237620035
Test loss: 8.886915961901346
Validation loss: 9.0801

-------------------- Epoch 1181 --------------------
Train loss: 3.5715
Test loss: 3.5823667645454407
Test loss: 3.4240923722585044
Validation loss: 3.5824

-------------------- Epoch 1182 --------------------
Train loss: 2.9268
Test loss: 2.4820014983415604
Test loss: 2.2486064235369363
New best validation loss: 2.4820, saving model weights to best_model_weights.pth

-------------------- Epoch 1183 --------------------
Train loss: 2.3966
Test loss: 2.6700781087080636
Test loss: 2.4748155574003854
Validation loss: 2.6701

-------------------- Epoch 1184 --------------------
Train loss: 2.4089
Test loss: 4.252445588509242
Test loss: 4.134775072336197
Validation loss: 4.2524

-------------------- Epoch 1185 --------------------
Train loss: 2.3023
Test loss: 6.745382209618886
Test loss: 6.748639325300853
Validation loss: 6.7454

-------------------- Epoch 1186 --------------------
Train loss: 2.5024
Test loss: 3.471741735935211
Test loss: 3.312466323375702
Validation loss: 3.4717

-------------------- Epoch 1187 --------------------
Train loss: 2.7203
Test loss: 8.344082355499268
Test loss: 8.236540873845419
Validation loss: 8.3441

-------------------- Epoch 1188 --------------------
Train loss: 2.6219
Test loss: 3.899371564388275
Test loss: 3.7445143163204193
Validation loss: 3.8994

-------------------- Epoch 1189 --------------------
Train loss: 2.4665
Test loss: 3.854664067427317
Test loss: 3.656258632739385
Validation loss: 3.8547

-------------------- Epoch 1190 --------------------
Train loss: 2.1126
Test loss: 15.182092626889547
Test loss: 15.254884004592896
Validation loss: 15.1821

-------------------- Epoch 1191 --------------------
Train loss: 3.4482
Test loss: 8.46294871966044
Test loss: 8.350080271561941
Validation loss: 8.4629

-------------------- Epoch 1192 --------------------
Train loss: 2.7428
Test loss: 4.261036674181621
Test loss: 4.114101419846217
Validation loss: 4.2610

-------------------- Epoch 1193 --------------------
Train loss: 2.4738
Test loss: 6.076439400513967
Test loss: 5.934568484624227
Validation loss: 6.0764

-------------------- Epoch 1194 --------------------
Train loss: 2.4622
Test loss: 2.641196365157763
Test loss: 2.363946740825971
Validation loss: 2.6412

-------------------- Epoch 1195 --------------------
Train loss: 2.7204
Test loss: 14.408470074335733
Test loss: 14.626610080401102
Validation loss: 14.4085

-------------------- Epoch 1196 --------------------
Train loss: 3.0197
Test loss: 2.748448297381401
Test loss: 2.5287512888511023
Validation loss: 2.7484

-------------------- Epoch 1197 --------------------
Train loss: 2.4243
Test loss: 10.957381208737692
Test loss: 10.959662119547525
Validation loss: 10.9574

-------------------- Epoch 1198 --------------------
Train loss: 2.9262
Test loss: 4.6391966839631396
Test loss: 4.659430543581645
Validation loss: 4.6392

-------------------- Epoch 1199 --------------------
Train loss: 2.4750
Test loss: 3.452375759681066
Test loss: 3.367152671019236
Validation loss: 3.4524

-------------------- Epoch 1200 --------------------
Train loss: 2.4927
Test loss: 5.497314532597859
Test loss: 5.297516286373138
Validation loss: 5.4973

-------------------- Epoch 1201 --------------------
Train loss: 2.6361
Test loss: 2.455446725090345
Test loss: 2.2794157713651657
New best validation loss: 2.4554, saving model weights to best_model_weights.pth

-------------------- Epoch 1202 --------------------
Train loss: 2.4957
Test loss: 2.75763272245725
Test loss: 2.605538229147593
Validation loss: 2.7576

-------------------- Epoch 1203 --------------------
Train loss: 2.4247
Test loss: 3.5501924057801566
Test loss: 3.4034364223480225
Validation loss: 3.5502

-------------------- Epoch 1204 --------------------
Train loss: 2.6459
Test loss: 5.028525332609813
Test loss: 4.996824681758881
Validation loss: 5.0285

-------------------- Epoch 1205 --------------------
Train loss: 2.4690
Test loss: 3.8944176733493805
Test loss: 3.79926269253095
Validation loss: 3.8944

-------------------- Epoch 1206 --------------------
Train loss: 2.4960
Test loss: 2.670214762290319
Test loss: 2.4488231440385184
Validation loss: 2.6702

-------------------- Epoch 1207 --------------------
Train loss: 2.5231
Test loss: 3.4858523507912955
Test loss: 3.425021062294642
Validation loss: 3.4859

-------------------- Epoch 1208 --------------------
Train loss: 2.6559
Test loss: 5.795171678066254
Test loss: 5.850840965906779
Validation loss: 5.7952

-------------------- Epoch 1209 --------------------
Train loss: 2.3988
Test loss: 2.4067126363515854
Test loss: 2.2436384111642838
New best validation loss: 2.4067, saving model weights to best_model_weights.pth

-------------------- Epoch 1210 --------------------
Train loss: 2.3966
Test loss: 5.1066506405671435
Test loss: 5.108802616596222
Validation loss: 5.1067

-------------------- Epoch 1211 --------------------
Train loss: 2.4011
Test loss: 3.061601678530375
Test loss: 2.8828178346157074
Validation loss: 3.0616

-------------------- Epoch 1212 --------------------
Train loss: 2.3920
Test loss: 4.708255549271901
Test loss: 4.685225913921992
Validation loss: 4.7083

-------------------- Epoch 1213 --------------------
Train loss: 2.2160
Test loss: 3.370775024096171
Test loss: 3.330563316742579
Validation loss: 3.3708

-------------------- Epoch 1214 --------------------
Train loss: 2.2377
Test loss: 2.6798923214276633
Test loss: 2.509915957848231
Validation loss: 2.6799

-------------------- Epoch 1215 --------------------
Train loss: 2.5819
Test loss: 2.896150474747022
Test loss: 2.7547036508719125
Validation loss: 2.8962

-------------------- Epoch 1216 --------------------
Train loss: 2.7826
Test loss: 2.3147421727577844
Test loss: 2.158984204133352
New best validation loss: 2.3147, saving model weights to best_model_weights.pth

-------------------- Epoch 1217 --------------------
Train loss: 2.3881
Test loss: 2.3461112529039383
Test loss: 2.254506771763166
Validation loss: 2.3461

-------------------- Epoch 1218 --------------------
Train loss: 2.3934
Test loss: 2.5545378824075065
Test loss: 2.390739838282267
Validation loss: 2.5545

-------------------- Epoch 1219 --------------------
Train loss: 2.5201
Test loss: 10.062602321306864
Test loss: 10.18229877948761
Validation loss: 10.0626

-------------------- Epoch 1220 --------------------
Train loss: 2.6068
Test loss: 6.539541979630788
Test loss: 6.542616446812947
Validation loss: 6.5395

-------------------- Epoch 1221 --------------------
Train loss: 2.0446
Test loss: 3.5971487959225974
Test loss: 3.524342864751816
Validation loss: 3.5971

-------------------- Epoch 1222 --------------------
Train loss: 2.2387
Test loss: 6.805601219336192
Test loss: 6.901442527770996
Validation loss: 6.8056

-------------------- Epoch 1223 --------------------
Train loss: 2.6312
Test loss: 4.743536392847697
Test loss: 4.731727421283722
Validation loss: 4.7435

-------------------- Epoch 1224 --------------------
Train loss: 2.4579
Test loss: 4.8450497190157575
Test loss: 4.797985712687175
Validation loss: 4.8450

-------------------- Epoch 1225 --------------------
Train loss: 2.5646
Test loss: 4.941171069939931
Test loss: 4.868696649869283
Validation loss: 4.9412

-------------------- Epoch 1226 --------------------
Train loss: 2.4201
Test loss: 2.5541845858097076
Test loss: 2.455636272827784
Validation loss: 2.5542

-------------------- Epoch 1227 --------------------
Train loss: 2.3070
Test loss: 2.3193307518959045
Test loss: 2.2310729175806046
Validation loss: 2.3193

-------------------- Epoch 1228 --------------------
Train loss: 2.0600
Test loss: 2.9805880188941956
Test loss: 2.9128019313017526
Validation loss: 2.9806

-------------------- Epoch 1229 --------------------
Train loss: 2.5830
Test loss: 4.6214439868927
Test loss: 4.444796065489451
Validation loss: 4.6214

-------------------- Epoch 1230 --------------------
Train loss: 2.5204
Test loss: 2.7408213118712106
Test loss: 2.6090388546387353
Validation loss: 2.7408

-------------------- Epoch 1231 --------------------
Train loss: 2.8504
Test loss: 11.191393772761026
Test loss: 11.2212233543396
Validation loss: 11.1914

-------------------- Epoch 1232 --------------------
Train loss: 2.9522
Test loss: 2.152075762550036
Test loss: 2.0333878993988037
New best validation loss: 2.1521, saving model weights to best_model_weights.pth

-------------------- Epoch 1233 --------------------
Train loss: 2.4390
Test loss: 4.199717591206233
Test loss: 4.191887567440669
Validation loss: 4.1997

-------------------- Epoch 1234 --------------------
Train loss: 2.0552
Test loss: 7.217382788658142
Test loss: 7.273369650046031
Validation loss: 7.2174

-------------------- Epoch 1235 --------------------
Train loss: 2.7425
Test loss: 2.3823117216428122
Test loss: 2.2677433838446936
Validation loss: 2.3823

-------------------- Epoch 1236 --------------------
Train loss: 2.5199
Test loss: 2.8647957344849906
Test loss: 2.7516174713770547
Validation loss: 2.8648

-------------------- Epoch 1237 --------------------
Train loss: 2.5118
Test loss: 3.7413105070590973
Test loss: 3.70013498266538
Validation loss: 3.7413

-------------------- Epoch 1238 --------------------
Train loss: 2.4073
Test loss: 4.6371713280677795
Test loss: 4.626730392376582
Validation loss: 4.6372

-------------------- Epoch 1239 --------------------
Train loss: 2.4217
Test loss: 5.890080471833547
Test loss: 5.876182893911998
Validation loss: 5.8901

-------------------- Epoch 1240 --------------------
Train loss: 2.3429
Test loss: 2.766605560978254
Test loss: 2.638048162062963
Validation loss: 2.7666

-------------------- Epoch 1241 --------------------
Train loss: 3.1564
Test loss: 2.452156588435173
Test loss: 2.278592432538668
Validation loss: 2.4522

-------------------- Epoch 1242 --------------------
Train loss: 2.1979
Test loss: 2.143098404010137
Test loss: 2.0366990665594735
New best validation loss: 2.1431, saving model weights to best_model_weights.pth

-------------------- Epoch 1243 --------------------
Train loss: 2.2277
Test loss: 2.314242944121361
Test loss: 2.1654647439718246
Validation loss: 2.3142

-------------------- Epoch 1244 --------------------
Train loss: 2.3904
Test loss: 2.5756207009156546
Test loss: 2.3913048853476844
Validation loss: 2.5756

-------------------- Epoch 1245 --------------------
Train loss: 2.5087
Test loss: 4.78104829788208
Test loss: 4.735252797603607
Validation loss: 4.7810

-------------------- Epoch 1246 --------------------
Train loss: 2.3378
Test loss: 4.822764217853546
Test loss: 4.825487375259399
Validation loss: 4.8228

-------------------- Epoch 1247 --------------------
Train loss: 2.3900
Test loss: 3.5066221157709756
Test loss: 3.419749071200689
Validation loss: 3.5066

-------------------- Epoch 1248 --------------------
Train loss: 2.1880
Test loss: 4.370563407739003
Test loss: 4.268967896699905
Validation loss: 4.3706

-------------------- Epoch 1249 --------------------
Train loss: 2.2712
Test loss: 4.332162926594417
Test loss: 4.280282566944758
Validation loss: 4.3322

-------------------- Epoch 1250 --------------------
Train loss: 2.3350
Test loss: 3.365452935298284
Test loss: 3.2803007066249847
Validation loss: 3.3655

-------------------- Epoch 1251 --------------------
Train loss: 2.3676
Test loss: 2.3323184003432593
Test loss: 2.289118746916453
Validation loss: 2.3323

-------------------- Epoch 1252 --------------------
Train loss: 2.3249
Test loss: 2.9246168732643127
Test loss: 2.869142731030782
Validation loss: 2.9246

-------------------- Epoch 1253 --------------------
Train loss: 2.0376
Test loss: 3.025850385427475
Test loss: 2.878327190876007
Validation loss: 3.0259

-------------------- Epoch 1254 --------------------
Train loss: 2.3553
Test loss: 2.0563451945781708
Test loss: 1.9515106876691182
New best validation loss: 2.0563, saving model weights to best_model_weights.pth

-------------------- Epoch 1255 --------------------
Train loss: 2.1230
Test loss: 2.0410211036602655
Test loss: 1.9355690628290176
New best validation loss: 2.0410, saving model weights to best_model_weights.pth

-------------------- Epoch 1256 --------------------
Train loss: 2.1797
Test loss: 2.5512493749459586
Test loss: 2.484726846218109
Validation loss: 2.5512

-------------------- Epoch 1257 --------------------
Train loss: 2.1053
Test loss: 2.7056075632572174
Test loss: 2.593651463588079
Validation loss: 2.7056

-------------------- Epoch 1258 --------------------
Train loss: 2.2156
Test loss: 4.113506843646367
Test loss: 4.073023587465286
Validation loss: 4.1135

-------------------- Epoch 1259 --------------------
Train loss: 2.2779
Test loss: 2.1036477982997894
Test loss: 1.9964602142572403
Validation loss: 2.1036

-------------------- Epoch 1260 --------------------
Train loss: 2.7709
Test loss: 3.893439402182897
Test loss: 3.7292464474836984
Validation loss: 3.8934

-------------------- Epoch 1261 --------------------
Train loss: 2.4881
Test loss: 3.2239507933457694
Test loss: 3.1067189077536264
Validation loss: 3.2240

-------------------- Epoch 1262 --------------------
Train loss: 2.2744
Test loss: 2.0526221146186194
Test loss: 1.8933563927809398
Validation loss: 2.0526

-------------------- Epoch 1263 --------------------
Train loss: 2.2337
Test loss: 3.4223862091700235
Test loss: 3.4217226207256317
Validation loss: 3.4224

-------------------- Epoch 1264 --------------------
Train loss: 2.3416
Test loss: 2.3213602056105933
Test loss: 2.2239657243092856
Validation loss: 2.3214

-------------------- Epoch 1265 --------------------
Train loss: 2.2875
Test loss: 6.205534974733989
Test loss: 6.2840452790260315
Validation loss: 6.2055

-------------------- Epoch 1266 --------------------
Train loss: 2.3358
Test loss: 2.1428091873725257
Test loss: 2.035374730825424
Validation loss: 2.1428

-------------------- Epoch 1267 --------------------
Train loss: 2.2991
Test loss: 3.6251336137453714
Test loss: 3.514079729715983
Validation loss: 3.6251

-------------------- Epoch 1268 --------------------
Train loss: 2.2671
Test loss: 2.374676153063774
Test loss: 2.2546669443448386
Validation loss: 2.3747

-------------------- Epoch 1269 --------------------
Train loss: 2.1765
Test loss: 4.587353547414144
Test loss: 4.5153891543547315
Validation loss: 4.5874

-------------------- Epoch 1270 --------------------
Train loss: 2.2737
Test loss: 5.1710155208905535
Test loss: 5.159852147102356
Validation loss: 5.1710

-------------------- Epoch 1271 --------------------
Train loss: 2.3404
Test loss: 2.228740801413854
Test loss: 2.1333941568930945
Validation loss: 2.2287

-------------------- Epoch 1272 --------------------
Train loss: 2.2371
Test loss: 2.82575316230456
Test loss: 2.756763438383738
Validation loss: 2.8258

-------------------- Epoch 1273 --------------------
Train loss: 2.1457
Test loss: 3.9711514711380005
Test loss: 3.977054556210836
Validation loss: 3.9712

-------------------- Epoch 1274 --------------------
Train loss: 2.1743
Test loss: 3.485858162244161
Test loss: 3.465423176685969
Validation loss: 3.4859

-------------------- Epoch 1275 --------------------
Train loss: 2.1254
Test loss: 4.385422011216481
Test loss: 4.305484275023143
Validation loss: 4.3854

-------------------- Epoch 1276 --------------------
Train loss: 2.4645
Test loss: 8.193418025970459
Test loss: 8.257967869440714
Validation loss: 8.1934

-------------------- Epoch 1277 --------------------
Train loss: 2.9079
Test loss: 2.9492151141166687
Test loss: 2.9351627031962075
Validation loss: 2.9492

-------------------- Epoch 1278 --------------------
Train loss: 2.1096
Test loss: 2.27165295680364
Test loss: 2.2077406346797943
Validation loss: 2.2717

-------------------- Epoch 1279 --------------------
Train loss: 2.1192
Test loss: 4.767573287089665
Test loss: 4.746326098839442
Validation loss: 4.7676

-------------------- Epoch 1280 --------------------
Train loss: 2.1877
Test loss: 3.5521578391393027
Test loss: 3.516576866308848
Validation loss: 3.5522

-------------------- Epoch 1281 --------------------
Train loss: 2.2447
Test loss: 1.9584826628367107
Test loss: 1.825260117650032
New best validation loss: 1.9585, saving model weights to best_model_weights.pth

-------------------- Epoch 1282 --------------------
Train loss: 2.1016
Test loss: 5.421457529067993
Test loss: 5.410942355791728
Validation loss: 5.4215

-------------------- Epoch 1283 --------------------
Train loss: 3.0735
Test loss: 9.852331638336182
Test loss: 9.893684109052023
Validation loss: 9.8523

-------------------- Epoch 1284 --------------------
Train loss: 2.6212
Test loss: 2.0441559801499047
Test loss: 1.9628590246041615
Validation loss: 2.0442

-------------------- Epoch 1285 --------------------
Train loss: 1.9376
Test loss: 2.5755036175251007
Test loss: 2.523692101240158
Validation loss: 2.5755

-------------------- Epoch 1286 --------------------
Train loss: 2.1534
Test loss: 4.155596524477005
Test loss: 4.131159196297328
Validation loss: 4.1556

-------------------- Epoch 1287 --------------------
Train loss: 2.1516
Test loss: 2.529710054397583
Test loss: 2.4697613418102264
Validation loss: 2.5297

-------------------- Epoch 1288 --------------------
Train loss: 2.0365
Test loss: 3.6226302683353424
Test loss: 3.516478488842646
Validation loss: 3.6226

-------------------- Epoch 1289 --------------------
Train loss: 1.9979
Test loss: 2.062328204512596
Test loss: 1.9543246229489644
Validation loss: 2.0623

-------------------- Epoch 1290 --------------------
Train loss: 1.9165
Test loss: 2.4516839534044266
Test loss: 2.3709849417209625
Validation loss: 2.4517

-------------------- Epoch 1291 --------------------
Train loss: 2.0723
Test loss: 1.972458377480507
Test loss: 1.860597272713979
Validation loss: 1.9725

-------------------- Epoch 1292 --------------------
Train loss: 1.9940
Test loss: 7.992376705010732
Test loss: 8.13426411151886
Validation loss: 7.9924

-------------------- Epoch 1293 --------------------
Train loss: 2.2447
Test loss: 3.835074802239736
Test loss: 3.7807110249996185
Validation loss: 3.8351

-------------------- Epoch 1294 --------------------
Train loss: 1.9447
Test loss: 3.4205700059731803
Test loss: 3.3121204872926078
Validation loss: 3.4206

-------------------- Epoch 1295 --------------------
Train loss: 2.1172
Test loss: 3.7605881790320077
Test loss: 3.7203815579414368
Validation loss: 3.7606

-------------------- Epoch 1296 --------------------
Train loss: 2.0567
Test loss: 2.889567186435064
Test loss: 2.8675606995821
Validation loss: 2.8896

-------------------- Epoch 1297 --------------------
Train loss: 1.9949
Test loss: 3.0958817998568215
Test loss: 3.0485797226428986
Validation loss: 3.0959

-------------------- Epoch 1298 --------------------
Train loss: 2.0939
Test loss: 3.1753711501757302
Test loss: 3.1159869035085044
Validation loss: 3.1754

-------------------- Epoch 1299 --------------------
Train loss: 2.0376
Test loss: 2.53647688527902
Test loss: 2.4456603129704795
Validation loss: 2.5365

-------------------- Epoch 1300 --------------------
Train loss: 1.9605
Test loss: 2.2163565208514533
Test loss: 2.118913546204567
Validation loss: 2.2164

-------------------- Epoch 1301 --------------------
Train loss: 1.9678
Test loss: 4.9357379873593645
Test loss: 4.878500401973724
Validation loss: 4.9357

-------------------- Epoch 1302 --------------------
Train loss: 2.0360
Test loss: 4.7862974802653
Test loss: 4.7954607009887695
Validation loss: 4.7863

-------------------- Epoch 1303 --------------------
Train loss: 1.9931
Test loss: 2.7331543266773224
Test loss: 2.6690166195233664
Validation loss: 2.7332

-------------------- Epoch 1304 --------------------
Train loss: 1.9315
Test loss: 4.1974781056245165
Test loss: 4.148894488811493
Validation loss: 4.1975

-------------------- Epoch 1305 --------------------
Train loss: 2.0833
Test loss: 6.747266014417012
Test loss: 6.807926535606384
Validation loss: 6.7473

-------------------- Epoch 1306 --------------------
Train loss: 2.3809
Test loss: 2.168825830022494
Test loss: 2.0149796158075333
Validation loss: 2.1688

-------------------- Epoch 1307 --------------------
Train loss: 1.8737
Test loss: 2.524491806825002
Test loss: 2.4374150137106576
Validation loss: 2.5245

-------------------- Epoch 1308 --------------------
Train loss: 1.9612
Test loss: 1.9214246571063995
Test loss: 1.7936915457248688
New best validation loss: 1.9214, saving model weights to best_model_weights.pth

-------------------- Epoch 1309 --------------------
Train loss: 1.8668
Test loss: 2.380491370956103
Test loss: 2.212182636062304
Validation loss: 2.3805

-------------------- Epoch 1310 --------------------
Train loss: 1.9089
Test loss: 2.442502796649933
Test loss: 2.335532690087954
Validation loss: 2.4425

-------------------- Epoch 1311 --------------------
Train loss: 1.9597
Test loss: 1.972305605808894
Test loss: 1.8123243947823842
Validation loss: 1.9723

-------------------- Epoch 1312 --------------------
Train loss: 2.0321
Test loss: 2.046109696229299
Test loss: 1.9259416808684666
Validation loss: 2.0461

-------------------- Epoch 1313 --------------------
Train loss: 2.0294
Test loss: 2.599135547876358
Test loss: 2.4932196140289307
Validation loss: 2.5991

-------------------- Epoch 1314 --------------------
Train loss: 1.9943
Test loss: 5.505672097206116
Test loss: 5.435107270876567
Validation loss: 5.5057

-------------------- Epoch 1315 --------------------
Train loss: 1.9224
Test loss: 1.8680191387732823
Test loss: 1.7050830721855164
New best validation loss: 1.8680, saving model weights to best_model_weights.pth

-------------------- Epoch 1316 --------------------
Train loss: 1.8877
Test loss: 3.8342710038026175
Test loss: 3.777658134698868
Validation loss: 3.8343

-------------------- Epoch 1317 --------------------
Train loss: 1.9670
Test loss: 2.4211502422889075
Test loss: 2.3133759647607803
Validation loss: 2.4212

-------------------- Epoch 1318 --------------------
Train loss: 1.8654
Test loss: 3.4095265666643777
Test loss: 3.296163539091746
Validation loss: 3.4095

-------------------- Epoch 1319 --------------------
Train loss: 1.9054
Test loss: 4.184702167908351
Test loss: 4.1718620757261915
Validation loss: 4.1847

-------------------- Epoch 1320 --------------------
Train loss: 2.0486
Test loss: 1.9756373316049576
Test loss: 1.8893126646677654
Validation loss: 1.9756

-------------------- Epoch 1321 --------------------
Train loss: 1.8440
Test loss: 2.25996965666612
Test loss: 2.0617707073688507
Validation loss: 2.2600

-------------------- Epoch 1322 --------------------
Train loss: 1.8398
Test loss: 2.2443665067354837
Test loss: 2.0944593797127404
Validation loss: 2.2444

-------------------- Epoch 1323 --------------------
Train loss: 1.8310
Test loss: 3.634012669324875
Test loss: 3.5733374059200287
Validation loss: 3.6340

-------------------- Epoch 1324 --------------------
Train loss: 2.0283
Test loss: 2.698687439163526
Test loss: 2.581493010123571
Validation loss: 2.6987

-------------------- Epoch 1325 --------------------
Train loss: 1.8551
Test loss: 1.8258692920207977
Test loss: 1.7011854996283848
New best validation loss: 1.8259, saving model weights to best_model_weights.pth

-------------------- Epoch 1326 --------------------
Train loss: 1.8289
Test loss: 2.2215320517619452
Test loss: 2.1450497607390084
Validation loss: 2.2215

-------------------- Epoch 1327 --------------------
Train loss: 1.9036
Test loss: 3.0093942185242972
Test loss: 2.963342934846878
Validation loss: 3.0094

-------------------- Epoch 1328 --------------------
Train loss: 1.8369
Test loss: 2.0595938762029014
Test loss: 1.885315328836441
Validation loss: 2.0596

-------------------- Epoch 1329 --------------------
Train loss: 1.8864
Test loss: 1.8831347276767094
Test loss: 1.7375860611597698
Validation loss: 1.8831

-------------------- Epoch 1330 --------------------
Train loss: 1.8003
Test loss: 1.8556346396605174
Test loss: 1.733074312408765
Validation loss: 1.8556

-------------------- Epoch 1331 --------------------
Train loss: 1.8514
Test loss: 1.960054452220599
Test loss: 1.834927166501681
Validation loss: 1.9601

-------------------- Epoch 1332 --------------------
Train loss: 1.8436
Test loss: 2.1682602216800055
Test loss: 2.061922093232473
Validation loss: 2.1683

-------------------- Epoch 1333 --------------------
Train loss: 1.8799
Test loss: 1.9664551615715027
Test loss: 1.8582346737384796
Validation loss: 1.9665

-------------------- Epoch 1334 --------------------
Train loss: 1.8030
Test loss: 2.3365184714396796
Test loss: 2.2144162356853485
Validation loss: 2.3365

-------------------- Epoch 1335 --------------------
Train loss: 1.8320
Test loss: 1.8879932165145874
Test loss: 1.7340672711531322
Validation loss: 1.8880

-------------------- Epoch 1336 --------------------
Train loss: 2.1359
Test loss: 2.03448449075222
Test loss: 1.8607203165690105
Validation loss: 2.0345

-------------------- Epoch 1337 --------------------
Train loss: 1.8054
Test loss: 2.701128209630648
Test loss: 2.6141496300697327
Validation loss: 2.7011

-------------------- Epoch 1338 --------------------
Train loss: 1.8449
Test loss: 1.9986621240774791
Test loss: 1.8683702846368153
Validation loss: 1.9987

-------------------- Epoch 1339 --------------------
Train loss: 1.8356
Test loss: 2.5223765472571054
Test loss: 2.395466521382332
Validation loss: 2.5224

-------------------- Epoch 1340 --------------------
Train loss: 1.7925
Test loss: 1.8357388724883397
Test loss: 1.6939162810643513
Validation loss: 1.8357

-------------------- Epoch 1341 --------------------
Train loss: 1.9339
Test loss: 1.848234032591184
Test loss: 1.7207637876272202
Validation loss: 1.8482

-------------------- Epoch 1342 --------------------
Train loss: 1.7995
Test loss: 2.5618735452493033
Test loss: 2.403070325652758
Validation loss: 2.5619

-------------------- Epoch 1343 --------------------
Train loss: 1.7790
Test loss: 2.753105401992798
Test loss: 2.671984851360321
Validation loss: 2.7531

-------------------- Epoch 1344 --------------------
Train loss: 2.0026
Test loss: 3.151676128307978
Test loss: 3.06953427195549
Validation loss: 3.1517

-------------------- Epoch 1345 --------------------
Train loss: 1.8311
Test loss: 2.179639687140783
Test loss: 2.041960765918096
Validation loss: 2.1796

-------------------- Epoch 1346 --------------------
Train loss: 1.8462
Test loss: 1.9576239834229152
Test loss: 1.8189918994903564
Validation loss: 1.9576

-------------------- Epoch 1347 --------------------
Train loss: 1.8479
Test loss: 1.8718017935752869
Test loss: 1.7927887737751007
Validation loss: 1.8718

-------------------- Epoch 1348 --------------------
Train loss: 1.8189
Test loss: 2.690730402866999
Test loss: 2.6299975315729776
Validation loss: 2.6907

-------------------- Epoch 1349 --------------------
Train loss: 1.7691
Test loss: 2.65479905406634
Test loss: 2.532372002800306
Validation loss: 2.6548

-------------------- Epoch 1350 --------------------
Train loss: 1.8879
Test loss: 2.7983701527118683
Test loss: 2.651295801003774
Validation loss: 2.7984

-------------------- Epoch 1351 --------------------
Train loss: 1.9674
Test loss: 1.8784229308366776
Test loss: 1.7789519727230072
Validation loss: 1.8784

-------------------- Epoch 1352 --------------------
Train loss: 1.7593
Test loss: 1.8325956612825394
Test loss: 1.7279581328233082
Validation loss: 1.8326

-------------------- Epoch 1353 --------------------
Train loss: 1.8048
Test loss: 1.9719897856314976
Test loss: 1.8508757452170055
Validation loss: 1.9720

-------------------- Epoch 1354 --------------------
Train loss: 1.9343
Test loss: 1.8098176668087642
Test loss: 1.6892757415771484
New best validation loss: 1.8098, saving model weights to best_model_weights.pth

-------------------- Epoch 1355 --------------------
Train loss: 1.7950
Test loss: 2.0396813303232193
Test loss: 1.9477157046397526
Validation loss: 2.0397

-------------------- Epoch 1356 --------------------
Train loss: 2.3668
Test loss: 1.799412210782369
Test loss: 1.6808163076639175
New best validation loss: 1.7994, saving model weights to best_model_weights.pth

-------------------- Epoch 1357 --------------------
Train loss: 1.8594
Test loss: 5.094594279925029
Test loss: 5.094089289506276
Validation loss: 5.0946

-------------------- Epoch 1358 --------------------
Train loss: 1.9401
Test loss: 2.2860140204429626
Test loss: 2.2190783520539603
Validation loss: 2.2860

-------------------- Epoch 1359 --------------------
Train loss: 2.0576
Test loss: 1.798933540781339
Test loss: 1.6821229805548985
New best validation loss: 1.7989, saving model weights to best_model_weights.pth

-------------------- Epoch 1360 --------------------
Train loss: 1.7849
Test loss: 2.1487251073122025
Test loss: 2.0493284116188684
Validation loss: 2.1487

-------------------- Epoch 1361 --------------------
Train loss: 1.7835
Test loss: 2.707389940818151
Test loss: 2.5946520070234933
Validation loss: 2.7074

-------------------- Epoch 1362 --------------------
Train loss: 1.7736
Test loss: 1.7882556865612667
Test loss: 1.6794969141483307
New best validation loss: 1.7883, saving model weights to best_model_weights.pth

-------------------- Epoch 1363 --------------------
Train loss: 1.7636
Test loss: 2.142004112402598
Test loss: 2.064957151810328
Validation loss: 2.1420

-------------------- Epoch 1364 --------------------
Train loss: 1.7610
Test loss: 2.365931118528048
Test loss: 2.2299078156550727
Validation loss: 2.3659

-------------------- Epoch 1365 --------------------
Train loss: 1.7140
Test loss: 1.79327791929245
Test loss: 1.6775724440813065
Validation loss: 1.7933

-------------------- Epoch 1366 --------------------
Train loss: 1.8694
Test loss: 1.8999604632457097
Test loss: 1.8009830961624782
Validation loss: 1.9000

-------------------- Epoch 1367 --------------------
Train loss: 1.8571
Test loss: 1.923979898293813
Test loss: 1.8378094583749771
Validation loss: 1.9240

-------------------- Epoch 1368 --------------------
Train loss: 1.7489
Test loss: 1.8387457827727
Test loss: 1.7127730548381805
Validation loss: 1.8387

-------------------- Epoch 1369 --------------------
Train loss: 1.7710
Test loss: 2.2224252223968506
Test loss: 2.093056937058767
Validation loss: 2.2224

-------------------- Epoch 1370 --------------------
Train loss: 1.7463
Test loss: 1.8779282172520955
Test loss: 1.8011759320894878
Validation loss: 1.8779

-------------------- Epoch 1371 --------------------
Train loss: 1.7479
Test loss: 1.872248222430547
Test loss: 1.7291908661524455
Validation loss: 1.8722

-------------------- Epoch 1372 --------------------
Train loss: 1.7323
Test loss: 1.7584976305564244
Test loss: 1.6483569691578548
New best validation loss: 1.7585, saving model weights to best_model_weights.pth

-------------------- Epoch 1373 --------------------
Train loss: 1.7158
Test loss: 1.7862504820028942
Test loss: 1.6811979760726292
Validation loss: 1.7863

-------------------- Epoch 1374 --------------------
Train loss: 1.7693
Test loss: 2.5228383193413415
Test loss: 2.403094028433164
Validation loss: 2.5228

-------------------- Epoch 1375 --------------------
Train loss: 1.7553
Test loss: 1.9756389955679576
Test loss: 1.895331437389056
Validation loss: 1.9756

-------------------- Epoch 1376 --------------------
Train loss: 1.7665
Test loss: 1.9302931924661
Test loss: 1.779612069328626
Validation loss: 1.9303

-------------------- Epoch 1377 --------------------
Train loss: 1.7381
Test loss: 1.8169247259696324
Test loss: 1.7080151289701462
Validation loss: 1.8169

-------------------- Epoch 1378 --------------------
Train loss: 1.7352
Test loss: 1.7413183848063152
Test loss: 1.6191956301530201
New best validation loss: 1.7413, saving model weights to best_model_weights.pth

-------------------- Epoch 1379 --------------------
Train loss: 1.7120
Test loss: 1.8327789704004924
Test loss: 1.721843461195628
Validation loss: 1.8328

-------------------- Epoch 1380 --------------------
Train loss: 1.7146
Test loss: 1.929692621032397
Test loss: 1.8388152023156483
Validation loss: 1.9297

-------------------- Epoch 1381 --------------------
Train loss: 1.8318
Test loss: 1.991619606812795
Test loss: 1.9206327895323436
Validation loss: 1.9916

-------------------- Epoch 1382 --------------------
Train loss: 1.7117
Test loss: 2.5820563435554504
Test loss: 2.445901786287626
Validation loss: 2.5821

-------------------- Epoch 1383 --------------------
Train loss: 1.7263
Test loss: 2.0190745840469995
Test loss: 1.876739114522934
Validation loss: 2.0191

-------------------- Epoch 1384 --------------------
Train loss: 1.7247
Test loss: 1.8301309496164322
Test loss: 1.7172536551952362
Validation loss: 1.8301

-------------------- Epoch 1385 --------------------
Train loss: 1.7068
Test loss: 2.4034834255774817
Test loss: 2.306252976258596
Validation loss: 2.4035

-------------------- Epoch 1386 --------------------
Train loss: 1.7402
Test loss: 1.8902695924043655
Test loss: 1.7778983066479366
Validation loss: 1.8903

-------------------- Epoch 1387 --------------------
Train loss: 1.6950
Test loss: 1.7614802022775014
Test loss: 1.6463243663311005
Validation loss: 1.7615

-------------------- Epoch 1388 --------------------
Train loss: 1.7394
Test loss: 1.8531289945046108
Test loss: 1.7789640724658966
Validation loss: 1.8531

-------------------- Epoch 1389 --------------------
Train loss: 1.7404
Test loss: 2.3674462785323462
Test loss: 2.3048535933097205
Validation loss: 2.3674

-------------------- Epoch 1390 --------------------
Train loss: 1.7176
Test loss: 1.8524564107259114
Test loss: 1.7195184628168743
Validation loss: 1.8525

-------------------- Epoch 1391 --------------------
Train loss: 1.7093
Test loss: 1.748138964176178
Test loss: 1.6418199588855107
Validation loss: 1.7481

-------------------- Epoch 1392 --------------------
Train loss: 1.7006
Test loss: 1.8122719178597133
Test loss: 1.7124564150969188
Validation loss: 1.8123

-------------------- Epoch 1393 --------------------
Train loss: 1.6816
Test loss: 2.0468336790800095
Test loss: 1.9714760581652324
Validation loss: 2.0468

-------------------- Epoch 1394 --------------------
Train loss: 1.7206
Test loss: 1.839667742451032
Test loss: 1.7297269304593403
Validation loss: 1.8397

-------------------- Epoch 1395 --------------------
Train loss: 1.6799
Test loss: 1.9814099470774333
Test loss: 1.8434652189413707
Validation loss: 1.9814

-------------------- Epoch 1396 --------------------
Train loss: 1.8331
Test loss: 2.1093016217152276
Test loss: 1.9901900440454483
Validation loss: 2.1093

-------------------- Epoch 1397 --------------------
Train loss: 1.7575
Test loss: 1.7850181857744853
Test loss: 1.664258524775505
Validation loss: 1.7850

-------------------- Epoch 1398 --------------------
Train loss: 1.6984
Test loss: 1.756837969024976
Test loss: 1.6585725198189418
Validation loss: 1.7568

-------------------- Epoch 1399 --------------------
Train loss: 1.7403
Test loss: 1.861530805627505
Test loss: 1.7172110279401143
Validation loss: 1.8615

-------------------- Epoch 1400 --------------------
Train loss: 1.6878
Test loss: 1.8917205780744553
Test loss: 1.7696785380442936
Validation loss: 1.8917

-------------------- Epoch 1401 --------------------
Train loss: 1.6950
Test loss: 1.7347594201564789
Test loss: 1.6191459546486537
New best validation loss: 1.7348, saving model weights to best_model_weights.pth

-------------------- Epoch 1402 --------------------
Train loss: 1.6731
Test loss: 1.7597632606824238
Test loss: 1.6490704119205475
Validation loss: 1.7598

-------------------- Epoch 1403 --------------------
Train loss: 1.6921
Test loss: 1.7410629789034526
Test loss: 1.6286486635605495
Validation loss: 1.7411

-------------------- Epoch 1404 --------------------
Train loss: 1.7979
Test loss: 1.7573434213797252
Test loss: 1.652500495314598
Validation loss: 1.7573

-------------------- Epoch 1405 --------------------
Train loss: 1.7060
Test loss: 1.7529286742210388
Test loss: 1.6208080450693767
Validation loss: 1.7529

-------------------- Epoch 1406 --------------------
Train loss: 1.7887
Test loss: 2.3880313535531363
Test loss: 2.277970631917318
Validation loss: 2.3880

-------------------- Epoch 1407 --------------------
Train loss: 1.7050
Test loss: 1.9127110739549
Test loss: 1.8320455998182297
Validation loss: 1.9127

-------------------- Epoch 1408 --------------------
Train loss: 1.6910
Test loss: 1.7262929578622181
Test loss: 1.6233390669027965
New best validation loss: 1.7263, saving model weights to best_model_weights.pth

-------------------- Epoch 1409 --------------------
Train loss: 1.6776
Test loss: 1.9231900225083034
Test loss: 1.8048306355873744
Validation loss: 1.9232

-------------------- Epoch 1410 --------------------
Train loss: 1.6777
Test loss: 1.7628019104401271
Test loss: 1.6845581034819286
Validation loss: 1.7628

-------------------- Epoch 1411 --------------------
Train loss: 1.6934
Test loss: 1.7555522322654724
Test loss: 1.6597590446472168
Validation loss: 1.7556

-------------------- Epoch 1412 --------------------
Train loss: 1.6820
Test loss: 1.8951620856920879
Test loss: 1.7709596653779347
Validation loss: 1.8952

-------------------- Epoch 1413 --------------------
Train loss: 1.6636
Test loss: 1.8149263858795166
Test loss: 1.6926466276248295
Validation loss: 1.8149

-------------------- Epoch 1414 --------------------
Train loss: 1.6871
Test loss: 1.7270554999510448
Test loss: 1.6202755719423294
Validation loss: 1.7271

-------------------- Epoch 1415 --------------------
Train loss: 1.6923
Test loss: 1.8851649761199951
Test loss: 1.8010427554448445
Validation loss: 1.8852

-------------------- Epoch 1416 --------------------
Train loss: 1.6679
Test loss: 1.8513228247563045
Test loss: 1.7216973255077999
Validation loss: 1.8513

-------------------- Epoch 1417 --------------------
Train loss: 1.6842
Test loss: 1.8367942969004314
Test loss: 1.7259818414847057
Validation loss: 1.8368

-------------------- Epoch 1418 --------------------
Train loss: 1.6925
Test loss: 1.7469319999217987
Test loss: 1.6485830545425415
Validation loss: 1.7469

-------------------- Epoch 1419 --------------------
Train loss: 1.6766
Test loss: 1.7273868769407272
Test loss: 1.6222857981920242
Validation loss: 1.7274

-------------------- Epoch 1420 --------------------
Train loss: 1.6809
Test loss: 1.7223604867855709
Test loss: 1.6100273032983143
New best validation loss: 1.7224, saving model weights to best_model_weights.pth

-------------------- Epoch 1421 --------------------
Train loss: 1.6693
Test loss: 1.7958568235238392
Test loss: 1.6960669507582982
Validation loss: 1.7959

-------------------- Epoch 1422 --------------------
Train loss: 1.6654
Test loss: 1.7395278712113698
Test loss: 1.622288276751836
Validation loss: 1.7395

-------------------- Epoch 1423 --------------------
Train loss: 1.6850
Test loss: 1.7212917258342106
Test loss: 1.6260771850744884
New best validation loss: 1.7213, saving model weights to best_model_weights.pth

-------------------- Epoch 1424 --------------------
Train loss: 1.6859
Test loss: 1.7377309650182724
Test loss: 1.6386298636595409
Validation loss: 1.7377

-------------------- Epoch 1425 --------------------
Train loss: 1.6975
Test loss: 1.8898580769697826
Test loss: 1.7570335169633229
Validation loss: 1.8899

-------------------- Epoch 1426 --------------------
Train loss: 1.6837
Test loss: 1.7164005984862645
Test loss: 1.6028662274281185
New best validation loss: 1.7164, saving model weights to best_model_weights.pth

-------------------- Epoch 1427 --------------------
Train loss: 1.7071
Test loss: 1.8056552509466808
Test loss: 1.6905497362216313
Validation loss: 1.8057

-------------------- Epoch 1428 --------------------
Train loss: 1.6928
Test loss: 1.733066553870837
Test loss: 1.6175949325164158
Validation loss: 1.7331

-------------------- Epoch 1429 --------------------
Train loss: 1.6578
Test loss: 1.7265484780073166
Test loss: 1.6228250364462535
Validation loss: 1.7265

-------------------- Epoch 1430 --------------------
Train loss: 1.6797
Test loss: 1.8057582179705303
Test loss: 1.6847533931334813
Validation loss: 1.8058

-------------------- Epoch 1431 --------------------
Train loss: 1.6591
Test loss: 1.7080419212579727
Test loss: 1.6020891567071278
New best validation loss: 1.7080, saving model weights to best_model_weights.pth

-------------------- Epoch 1432 --------------------
Train loss: 1.6636
Test loss: 1.8415479163328807
Test loss: 1.7193744083245595
Validation loss: 1.8415

-------------------- Epoch 1433 --------------------
Train loss: 1.6637
Test loss: 1.7198663105567296
Test loss: 1.614826222260793
Validation loss: 1.7199

-------------------- Epoch 1434 --------------------
Train loss: 1.6625
Test loss: 1.7530546585718791
Test loss: 1.6306267529726028
Validation loss: 1.7531

-------------------- Epoch 1435 --------------------
Train loss: 1.6586
Test loss: 1.7296419143676758
Test loss: 1.628582959373792
Validation loss: 1.7296

-------------------- Epoch 1436 --------------------
Train loss: 1.6968
Test loss: 1.7378513664007187
Test loss: 1.6339434136946995
Validation loss: 1.7379

-------------------- Epoch 1437 --------------------
Train loss: 1.6644
Test loss: 1.7075098156929016
Test loss: 1.601216693719228
New best validation loss: 1.7075, saving model weights to best_model_weights.pth

-------------------- Epoch 1438 --------------------
Train loss: 1.6677
Test loss: 1.7777719795703888
Test loss: 1.6562837014595668
Validation loss: 1.7778

-------------------- Epoch 1439 --------------------
Train loss: 1.6843
Test loss: 1.704914540052414
Test loss: 1.6013338714838028
New best validation loss: 1.7049, saving model weights to best_model_weights.pth

-------------------- Epoch 1440 --------------------
Train loss: 1.6602
Test loss: 1.7088133096694946
Test loss: 1.599532663822174
Validation loss: 1.7088

-------------------- Epoch 1441 --------------------
Train loss: 1.6543
Test loss: 1.7605962802966435
Test loss: 1.6659861356019974
Validation loss: 1.7606

-------------------- Epoch 1442 --------------------
Train loss: 1.6487
Test loss: 1.782030463218689
Test loss: 1.6917966206868489
Validation loss: 1.7820

-------------------- Epoch 1443 --------------------
Train loss: 1.6562
Test loss: 1.7476939012606938
Test loss: 1.6274870137373607
Validation loss: 1.7477

-------------------- Epoch 1444 --------------------
Train loss: 1.6521
Test loss: 1.7408741563558578
Test loss: 1.6259010980526607
Validation loss: 1.7409

-------------------- Epoch 1445 --------------------
Train loss: 1.6549
Test loss: 1.7033223112424214
Test loss: 1.6045412967602413
New best validation loss: 1.7033, saving model weights to best_model_weights.pth

-------------------- Epoch 1446 --------------------
Train loss: 1.6522
Test loss: 1.725158378481865
Test loss: 1.6235164105892181
Validation loss: 1.7252

-------------------- Epoch 1447 --------------------
Train loss: 1.6551
Test loss: 1.7910860776901245
Test loss: 1.6982303857803345
Validation loss: 1.7911

-------------------- Epoch 1448 --------------------
Train loss: 1.6534
Test loss: 1.7187797377506893
Test loss: 1.6171081066131592
Validation loss: 1.7188

-------------------- Epoch 1449 --------------------
Train loss: 1.6572
Test loss: 1.71107113858064
Test loss: 1.5999667048454285
Validation loss: 1.7111

-------------------- Epoch 1450 --------------------
Train loss: 1.6519
Test loss: 1.7281427184740703
Test loss: 1.6196782340606053
Validation loss: 1.7281

-------------------- Epoch 1451 --------------------
Train loss: 1.6850
Test loss: 1.7025506049394608
Test loss: 1.5922908335924149
New best validation loss: 1.7026, saving model weights to best_model_weights.pth

-------------------- Epoch 1452 --------------------
Train loss: 1.6454
Test loss: 1.7237881869077682
Test loss: 1.6208457797765732
Validation loss: 1.7238

-------------------- Epoch 1453 --------------------
Train loss: 1.6558
Test loss: 1.7039733777443569
Test loss: 1.5941342860460281
Validation loss: 1.7040

-------------------- Epoch 1454 --------------------
Train loss: 1.6567
Test loss: 1.7064379105965297
Test loss: 1.6015848616758983
Validation loss: 1.7064

-------------------- Epoch 1455 --------------------
Train loss: 1.6489
Test loss: 1.711233764886856
Test loss: 1.6064192205667496
Validation loss: 1.7112

-------------------- Epoch 1456 --------------------
Train loss: 1.6473
Test loss: 1.7245993167161942
Test loss: 1.6110087186098099
Validation loss: 1.7246

-------------------- Epoch 1457 --------------------
Train loss: 1.7518
Test loss: 1.7202416906754177
Test loss: 1.6045823295911152
Validation loss: 1.7202

-------------------- Epoch 1458 --------------------
Train loss: 1.6430
Test loss: 1.7196127076943715
Test loss: 1.6054666091998417
Validation loss: 1.7196

-------------------- Epoch 1459 --------------------
Train loss: 1.6443
Test loss: 1.7319916437069576
Test loss: 1.6177454392115276
Validation loss: 1.7320

-------------------- Epoch 1460 --------------------
Train loss: 1.6593
Test loss: 1.7023624231417973
Test loss: 1.5925325254599254
New best validation loss: 1.7024, saving model weights to best_model_weights.pth

-------------------- Epoch 1461 --------------------
Train loss: 1.6488
Test loss: 1.7012408127387364
Test loss: 1.5926691790421803
New best validation loss: 1.7012, saving model weights to best_model_weights.pth

-------------------- Epoch 1462 --------------------
Train loss: 1.6466
Test loss: 1.720594530304273
Test loss: 1.606321543455124
Validation loss: 1.7206

-------------------- Epoch 1463 --------------------
Train loss: 1.6424
Test loss: 1.7032340516646702
Test loss: 1.5931207935015361
Validation loss: 1.7032

-------------------- Epoch 1464 --------------------
Train loss: 1.6459
Test loss: 1.7007097800572712
Test loss: 1.5947388758261998
New best validation loss: 1.7007, saving model weights to best_model_weights.pth

-------------------- Epoch 1465 --------------------
Train loss: 1.6455
Test loss: 1.700864553451538
Test loss: 1.5961009015639622
Validation loss: 1.7009

-------------------- Epoch 1466 --------------------
Train loss: 1.6436
Test loss: 1.7014075169960658
Test loss: 1.5953022042910259
Validation loss: 1.7014

-------------------- Epoch 1467 --------------------
Train loss: 1.6467
Test loss: 1.7036508619785309
Test loss: 1.6001290827989578
Validation loss: 1.7037

-------------------- Epoch 1468 --------------------
Train loss: 1.6464
Test loss: 1.7027283608913422
Test loss: 1.5945084442694981
Validation loss: 1.7027

-------------------- Epoch 1469 --------------------
Train loss: 1.6414
Test loss: 1.7086450109879177
Test loss: 1.5980172157287598
Validation loss: 1.7086

-------------------- Epoch 1470 --------------------
Train loss: 1.6434
Test loss: 1.7152713735898335
Test loss: 1.6018743614355724
Validation loss: 1.7153

-------------------- Epoch 1471 --------------------
Train loss: 1.6521
Test loss: 1.703015421827634
Test loss: 1.5936838587125142
Validation loss: 1.7030

-------------------- Epoch 1472 --------------------
Train loss: 1.6380
Test loss: 1.703180804848671
Test loss: 1.5933975875377655
Validation loss: 1.7032

-------------------- Epoch 1473 --------------------
Train loss: 1.6399
Test loss: 1.7008202522993088
Test loss: 1.592952514688174
Validation loss: 1.7008

-------------------- Epoch 1474 --------------------
Train loss: 1.6472
Test loss: 1.7019184877475102
Test loss: 1.5928338021039963
Validation loss: 1.7019

-------------------- Epoch 1475 --------------------
Train loss: 1.6449
Test loss: 1.7018839816252391
Test loss: 1.5928761412700017
Validation loss: 1.7019

-------------------- Epoch 1476 --------------------
Train loss: 1.6418
Test loss: 1.7011987765630086
Test loss: 1.5932625234127045
Validation loss: 1.7012

-------------------- Epoch 1477 --------------------
Train loss: 1.6452
Test loss: 1.7018882880608242
Test loss: 1.5927528937657673
Validation loss: 1.7019

-------------------- Epoch 1478 --------------------
Train loss: 1.6467
Test loss: 1.7008976588646572
Test loss: 1.5930121938387554
Validation loss: 1.7009

-------------------- Epoch 1479 --------------------
Train loss: 1.6833
Test loss: 1.7012077768643696
Test loss: 1.5926991403102875
Validation loss: 1.7012

-------------------- Epoch 1480 --------------------
Train loss: 1.6431
Test loss: 1.701509416103363
Test loss: 1.5926845024029415
Validation loss: 1.7015

-------------------- Epoch 1481 --------------------
Train loss: 4.6013
Test loss: 4.841118236382802
Test loss: 4.846899708112081
Validation loss: 4.8411

-------------------- Epoch 1482 --------------------
Train loss: 5.0126
Test loss: 7.8833480676015215
Test loss: 7.907018621762593
Validation loss: 7.8833

-------------------- Epoch 1483 --------------------
Train loss: 4.0176
Test loss: 5.604536275068919
Test loss: 5.656548579533895
Validation loss: 5.6045

-------------------- Epoch 1484 --------------------
Train loss: 4.0185
Test loss: 2.397264301776886
Test loss: 2.283232902487119
Validation loss: 2.3973

-------------------- Epoch 1485 --------------------
Train loss: 4.2818
Test loss: 5.659597824017207
Test loss: 5.811107238133748
Validation loss: 5.6596

-------------------- Epoch 1486 --------------------
Train loss: 3.3034
Test loss: 6.854623178641002
Test loss: 6.8374256292978925
Validation loss: 6.8546

-------------------- Epoch 1487 --------------------
Train loss: 5.5263
Test loss: 2.9693537056446075
Test loss: 2.9313271741072335
Validation loss: 2.9694

-------------------- Epoch 1488 --------------------
Train loss: 3.5154
Test loss: 2.9656256486972175
Test loss: 2.9712605277697244
Validation loss: 2.9656

-------------------- Epoch 1489 --------------------
Train loss: 4.2352
Test loss: 2.602961932619413
Test loss: 2.6119512567917504
Validation loss: 2.6030

-------------------- Epoch 1490 --------------------
Train loss: 4.1043
Test loss: 11.31909199555715
Test loss: 11.543599645296732
Validation loss: 11.3191

-------------------- Epoch 1491 --------------------
Train loss: 4.8088
Test loss: 16.50864573319753
Test loss: 16.761067986488342
Validation loss: 16.5086

-------------------- Epoch 1492 --------------------
Train loss: 4.8980
Test loss: 3.249283860127131
Test loss: 3.2901341915130615
Validation loss: 3.2493

-------------------- Epoch 1493 --------------------
Train loss: 3.1803
Test loss: 2.5781855285167694
Test loss: 2.536698122819265
Validation loss: 2.5782

-------------------- Epoch 1494 --------------------
Train loss: 3.6618
Test loss: 2.4016690850257874
Test loss: 2.337876891096433
Validation loss: 2.4017

-------------------- Epoch 1495 --------------------
Train loss: 3.6903
Test loss: 2.7992278834184012
Test loss: 2.7962795992692313
Validation loss: 2.7992

-------------------- Epoch 1496 --------------------
Train loss: 3.3461
Test loss: 4.366471687952678
Test loss: 4.340578575929006
Validation loss: 4.3665

-------------------- Epoch 1497 --------------------
Train loss: 3.4412
Test loss: 7.567073047161102
Test loss: 7.664551933606465
Validation loss: 7.5671

-------------------- Epoch 1498 --------------------
Train loss: 5.1721
Test loss: 17.72159695625305
Test loss: 18.015421152114868
Validation loss: 17.7216

-------------------- Epoch 1499 --------------------
Train loss: 5.2428
Test loss: 2.3952900618314743
Test loss: 2.401599739988645
Validation loss: 2.3953

-------------------- Epoch 1500 --------------------
Train loss: 4.6188
Test loss: 2.101096361875534
Test loss: 2.167456477880478
Validation loss: 2.1011

-------------------- Epoch 1501 --------------------
Train loss: 4.0521
Test loss: 18.608638723691303
Test loss: 18.893237352371216
Validation loss: 18.6086

-------------------- Epoch 1502 --------------------
Train loss: 4.4728
Test loss: 4.183597962061564
Test loss: 4.226826697587967
Validation loss: 4.1836

-------------------- Epoch 1503 --------------------
Train loss: 3.9309
Test loss: 7.095806539058685
Test loss: 7.132331391175588
Validation loss: 7.0958

-------------------- Epoch 1504 --------------------
Train loss: 5.5026
Test loss: 16.60256580511729
Test loss: 16.738170862197876
Validation loss: 16.6026

-------------------- Epoch 1505 --------------------
Train loss: 4.5071
Test loss: 4.743802150090535
Test loss: 4.851836919784546
Validation loss: 4.7438

-------------------- Epoch 1506 --------------------
Train loss: 5.5575
Test loss: 6.523945391178131
Test loss: 6.505871454874675
Validation loss: 6.5239

-------------------- Epoch 1507 --------------------
Train loss: 4.5354
Test loss: 4.791994740565618
Test loss: 4.867778499921163
Validation loss: 4.7920

-------------------- Epoch 1508 --------------------
Train loss: 3.4395
Test loss: 6.438882509867351
Test loss: 6.414157152175903
Validation loss: 6.4389

-------------------- Epoch 1509 --------------------
Train loss: 4.9088
Test loss: 7.40213668346405
Test loss: 7.3449477553367615
Validation loss: 7.4021

-------------------- Epoch 1510 --------------------
Train loss: 4.3524
Test loss: 8.319303452968597
Test loss: 8.353105545043945
Validation loss: 8.3193

-------------------- Epoch 1511 --------------------
Train loss: 3.8002
Test loss: 4.067476719617844
Test loss: 4.13307324051857
Validation loss: 4.0675

-------------------- Epoch 1512 --------------------
Train loss: 6.6358
Test loss: 8.684928933779398
Test loss: 8.880892117818197
Validation loss: 8.6849

-------------------- Epoch 1513 --------------------
Train loss: 4.0202
Test loss: 3.9219671189785004
Test loss: 3.9438357651233673
Validation loss: 3.9220

-------------------- Epoch 1514 --------------------
Train loss: 3.7530
Test loss: 8.120774527390799
Test loss: 8.285638590653738
Validation loss: 8.1208

-------------------- Epoch 1515 --------------------
Train loss: 3.6791
Test loss: 5.375137726465861
Test loss: 5.524289568265279
Validation loss: 5.3751

-------------------- Epoch 1516 --------------------
Train loss: 3.6502
Test loss: 6.207862317562103
Test loss: 6.327914734681447
Validation loss: 6.2079

-------------------- Epoch 1517 --------------------
Train loss: 4.2389
Test loss: 6.0625449021657305
Test loss: 6.135850230852763
Validation loss: 6.0625

-------------------- Epoch 1518 --------------------
Train loss: 4.0172
Test loss: 6.068358759085338
Test loss: 6.171424865722656
Validation loss: 6.0684

-------------------- Epoch 1519 --------------------
Train loss: 4.4531
Test loss: 9.355464915434519
Test loss: 9.513762752215067
Validation loss: 9.3555

-------------------- Epoch 1520 --------------------
Train loss: 3.8502
Test loss: 2.185783083240191
Test loss: 2.2015703668196998
Validation loss: 2.1858

-------------------- Epoch 1521 --------------------
Train loss: 3.4225
Test loss: 7.387430489063263
Test loss: 7.5615465839703875
Validation loss: 7.3874

-------------------- Epoch 1522 --------------------
Train loss: 4.1150
Test loss: 4.5770067274570465
Test loss: 4.717429955800374
Validation loss: 4.5770

-------------------- Epoch 1523 --------------------
Train loss: 3.9632
Test loss: 8.199422180652618
Test loss: 8.2276385029157
Validation loss: 8.1994

-------------------- Epoch 1524 --------------------
Train loss: 3.0719
Test loss: 4.0930158495903015
Test loss: 4.069515258073807
Validation loss: 4.0930

-------------------- Epoch 1525 --------------------
Train loss: 3.6036
Test loss: 4.82811023791631
Test loss: 4.837807099024455
Validation loss: 4.8281

-------------------- Epoch 1526 --------------------
Train loss: 3.7630
Test loss: 5.947698434193929
Test loss: 6.083630879720052
Validation loss: 5.9477

-------------------- Epoch 1527 --------------------
Train loss: 4.4349
Test loss: 9.866111914316813
Test loss: 10.024036208788553
Validation loss: 9.8661

-------------------- Epoch 1528 --------------------
Train loss: 4.3942
Test loss: 4.471294045448303
Test loss: 4.521294593811035
Validation loss: 4.4713

-------------------- Epoch 1529 --------------------
Train loss: 3.6407
Test loss: 2.0000942001740136
Test loss: 2.0424847404162088
Validation loss: 2.0001

-------------------- Epoch 1530 --------------------
Train loss: 3.3444
Test loss: 9.129753947257996
Test loss: 9.248842080434164
Validation loss: 9.1298

-------------------- Epoch 1531 --------------------
Train loss: 4.1802
Test loss: 6.7501199046770735
Test loss: 6.834819356600444
Validation loss: 6.7501

-------------------- Epoch 1532 --------------------
Train loss: 3.2649
Test loss: 4.0384345054626465
Test loss: 4.0519294540087385
Validation loss: 4.0384

-------------------- Epoch 1533 --------------------
Train loss: 3.7584
Test loss: 3.3806086480617523
Test loss: 3.385481854279836
Validation loss: 3.3806

-------------------- Epoch 1534 --------------------
Train loss: 4.2253
Test loss: 6.232850054899852
Test loss: 6.146830240885417
Validation loss: 6.2329

-------------------- Epoch 1535 --------------------
Train loss: 4.2520
Test loss: 2.727310687303543
Test loss: 2.884753242135048
Validation loss: 2.7273

-------------------- Epoch 1536 --------------------
Train loss: 4.3822
Test loss: 10.364809036254883
Test loss: 10.635323325792948
Validation loss: 10.3648

-------------------- Epoch 1537 --------------------
Train loss: 2.7765
Test loss: 3.217813561360041
Test loss: 3.305494576692581
Validation loss: 3.2178

-------------------- Epoch 1538 --------------------
Train loss: 3.6179
Test loss: 4.912037670612335
Test loss: 5.005301833152771
Validation loss: 4.9120

-------------------- Epoch 1539 --------------------
Train loss: 5.4543
Test loss: 11.828644752502441
Test loss: 11.99892028172811
Validation loss: 11.8286

-------------------- Epoch 1540 --------------------
Train loss: 5.9482
Test loss: 4.4243850111961365
Test loss: 4.514223476250966
Validation loss: 4.4244

-------------------- Epoch 1541 --------------------
Train loss: 3.7144
Test loss: 7.734808146953583
Test loss: 7.878840943177541
Validation loss: 7.7348

-------------------- Epoch 1542 --------------------
Train loss: 3.2017
Test loss: 3.5015602012475333
Test loss: 3.48847026626269
Validation loss: 3.5016

-------------------- Epoch 1543 --------------------
Train loss: 4.5567
Test loss: 4.0142553349335985
Test loss: 4.047197639942169
Validation loss: 4.0143

-------------------- Epoch 1544 --------------------
Train loss: 6.7959
Test loss: 7.664845903714498
Test loss: 7.728407879670461
Validation loss: 7.6648

-------------------- Epoch 1545 --------------------
Train loss: 6.3577
Test loss: 3.66688401500384
Test loss: 3.722267061471939
Validation loss: 3.6669

-------------------- Epoch 1546 --------------------
Train loss: 5.3048
Test loss: 4.756920576095581
Test loss: 4.677425106366475
Validation loss: 4.7569

-------------------- Epoch 1547 --------------------
Train loss: 3.4558
Test loss: 7.255752126375834
Test loss: 7.371751070022583
Validation loss: 7.2558

-------------------- Epoch 1548 --------------------
Train loss: 3.2299
Test loss: 4.717106372117996
Test loss: 4.753876904646556
Validation loss: 4.7171

-------------------- Epoch 1549 --------------------
Train loss: 4.6953
Test loss: 14.109020193417868
Test loss: 14.221556067466736
Validation loss: 14.1090

-------------------- Epoch 1550 --------------------
Train loss: 5.4044
Test loss: 3.2572241127490997
Test loss: 3.2927864690621695
Validation loss: 3.2572

-------------------- Epoch 1551 --------------------
Train loss: 3.7842
Test loss: 6.583814760049184
Test loss: 6.583891729513804
Validation loss: 6.5838

-------------------- Epoch 1552 --------------------
Train loss: 3.6315
Test loss: 2.6066674292087555
Test loss: 2.664889226357142
Validation loss: 2.6067

-------------------- Epoch 1553 --------------------
Train loss: 3.6388
Test loss: 3.0514546732107797
Test loss: 3.056248019138972
Validation loss: 3.0515

-------------------- Epoch 1554 --------------------
Train loss: 3.0664
Test loss: 5.5258117616176605
Test loss: 5.600775162378947
Validation loss: 5.5258

-------------------- Epoch 1555 --------------------
Train loss: 3.6982
Test loss: 4.324531088272731
Test loss: 4.42085878054301
Validation loss: 4.3245

-------------------- Epoch 1556 --------------------
Train loss: 3.7514
Test loss: 14.313948114713034
Test loss: 14.51623241106669
Validation loss: 14.3139

-------------------- Epoch 1557 --------------------
Train loss: 4.6569
Test loss: 5.30526206890742
Test loss: 5.4492877920468645
Validation loss: 5.3053

-------------------- Epoch 1558 --------------------
Train loss: 3.9759
Test loss: 2.4019558280706406
Test loss: 2.4456654091676078
Validation loss: 2.4020

-------------------- Epoch 1559 --------------------
Train loss: 3.9028
Test loss: 3.7559148371219635
Test loss: 3.698124865690867
Validation loss: 3.7559

-------------------- Epoch 1560 --------------------
Train loss: 4.1112
Test loss: 12.426318963368734
Test loss: 12.660147666931152
Validation loss: 12.4263

-------------------- Epoch 1561 --------------------
Train loss: 3.9196
Test loss: 2.3809087028106055
Test loss: 2.314518695076307
Validation loss: 2.3809

-------------------- Epoch 1562 --------------------
Train loss: 3.2974
Test loss: 1.9286889533201854
Test loss: 1.9286737044652302
Validation loss: 1.9287

-------------------- Epoch 1563 --------------------
Train loss: 4.2773
Test loss: 9.115357677141825
Test loss: 9.38892126083374
Validation loss: 9.1154

-------------------- Epoch 1564 --------------------
Train loss: 4.4115
Test loss: 3.079324940840403
Test loss: 3.0862234930197396
Validation loss: 3.0793

-------------------- Epoch 1565 --------------------
Train loss: 3.6904
Test loss: 7.00898555914561
Test loss: 7.129032035668691
Validation loss: 7.0090

-------------------- Epoch 1566 --------------------
Train loss: 3.6939
Test loss: 6.127114752928416
Test loss: 6.135630667209625
Validation loss: 6.1271

-------------------- Epoch 1567 --------------------
Train loss: 3.7559
Test loss: 2.748456979791323
Test loss: 2.820224036773046
Validation loss: 2.7485

-------------------- Epoch 1568 --------------------
Train loss: 2.9938
Test loss: 2.2887336363395057
Test loss: 2.2088499913613
Validation loss: 2.2887

-------------------- Epoch 1569 --------------------
Train loss: 3.4481
Test loss: 7.7540151079495745
Test loss: 7.843777557214101
Validation loss: 7.7540

-------------------- Epoch 1570 --------------------
Train loss: 3.4389
Test loss: 5.185301840305328
Test loss: 5.235040128231049
Validation loss: 5.1853

-------------------- Epoch 1571 --------------------
Train loss: 3.2996
Test loss: 2.4862603147824607
Test loss: 2.418079306681951
Validation loss: 2.4863

-------------------- Epoch 1572 --------------------
Train loss: 3.9135
Test loss: 5.238620539506276
Test loss: 5.346848805745442
Validation loss: 5.2386

-------------------- Epoch 1573 --------------------
Train loss: 3.5055
Test loss: 1.83289901415507
Test loss: 1.8292303731044133
Validation loss: 1.8329

-------------------- Epoch 1574 --------------------
Train loss: 3.6384
Test loss: 2.8171530961990356
Test loss: 2.7986541092395782
Validation loss: 2.8172

-------------------- Epoch 1575 --------------------
Train loss: 2.6469
Test loss: 6.555712481339772
Test loss: 6.555522978305817
Validation loss: 6.5557

-------------------- Epoch 1576 --------------------
Train loss: 3.6544
Test loss: 2.7930622597535453
Test loss: 2.851219668984413
Validation loss: 2.7931

-------------------- Epoch 1577 --------------------
Train loss: 4.7292
Test loss: 7.152438084284465
Test loss: 7.321530818939209
Validation loss: 7.1524

-------------------- Epoch 1578 --------------------
Train loss: 3.9696
Test loss: 3.1342723866303763
Test loss: 3.2629766762256622
Validation loss: 3.1343

-------------------- Epoch 1579 --------------------
Train loss: 5.0200
Test loss: 4.570839375257492
Test loss: 4.675264318784078
Validation loss: 4.5708

-------------------- Epoch 1580 --------------------
Train loss: 3.8532
Test loss: 3.2679582834243774
Test loss: 3.343090534210205
Validation loss: 3.2680

-------------------- Epoch 1581 --------------------
Train loss: 3.3153
Test loss: 4.576965282360713
Test loss: 4.649569233258565
Validation loss: 4.5770

-------------------- Epoch 1582 --------------------
Train loss: 3.6388
Test loss: 8.585557460784912
Test loss: 8.64326024055481
Validation loss: 8.5856

-------------------- Epoch 1583 --------------------
Train loss: 6.1601
Test loss: 16.430545409520466
Test loss: 16.51001290480296
Validation loss: 16.4305

-------------------- Epoch 1584 --------------------
Train loss: 4.4505
Test loss: 8.353161334991455
Test loss: 8.508269667625427
Validation loss: 8.3532

-------------------- Epoch 1585 --------------------
Train loss: 3.7471
Test loss: 6.432006299495697
Test loss: 6.601554711659749
Validation loss: 6.4320

-------------------- Epoch 1586 --------------------
Train loss: 3.5829
Test loss: 2.725033680597941
Test loss: 2.7876842419306436
Validation loss: 2.7250

-------------------- Epoch 1587 --------------------
Train loss: 3.1551
Test loss: 3.967005650202433
Test loss: 4.037818431854248
Validation loss: 3.9670

-------------------- Epoch 1588 --------------------
Train loss: 4.0091
Test loss: 6.526272157828013
Test loss: 6.694609542687734
Validation loss: 6.5263

-------------------- Epoch 1589 --------------------
Train loss: 2.9631
Test loss: 3.6385456919670105
Test loss: 3.6762852370738983
Validation loss: 3.6385

-------------------- Epoch 1590 --------------------
Train loss: 4.6223
Test loss: 5.775172392527263
Test loss: 5.87449723482132
Validation loss: 5.7752

-------------------- Epoch 1591 --------------------
Train loss: 3.4612
Test loss: 3.7489092449347177
Test loss: 3.80161260565122
Validation loss: 3.7489

-------------------- Epoch 1592 --------------------
Train loss: 3.3871
Test loss: 4.864503741264343
Test loss: 4.934580107529958
Validation loss: 4.8645

-------------------- Epoch 1593 --------------------
Train loss: 3.7445
Test loss: 6.623771210511525
Test loss: 6.702476779619853
Validation loss: 6.6238

-------------------- Epoch 1594 --------------------
Train loss: 3.4083
Test loss: 4.696040829022725
Test loss: 4.682467341423035
Validation loss: 4.6960

-------------------- Epoch 1595 --------------------
Train loss: 3.0503
Test loss: 6.22292019923528
Test loss: 6.355751832326253
Validation loss: 6.2229

-------------------- Epoch 1596 --------------------
Train loss: 3.8206
Test loss: 3.6652121345202127
Test loss: 3.5962465902169547
Validation loss: 3.6652

-------------------- Epoch 1597 --------------------
Train loss: 3.7761
Test loss: 1.961750442783038
Test loss: 1.9674498389164607
Validation loss: 1.9618

-------------------- Epoch 1598 --------------------
Train loss: 3.2518
Test loss: 2.7754385570685067
Test loss: 2.8924488723278046
Validation loss: 2.7754

-------------------- Epoch 1599 --------------------
Train loss: 3.0637
Test loss: 1.822274272640546
Test loss: 1.8053963830073674
Validation loss: 1.8223

-------------------- Epoch 1600 --------------------
Train loss: 2.8540
Test loss: 1.8637901991605759
Test loss: 1.9058640748262405
Validation loss: 1.8638

-------------------- Epoch 1601 --------------------
Train loss: 4.8925
Test loss: 3.981487433115641
Test loss: 3.91305277744929
Validation loss: 3.9815

-------------------- Epoch 1602 --------------------
Train loss: 4.2765
Test loss: 6.81835691134135
Test loss: 6.953318774700165
Validation loss: 6.8184

-------------------- Epoch 1603 --------------------
Train loss: 3.8335
Test loss: 4.158902237812678
Test loss: 4.298897753159205
Validation loss: 4.1589

-------------------- Epoch 1604 --------------------
Train loss: 3.7438
Test loss: 4.329249461491902
Test loss: 4.3268811504046125
Validation loss: 4.3292

-------------------- Epoch 1605 --------------------
Train loss: 3.4695
Test loss: 2.8451062440872192
Test loss: 2.902733157078425
Validation loss: 2.8451

-------------------- Epoch 1606 --------------------
Train loss: 3.5350
Test loss: 5.363067865371704
Test loss: 5.475498616695404
Validation loss: 5.3631

-------------------- Epoch 1607 --------------------
Train loss: 3.6220
Test loss: 6.296718796094258
Test loss: 6.4033083319664
Validation loss: 6.2967

-------------------- Epoch 1608 --------------------
Train loss: 2.7789
Test loss: 3.1011548141638436
Test loss: 3.144931455453237
Validation loss: 3.1012

-------------------- Epoch 1609 --------------------
Train loss: 2.8544
Test loss: 7.687923630078633
Test loss: 7.879823287328084
Validation loss: 7.6879

-------------------- Epoch 1610 --------------------
Train loss: 3.9343
Test loss: 6.734879732131958
Test loss: 6.910804529984792
Validation loss: 6.7349

-------------------- Epoch 1611 --------------------
Train loss: 4.3647
Test loss: 6.447700639565785
Test loss: 6.6304581960042315
Validation loss: 6.4477

-------------------- Epoch 1612 --------------------
Train loss: 3.5714
Test loss: 1.906923770904541
Test loss: 1.883747900525729
Validation loss: 1.9069

-------------------- Epoch 1613 --------------------
Train loss: 3.1571
Test loss: 4.438210328420003
Test loss: 4.49330457051595
Validation loss: 4.4382

-------------------- Epoch 1614 --------------------
Train loss: 4.1746
Test loss: 4.358356346686681
Test loss: 4.380061507225037
Validation loss: 4.3584

-------------------- Epoch 1615 --------------------
Train loss: 3.0822
Test loss: 2.0546666185061135
Test loss: 2.1026866336663566
Validation loss: 2.0547

-------------------- Epoch 1616 --------------------
Train loss: 3.2314
Test loss: 3.0459431211153665
Test loss: 3.1013415853182473
Validation loss: 3.0459

-------------------- Epoch 1617 --------------------
Train loss: 3.3878
Test loss: 5.581585844357808
Test loss: 5.78674457470576
Validation loss: 5.5816

-------------------- Epoch 1618 --------------------
Train loss: 3.2017
Test loss: 11.796786109606424
Test loss: 11.98127313454946
Validation loss: 11.7968

-------------------- Epoch 1619 --------------------
Train loss: 3.9756
Test loss: 2.3584375033775964
Test loss: 2.4762717386086783
Validation loss: 2.3584

-------------------- Epoch 1620 --------------------
Train loss: 3.3489
Test loss: 3.8589797616004944
Test loss: 3.967819740374883
Validation loss: 3.8590

-------------------- Epoch 1621 --------------------
Train loss: 3.8555
Test loss: 7.033242960770925
Test loss: 7.18328454097112
Validation loss: 7.0332

-------------------- Epoch 1622 --------------------
Train loss: 3.5827
Test loss: 2.002143214146296
Test loss: 2.029016668597857
Validation loss: 2.0021

-------------------- Epoch 1623 --------------------
Train loss: 3.4950
Test loss: 4.969147324562073
Test loss: 5.003169854482015
Validation loss: 4.9691

-------------------- Epoch 1624 --------------------
Train loss: 2.8473
Test loss: 1.9051988273859024
Test loss: 1.8974408855040867
Validation loss: 1.9052

-------------------- Epoch 1625 --------------------
Train loss: 3.3279
Test loss: 4.997854421536128
Test loss: 5.092491587003072
Validation loss: 4.9979

-------------------- Epoch 1626 --------------------
Train loss: 3.1780
Test loss: 8.604310592015585
Test loss: 8.695570806662241
Validation loss: 8.6043

-------------------- Epoch 1627 --------------------
Train loss: 3.5463
Test loss: 2.2967407753070197
Test loss: 2.321639304359754
Validation loss: 2.2967

-------------------- Epoch 1628 --------------------
Train loss: 4.3238
Test loss: 2.0681004226207733
Test loss: 2.0327326903740564
Validation loss: 2.0681

-------------------- Epoch 1629 --------------------
Train loss: 3.5214
Test loss: 5.3627113699913025
Test loss: 5.46895964940389
Validation loss: 5.3627

-------------------- Epoch 1630 --------------------
Train loss: 3.4499
Test loss: 5.66094168027242
Test loss: 5.785010278224945
Validation loss: 5.6609

-------------------- Epoch 1631 --------------------
Train loss: 3.6036
Test loss: 2.190931499004364
Test loss: 2.2763719310363135
Validation loss: 2.1909

-------------------- Epoch 1632 --------------------
Train loss: 3.5401
Test loss: 2.1508818666140237
Test loss: 2.1627883265415826
Validation loss: 2.1509

-------------------- Epoch 1633 --------------------
Train loss: 3.2870
Test loss: 1.8409837236007054
Test loss: 1.8873403171698253
Validation loss: 1.8410

-------------------- Epoch 1634 --------------------
Train loss: 3.5831
Test loss: 4.339282403389613
Test loss: 4.437175740798314
Validation loss: 4.3393

-------------------- Epoch 1635 --------------------
Train loss: 3.1802
Test loss: 4.6088065306345625
Test loss: 4.651596645514171
Validation loss: 4.6088

-------------------- Epoch 1636 --------------------
Train loss: 3.3304
Test loss: 4.70822028319041
Test loss: 4.783130367596944
Validation loss: 4.7082

-------------------- Epoch 1637 --------------------
Train loss: 5.3101
Test loss: 2.015838717420896
Test loss: 2.040907030304273
Validation loss: 2.0158

-------------------- Epoch 1638 --------------------
Train loss: 3.1460
Test loss: 4.170281559228897
Test loss: 4.250091006358464
Validation loss: 4.1703

-------------------- Epoch 1639 --------------------
Train loss: 3.4050
Test loss: 11.24397631486257
Test loss: 11.321167866388956
Validation loss: 11.2440

-------------------- Epoch 1640 --------------------
Train loss: 3.6378
Test loss: 5.944672882556915
Test loss: 5.999724249045054
Validation loss: 5.9447

-------------------- Epoch 1641 --------------------
Train loss: 3.3256
Test loss: 1.8959515293439229
Test loss: 1.9595383654038112
Validation loss: 1.8960

-------------------- Epoch 1642 --------------------
Train loss: 3.3421
Test loss: 4.421479175488154
Test loss: 4.625285824139913
Validation loss: 4.4215

-------------------- Epoch 1643 --------------------
Train loss: 3.2643
Test loss: 3.121646677454313
Test loss: 3.2987271547317505
Validation loss: 3.1216

-------------------- Epoch 1644 --------------------
Train loss: 3.6064
Test loss: 7.360266486803691
Test loss: 7.479924440383911
Validation loss: 7.3603

-------------------- Epoch 1645 --------------------
Train loss: 4.0754
Test loss: 7.838833808898926
Test loss: 7.93648229042689
Validation loss: 7.8388

-------------------- Epoch 1646 --------------------
Train loss: 6.2681
Test loss: 3.769453138113022
Test loss: 3.864167332649231
Validation loss: 3.7695

-------------------- Epoch 1647 --------------------
Train loss: 3.4845
Test loss: 1.885734423995018
Test loss: 1.9191844761371613
Validation loss: 1.8857

-------------------- Epoch 1648 --------------------
Train loss: 3.4640
Test loss: 4.6119438509146375
Test loss: 4.670288562774658
Validation loss: 4.6119

-------------------- Epoch 1649 --------------------
Train loss: 2.4716
Test loss: 2.6957225501537323
Test loss: 2.797803580760956
Validation loss: 2.6957

-------------------- Epoch 1650 --------------------
Train loss: 3.0681
Test loss: 1.9961973925431569
Test loss: 2.0614768316348395
Validation loss: 1.9962

-------------------- Epoch 1651 --------------------
Train loss: 4.6966
Test loss: 6.9261596004168196
Test loss: 7.118229111035665
Validation loss: 6.9262

-------------------- Epoch 1652 --------------------
Train loss: 3.3136
Test loss: 16.709947029749554
Test loss: 16.944428006807964
Validation loss: 16.7099

-------------------- Epoch 1653 --------------------
Train loss: 4.4316
Test loss: 5.794918855031331
Test loss: 5.91764493783315
Validation loss: 5.7949

-------------------- Epoch 1654 --------------------
Train loss: 3.5875
Test loss: 3.240775237480799
Test loss: 3.2307534317175546
Validation loss: 3.2408

-------------------- Epoch 1655 --------------------
Train loss: 3.0611
Test loss: 3.2357230186462402
Test loss: 3.330913374821345
Validation loss: 3.2357

-------------------- Epoch 1656 --------------------
Train loss: 3.7455
Test loss: 7.301215132077535
Test loss: 7.346750160058339
Validation loss: 7.3012

-------------------- Epoch 1657 --------------------
Train loss: 3.4887
Test loss: 5.173335254192352
Test loss: 5.167080223560333
Validation loss: 5.1733

-------------------- Epoch 1658 --------------------
Train loss: 3.2925
Test loss: 2.454634298880895
Test loss: 2.4178863763809204
Validation loss: 2.4546

-------------------- Epoch 1659 --------------------
Train loss: 3.5645
Test loss: 2.0756927778323493
Test loss: 2.1071706116199493
Validation loss: 2.0757

-------------------- Epoch 1660 --------------------
Train loss: 2.6336
Test loss: 7.254065771897634
Test loss: 7.378353337446849
Validation loss: 7.2541

-------------------- Epoch 1661 --------------------
Train loss: 3.9439
Test loss: 6.12779035170873
Test loss: 6.246687233448029
Validation loss: 6.1278

-------------------- Epoch 1662 --------------------
Train loss: 3.4784
Test loss: 4.098779688278834
Test loss: 4.18117751677831
Validation loss: 4.0988

-------------------- Epoch 1663 --------------------
Train loss: 3.1658
Test loss: 2.077621872226397
Test loss: 2.1364283760388694
Validation loss: 2.0776

-------------------- Epoch 1664 --------------------
Train loss: 4.0256
Test loss: 10.426648219426474
Test loss: 10.641151626904806
Validation loss: 10.4266

-------------------- Epoch 1665 --------------------
Train loss: 3.8190
Test loss: 2.5120167831579843
Test loss: 2.6062029004096985
Validation loss: 2.5120

-------------------- Epoch 1666 --------------------
Train loss: 3.4060
Test loss: 3.070173531770706
Test loss: 3.1195274591445923
Validation loss: 3.0702

-------------------- Epoch 1667 --------------------
Train loss: 3.2127
Test loss: 5.219147036472957
Test loss: 5.318174024422963
Validation loss: 5.2191

-------------------- Epoch 1668 --------------------
Train loss: 4.0124
Test loss: 4.286413758993149
Test loss: 4.354910294214885
Validation loss: 4.2864

-------------------- Epoch 1669 --------------------
Train loss: 2.9662
Test loss: 4.8369917670885725
Test loss: 4.88576356569926
Validation loss: 4.8370

-------------------- Epoch 1670 --------------------
Train loss: 3.5937
Test loss: 3.087058832248052
Test loss: 3.134653925895691
Validation loss: 3.0871

-------------------- Epoch 1671 --------------------
Train loss: 3.0316
Test loss: 2.7179326117038727
Test loss: 2.6783772706985474
Validation loss: 2.7179

-------------------- Epoch 1672 --------------------
Train loss: 3.3637
Test loss: 2.115815833210945
Test loss: 2.144782230257988
Validation loss: 2.1158

-------------------- Epoch 1673 --------------------
Train loss: 3.4362
Test loss: 3.0869853546222052
Test loss: 3.2011408706506095
Validation loss: 3.0870

-------------------- Epoch 1674 --------------------
Train loss: 3.2246
Test loss: 5.738716204961141
Test loss: 5.823519428571065
Validation loss: 5.7387

-------------------- Epoch 1675 --------------------
Train loss: 3.4447
Test loss: 5.19318151473999
Test loss: 5.280323525269826
Validation loss: 5.1932

-------------------- Epoch 1676 --------------------
Train loss: 2.6196
Test loss: 2.28140826523304
Test loss: 2.3242103109757104
Validation loss: 2.2814

-------------------- Epoch 1677 --------------------
Train loss: 2.7714
Test loss: 5.105325122674306
Test loss: 5.24633268515269
Validation loss: 5.1053

-------------------- Epoch 1678 --------------------
Train loss: 3.2402
Test loss: 4.485252310832341
Test loss: 4.6901657084623976
Validation loss: 4.4853

-------------------- Epoch 1679 --------------------
Train loss: 3.2548
Test loss: 2.6328796595335007
Test loss: 2.690837100148201
Validation loss: 2.6329

-------------------- Epoch 1680 --------------------
Train loss: 2.8666
Test loss: 2.5633804202079773
Test loss: 2.644704749186834
Validation loss: 2.5634

-------------------- Epoch 1681 --------------------
Train loss: 3.4445
Test loss: 5.317765017350514
Test loss: 5.357542435328166
Validation loss: 5.3178

-------------------- Epoch 1682 --------------------
Train loss: 3.4963
Test loss: 3.95545561114947
Test loss: 4.018046776453654
Validation loss: 3.9555

-------------------- Epoch 1683 --------------------
Train loss: 4.7270
Test loss: 9.211662292480469
Test loss: 9.315183162689209
Validation loss: 9.2117

-------------------- Epoch 1684 --------------------
Train loss: 6.0347
Test loss: 4.127758145332336
Test loss: 4.250819226106008
Validation loss: 4.1278

-------------------- Epoch 1685 --------------------
Train loss: 3.2353
Test loss: 5.112984577814738
Test loss: 5.135900676250458
Validation loss: 5.1130

-------------------- Epoch 1686 --------------------
Train loss: 2.7848
Test loss: 4.424449612696965
Test loss: 4.509281853834788
Validation loss: 4.4244

-------------------- Epoch 1687 --------------------
Train loss: 3.4051
Test loss: 3.4004017213980355
Test loss: 3.5101760824521384
Validation loss: 3.4004

-------------------- Epoch 1688 --------------------
Train loss: 3.3233
Test loss: 3.686261256535848
Test loss: 3.793694873650869
Validation loss: 3.6863

-------------------- Epoch 1689 --------------------
Train loss: 2.9108
Test loss: 6.295009712378184
Test loss: 6.401904106140137
Validation loss: 6.2950

-------------------- Epoch 1690 --------------------
Train loss: 2.5872
Test loss: 2.05554436147213
Test loss: 2.0798614720503488
Validation loss: 2.0555

-------------------- Epoch 1691 --------------------
Train loss: 3.1233
Test loss: 2.1722101668516793
Test loss: 2.2292204797267914
Validation loss: 2.1722

-------------------- Epoch 1692 --------------------
Train loss: 2.5333
Test loss: 2.824676255385081
Test loss: 2.925305445988973
Validation loss: 2.8247

-------------------- Epoch 1693 --------------------
Train loss: 3.4840
Test loss: 9.444655378659567
Test loss: 9.584187666575113
Validation loss: 9.4447

-------------------- Epoch 1694 --------------------
Train loss: 3.5088
Test loss: 1.8246187071005504
Test loss: 1.8274445633093517
Validation loss: 1.8246

-------------------- Epoch 1695 --------------------
Train loss: 3.6353
Test loss: 2.2036280234654746
Test loss: 2.2436509132385254
Validation loss: 2.2036

-------------------- Epoch 1696 --------------------
Train loss: 2.8825
Test loss: 3.8300252060095468
Test loss: 3.9128842055797577
Validation loss: 3.8300

-------------------- Epoch 1697 --------------------
Train loss: 2.7701
Test loss: 1.9312618325153987
Test loss: 1.9714847654104233
Validation loss: 1.9313

-------------------- Epoch 1698 --------------------
Train loss: 2.8712
Test loss: 2.048210302988688
Test loss: 2.1205327262481055
Validation loss: 2.0482

-------------------- Epoch 1699 --------------------
Train loss: 2.8924
Test loss: 4.40315627058347
Test loss: 4.400448302427928
Validation loss: 4.4032

-------------------- Epoch 1700 --------------------
Train loss: 2.5383
Test loss: 4.911798904339473
Test loss: 5.073276162147522
Validation loss: 4.9118

-------------------- Epoch 1701 --------------------
Train loss: 4.4183
Test loss: 3.367096801598867
Test loss: 3.3903684119383493
Validation loss: 3.3671

-------------------- Epoch 1702 --------------------
Train loss: 2.7599
Test loss: 4.685775657494863
Test loss: 4.828318536281586
Validation loss: 4.6858

-------------------- Epoch 1703 --------------------
Train loss: 4.6391
Test loss: 4.310143639643987
Test loss: 4.244190603494644
Validation loss: 4.3101

-------------------- Epoch 1704 --------------------
Train loss: 3.6831
Test loss: 2.201177105307579
Test loss: 2.2452071706453958
Validation loss: 2.2012

-------------------- Epoch 1705 --------------------
Train loss: 3.2205
Test loss: 4.670253862937291
Test loss: 4.671923379103343
Validation loss: 4.6703

-------------------- Epoch 1706 --------------------
Train loss: 4.3223
Test loss: 2.3698423157135644
Test loss: 2.372899810473124
Validation loss: 2.3698

-------------------- Epoch 1707 --------------------
Train loss: 2.6100
Test loss: 9.459186355272928
Test loss: 9.5644211769104
Validation loss: 9.4592

-------------------- Epoch 1708 --------------------
Train loss: 4.1335
Test loss: 10.769836664199829
Test loss: 10.919792215029398
Validation loss: 10.7698

-------------------- Epoch 1709 --------------------
Train loss: 3.2153
Test loss: 2.1108381301164627
Test loss: 2.0615480740865073
Validation loss: 2.1108

-------------------- Epoch 1710 --------------------
Train loss: 3.2041
Test loss: 3.000233511130015
Test loss: 3.0254126489162445
Validation loss: 3.0002

-------------------- Epoch 1711 --------------------
Train loss: 3.3187
Test loss: 2.514725466569265
Test loss: 2.5094747046629586
Validation loss: 2.5147

-------------------- Epoch 1712 --------------------
Train loss: 3.0922
Test loss: 5.285578568776448
Test loss: 5.500807722409566
Validation loss: 5.2856

-------------------- Epoch 1713 --------------------
Train loss: 2.9913
Test loss: 3.3647104601065316
Test loss: 3.46300615866979
Validation loss: 3.3647

-------------------- Epoch 1714 --------------------
Train loss: 2.9466
Test loss: 1.895392581820488
Test loss: 1.9365871051947277
Validation loss: 1.8954

-------------------- Epoch 1715 --------------------
Train loss: 3.0559
Test loss: 3.823096344868342
Test loss: 3.9014466802279153
Validation loss: 3.8231

-------------------- Epoch 1716 --------------------
Train loss: 2.6994
Test loss: 2.551359767715136
Test loss: 2.670877829194069
Validation loss: 2.5514

-------------------- Epoch 1717 --------------------
Train loss: 3.2167
Test loss: 4.17073592543602
Test loss: 4.342003722985585
Validation loss: 4.1707

-------------------- Epoch 1718 --------------------
Train loss: 4.1503
Test loss: 5.635067105293274
Test loss: 5.6672244270642596
Validation loss: 5.6351

-------------------- Epoch 1719 --------------------
Train loss: 2.7759
Test loss: 3.4550223549207053
Test loss: 3.5539754927158356
Validation loss: 3.4550

-------------------- Epoch 1720 --------------------
Train loss: 2.9160
Test loss: 3.774954338868459
Test loss: 3.8541212578614554
Validation loss: 3.7750

-------------------- Epoch 1721 --------------------
Train loss: 3.0401
Test loss: 2.2762536803881326
Test loss: 2.3321254700422287
Validation loss: 2.2763

-------------------- Epoch 1722 --------------------
Train loss: 3.0743
Test loss: 3.304458886384964
Test loss: 3.4013157188892365
Validation loss: 3.3045

-------------------- Epoch 1723 --------------------
Train loss: 2.9959
Test loss: 3.175661414861679
Test loss: 3.2523491779963174
Validation loss: 3.1757

-------------------- Epoch 1724 --------------------
Train loss: 2.2974
Test loss: 2.6118457317352295
Test loss: 2.6695279578367868
Validation loss: 2.6118

-------------------- Epoch 1725 --------------------
Train loss: 2.7773
Test loss: 1.7141378422578175
Test loss: 1.752584770321846
Validation loss: 1.7141

-------------------- Epoch 1726 --------------------
Train loss: 2.9891
Test loss: 3.119209518035253
Test loss: 3.166989336411158
Validation loss: 3.1192

-------------------- Epoch 1727 --------------------
Train loss: 2.6930
Test loss: 3.3788940211137137
Test loss: 3.416893720626831
Validation loss: 3.3789

-------------------- Epoch 1728 --------------------
Train loss: 3.0874
Test loss: 1.7498259097337723
Test loss: 1.7696205178896587
Validation loss: 1.7498

-------------------- Epoch 1729 --------------------
Train loss: 2.5603
Test loss: 1.7803316066662471
Test loss: 1.8403990964094799
Validation loss: 1.7803

-------------------- Epoch 1730 --------------------
Train loss: 5.2385
Test loss: 4.790024360020955
Test loss: 4.78756183385849
Validation loss: 4.7900

-------------------- Epoch 1731 --------------------
Train loss: 3.2830
Test loss: 6.481996138890584
Test loss: 6.498864630858104
Validation loss: 6.4820

-------------------- Epoch 1732 --------------------
Train loss: 2.8597
Test loss: 2.4147553543249765
Test loss: 2.490737030903498
Validation loss: 2.4148

-------------------- Epoch 1733 --------------------
Train loss: 3.0850
Test loss: 4.148415446281433
Test loss: 4.2740699251492815
Validation loss: 4.1484

-------------------- Epoch 1734 --------------------
Train loss: 3.0164
Test loss: 1.9851656605799992
Test loss: 2.0774018367131553
Validation loss: 1.9852

-------------------- Epoch 1735 --------------------
Train loss: 2.8783
Test loss: 5.938091556231181
Test loss: 6.001842578252156
Validation loss: 5.9381

-------------------- Epoch 1736 --------------------
Train loss: 3.1396
Test loss: 2.7965480585892997
Test loss: 2.8565883934497833
Validation loss: 2.7965

-------------------- Epoch 1737 --------------------
Train loss: 2.6084
Test loss: 3.344981014728546
Test loss: 3.340383251508077
Validation loss: 3.3450

-------------------- Epoch 1738 --------------------
Train loss: 3.2818
Test loss: 5.568497995535533
Test loss: 5.730540951093038
Validation loss: 5.5685

-------------------- Epoch 1739 --------------------
Train loss: 3.2676
Test loss: 2.4146511356035867
Test loss: 2.4921844204266868
Validation loss: 2.4147

-------------------- Epoch 1740 --------------------
Train loss: 2.8459
Test loss: 2.96749613682429
Test loss: 3.0304513971010842
Validation loss: 2.9675

-------------------- Epoch 1741 --------------------
Train loss: 3.4127
Test loss: 3.1913743019104004
Test loss: 3.2415826419989267
Validation loss: 3.1914

-------------------- Epoch 1742 --------------------
Train loss: 3.0389
Test loss: 3.4023390312989554
Test loss: 3.5070640047391257
Validation loss: 3.4023

-------------------- Epoch 1743 --------------------
Train loss: 2.8451
Test loss: 2.1907023141781488
Test loss: 2.244137500723203
Validation loss: 2.1907

-------------------- Epoch 1744 --------------------
Train loss: 3.1419
Test loss: 4.259238600730896
Test loss: 4.3671261469523115
Validation loss: 4.2592

-------------------- Epoch 1745 --------------------
Train loss: 3.5127
Test loss: 2.1850522508223853
Test loss: 2.2299209535121918
Validation loss: 2.1851

-------------------- Epoch 1746 --------------------
Train loss: 2.4610
Test loss: 1.891517957051595
Test loss: 1.8774534463882446
Validation loss: 1.8915

-------------------- Epoch 1747 --------------------
Train loss: 2.7558
Test loss: 2.613241990407308
Test loss: 2.6374511321385703
Validation loss: 2.6132

-------------------- Epoch 1748 --------------------
Train loss: 2.8349
Test loss: 3.699214975039164
Test loss: 3.8039663930734
Validation loss: 3.6992

-------------------- Epoch 1749 --------------------
Train loss: 3.1763
Test loss: 4.494712154070537
Test loss: 4.612353265285492
Validation loss: 4.4947

-------------------- Epoch 1750 --------------------
Train loss: 3.0798
Test loss: 3.8120442231496177
Test loss: 3.919104595979055
Validation loss: 3.8120

-------------------- Epoch 1751 --------------------
Train loss: 2.4795
Test loss: 2.826954632997513
Test loss: 2.9043093621730804
Validation loss: 2.8270

-------------------- Epoch 1752 --------------------
Train loss: 2.8653
Test loss: 3.937024861574173
Test loss: 4.053208490212758
Validation loss: 3.9370

-------------------- Epoch 1753 --------------------
Train loss: 2.8455
Test loss: 1.851485162973404
Test loss: 1.8645697037378948
Validation loss: 1.8515

-------------------- Epoch 1754 --------------------
Train loss: 2.9165
Test loss: 2.0255742023388543
Test loss: 1.9705795447031658
Validation loss: 2.0256

-------------------- Epoch 1755 --------------------
Train loss: 2.4987
Test loss: 1.6048465619484584
Test loss: 1.676279251774152
New best validation loss: 1.6048, saving model weights to best_model_weights.pth

-------------------- Epoch 1756 --------------------
Train loss: 2.6560
Test loss: 2.307605187098185
Test loss: 2.3540933479865394
Validation loss: 2.3076

-------------------- Epoch 1757 --------------------
Train loss: 3.0470
Test loss: 9.591172456741333
Test loss: 9.64128843943278
Validation loss: 9.5912

-------------------- Epoch 1758 --------------------
Train loss: 2.9976
Test loss: 3.279637426137924
Test loss: 3.402172108491262
Validation loss: 3.2796

-------------------- Epoch 1759 --------------------
Train loss: 2.5732
Test loss: 4.249413251876831
Test loss: 4.220588982105255
Validation loss: 4.2494

-------------------- Epoch 1760 --------------------
Train loss: 3.7127
Test loss: 3.288818657398224
Test loss: 3.422731250524521
Validation loss: 3.2888

-------------------- Epoch 1761 --------------------
Train loss: 4.1798
Test loss: 6.529933512210846
Test loss: 6.564407408237457
Validation loss: 6.5299

-------------------- Epoch 1762 --------------------
Train loss: 3.1103
Test loss: 1.9472379684448242
Test loss: 1.9110076228777568
Validation loss: 1.9472

-------------------- Epoch 1763 --------------------
Train loss: 2.8774
Test loss: 4.80013753970464
Test loss: 4.93590650955836
Validation loss: 4.8001

-------------------- Epoch 1764 --------------------
Train loss: 2.9334
Test loss: 6.397981444994609
Test loss: 6.5353842576344805
Validation loss: 6.3980

-------------------- Epoch 1765 --------------------
Train loss: 2.9108
Test loss: 3.7994519670804343
Test loss: 3.8996952970822654
Validation loss: 3.7995

-------------------- Epoch 1766 --------------------
Train loss: 2.6044
Test loss: 2.928901677330335
Test loss: 3.0234419306119285
Validation loss: 2.9289

-------------------- Epoch 1767 --------------------
Train loss: 2.8961
Test loss: 3.536154826482137
Test loss: 3.580204486846924
Validation loss: 3.5362

-------------------- Epoch 1768 --------------------
Train loss: 2.7743
Test loss: 3.043942535916964
Test loss: 3.152821977933248
Validation loss: 3.0439

-------------------- Epoch 1769 --------------------
Train loss: 2.6948
Test loss: 2.6980793674786887
Test loss: 2.72767839829127
Validation loss: 2.6981

-------------------- Epoch 1770 --------------------
Train loss: 3.0620
Test loss: 3.556844413280487
Test loss: 3.657552550236384
Validation loss: 3.5568

-------------------- Epoch 1771 --------------------
Train loss: 3.2433
Test loss: 5.053679883480072
Test loss: 5.113592823346456
Validation loss: 5.0537

-------------------- Epoch 1772 --------------------
Train loss: 2.7501
Test loss: 5.082419455051422
Test loss: 5.1813483238220215
Validation loss: 5.0824

-------------------- Epoch 1773 --------------------
Train loss: 2.7246
Test loss: 1.8558076123396556
Test loss: 1.882600004474322
Validation loss: 1.8558

-------------------- Epoch 1774 --------------------
Train loss: 2.5556
Test loss: 3.466194272041321
Test loss: 3.5016922454039254
Validation loss: 3.4662

-------------------- Epoch 1775 --------------------
Train loss: 2.5976
Test loss: 1.7859579026699066
Test loss: 1.8013631055752437
Validation loss: 1.7860

-------------------- Epoch 1776 --------------------
Train loss: 2.9167
Test loss: 3.0086734195550284
Test loss: 3.1397463182608285
Validation loss: 3.0087

-------------------- Epoch 1777 --------------------
Train loss: 3.4292
Test loss: 3.1231272319952645
Test loss: 3.18114580710729
Validation loss: 3.1231

-------------------- Epoch 1778 --------------------
Train loss: 2.6242
Test loss: 4.583891928195953
Test loss: 4.6784935394922895
Validation loss: 4.5839

-------------------- Epoch 1779 --------------------
Train loss: 2.5280
Test loss: 2.7721972862879434
Test loss: 2.8467357556025186
Validation loss: 2.7722

-------------------- Epoch 1780 --------------------
Train loss: 2.4015
Test loss: 1.6337320804595947
Test loss: 1.6421025693416595
Validation loss: 1.6337

-------------------- Epoch 1781 --------------------
Train loss: 2.7856
Test loss: 4.47308275103569
Test loss: 4.531611651182175
Validation loss: 4.4731

-------------------- Epoch 1782 --------------------
Train loss: 2.7169
Test loss: 1.717606246471405
Test loss: 1.7652652313311894
Validation loss: 1.7176

-------------------- Epoch 1783 --------------------
Train loss: 2.6492
Test loss: 1.782758151491483
Test loss: 1.7967325796683629
Validation loss: 1.7828

-------------------- Epoch 1784 --------------------
Train loss: 2.4336
Test loss: 3.267655392487844
Test loss: 3.34330419699351
Validation loss: 3.2677

-------------------- Epoch 1785 --------------------
Train loss: 2.7946
Test loss: 3.097707211971283
Test loss: 3.168331056833267
Validation loss: 3.0977

-------------------- Epoch 1786 --------------------
Train loss: 2.8259
Test loss: 5.293096125125885
Test loss: 5.4048275748888654
Validation loss: 5.2931

-------------------- Epoch 1787 --------------------
Train loss: 2.8303
Test loss: 1.8183356771866481
Test loss: 1.8124562501907349
Validation loss: 1.8183

-------------------- Epoch 1788 --------------------
Train loss: 2.5134
Test loss: 2.610514064629873
Test loss: 2.6501455307006836
Validation loss: 2.6105

-------------------- Epoch 1789 --------------------
Train loss: 2.9965
Test loss: 1.7676828404267628
Test loss: 1.7512544989585876
Validation loss: 1.7677

-------------------- Epoch 1790 --------------------
Train loss: 2.3007
Test loss: 1.5755265206098557
Test loss: 1.6578155408302944
New best validation loss: 1.5755, saving model weights to best_model_weights.pth

-------------------- Epoch 1791 --------------------
Train loss: 2.3744
Test loss: 3.335814416408539
Test loss: 3.4070955018202462
Validation loss: 3.3358

-------------------- Epoch 1792 --------------------
Train loss: 2.6382
Test loss: 1.894134392340978
Test loss: 1.94164081911246
Validation loss: 1.8941

-------------------- Epoch 1793 --------------------
Train loss: 2.4402
Test loss: 2.331980670491854
Test loss: 2.2875727812449136
Validation loss: 2.3320

-------------------- Epoch 1794 --------------------
Train loss: 2.6887
Test loss: 5.342855801184972
Test loss: 5.367684602737427
Validation loss: 5.3429

-------------------- Epoch 1795 --------------------
Train loss: 2.5031
Test loss: 1.6147779474655788
Test loss: 1.6800660689671834
Validation loss: 1.6148

-------------------- Epoch 1796 --------------------
Train loss: 2.3512
Test loss: 2.5139732559521994
Test loss: 2.5059247414271035
Validation loss: 2.5140

-------------------- Epoch 1797 --------------------
Train loss: 2.2321
Test loss: 1.9214424391587575
Test loss: 1.954718420902888
Validation loss: 1.9214

-------------------- Epoch 1798 --------------------
Train loss: 2.2633
Test loss: 3.450247516234716
Test loss: 3.525046149889628
Validation loss: 3.4502

-------------------- Epoch 1799 --------------------
Train loss: 2.3485
Test loss: 1.8221568763256073
Test loss: 1.8677281786998112
Validation loss: 1.8222

-------------------- Epoch 1800 --------------------
Train loss: 2.6427
Test loss: 1.7496361583471298
Test loss: 1.8317769020795822
Validation loss: 1.7496

-------------------- Epoch 1801 --------------------
Train loss: 2.3892
Test loss: 2.9256898065408072
Test loss: 2.987963686386744
Validation loss: 2.9257

-------------------- Epoch 1802 --------------------
Train loss: 2.3736
Test loss: 1.9205802430709202
Test loss: 1.978794053196907
Validation loss: 1.9206

-------------------- Epoch 1803 --------------------
Train loss: 2.1983
Test loss: 1.663334329922994
Test loss: 1.732833097378413
Validation loss: 1.6633

-------------------- Epoch 1804 --------------------
Train loss: 2.2803
Test loss: 4.941139171520869
Test loss: 4.9984532197316485
Validation loss: 4.9411

-------------------- Epoch 1805 --------------------
Train loss: 2.4978
Test loss: 2.260242228706678
Test loss: 2.280286873380343
Validation loss: 2.2602

-------------------- Epoch 1806 --------------------
Train loss: 4.3507
Test loss: 5.279695709546407
Test loss: 5.411491354306539
Validation loss: 5.2797

-------------------- Epoch 1807 --------------------
Train loss: 2.9103
Test loss: 6.270535012086232
Test loss: 6.3881450692812605
Validation loss: 6.2705

-------------------- Epoch 1808 --------------------
Train loss: 2.4069
Test loss: 2.799165278673172
Test loss: 2.9131819705168405
Validation loss: 2.7992

-------------------- Epoch 1809 --------------------
Train loss: 2.5855
Test loss: 1.6672202001015346
Test loss: 1.758859674135844
Validation loss: 1.6672

-------------------- Epoch 1810 --------------------
Train loss: 2.3046
Test loss: 3.8859046697616577
Test loss: 4.009100983540217
Validation loss: 3.8859

-------------------- Epoch 1811 --------------------
Train loss: 2.4734
Test loss: 2.6012779672940574
Test loss: 2.6783028841018677
Validation loss: 2.6013

-------------------- Epoch 1812 --------------------
Train loss: 2.3369
Test loss: 3.76934415102005
Test loss: 3.8754579226175943
Validation loss: 3.7693

-------------------- Epoch 1813 --------------------
Train loss: 2.7286
Test loss: 2.39626345038414
Test loss: 2.472744400302569
Validation loss: 2.3963

-------------------- Epoch 1814 --------------------
Train loss: 2.2609
Test loss: 4.266189992427826
Test loss: 4.352408925692241
Validation loss: 4.2662

-------------------- Epoch 1815 --------------------
Train loss: 2.5712
Test loss: 1.7541501571734746
Test loss: 1.7534108012914658
Validation loss: 1.7542

-------------------- Epoch 1816 --------------------
Train loss: 2.3469
Test loss: 3.0598596086104712
Test loss: 3.0920690496762595
Validation loss: 3.0599

-------------------- Epoch 1817 --------------------
Train loss: 2.5722
Test loss: 2.300385812918345
Test loss: 2.4048732618490853
Validation loss: 2.3004

-------------------- Epoch 1818 --------------------
Train loss: 2.2749
Test loss: 1.793587585290273
Test loss: 1.8134151498476665
Validation loss: 1.7936

-------------------- Epoch 1819 --------------------
Train loss: 2.3641
Test loss: 1.8855659812688828
Test loss: 1.857718825340271
Validation loss: 1.8856

-------------------- Epoch 1820 --------------------
Train loss: 2.4425
Test loss: 1.8469038158655167
Test loss: 1.92699038485686
Validation loss: 1.8469

-------------------- Epoch 1821 --------------------
Train loss: 2.4286
Test loss: 2.5518546303113303
Test loss: 2.4691243171691895
Validation loss: 2.5519

-------------------- Epoch 1822 --------------------
Train loss: 2.4336
Test loss: 3.05740753809611
Test loss: 3.0025286177794137
Validation loss: 3.0574

-------------------- Epoch 1823 --------------------
Train loss: 2.5619
Test loss: 4.474996447563171
Test loss: 4.582882146040599
Validation loss: 4.4750

-------------------- Epoch 1824 --------------------
Train loss: 2.5680
Test loss: 2.261916692058245
Test loss: 2.3051836440960565
Validation loss: 2.2619

-------------------- Epoch 1825 --------------------
Train loss: 2.1906
Test loss: 1.8445259829362233
Test loss: 1.900726353128751
Validation loss: 1.8445

-------------------- Epoch 1826 --------------------
Train loss: 2.5352
Test loss: 3.976635297139486
Test loss: 4.0852550864219666
Validation loss: 3.9766

-------------------- Epoch 1827 --------------------
Train loss: 2.4603
Test loss: 1.9421530465284984
Test loss: 2.0242121517658234
Validation loss: 1.9422

-------------------- Epoch 1828 --------------------
Train loss: 1.9933
Test loss: 1.833529770374298
Test loss: 1.8909565756718318
Validation loss: 1.8335

-------------------- Epoch 1829 --------------------
Train loss: 2.1637
Test loss: 2.034999499718348
Test loss: 2.063515062133471
Validation loss: 2.0350

-------------------- Epoch 1830 --------------------
Train loss: 2.1469
Test loss: 1.6469089140494664
Test loss: 1.7128901729981105
Validation loss: 1.6469

-------------------- Epoch 1831 --------------------
Train loss: 2.1514
Test loss: 2.5914655129114785
Test loss: 2.566810727119446
Validation loss: 2.5915

-------------------- Epoch 1832 --------------------
Train loss: 2.3859
Test loss: 3.493170420328776
Test loss: 3.565770755211512
Validation loss: 3.4932

-------------------- Epoch 1833 --------------------
Train loss: 2.2520
Test loss: 3.3837667405605316
Test loss: 3.4420076608657837
Validation loss: 3.3838

-------------------- Epoch 1834 --------------------
Train loss: 2.1756
Test loss: 3.6016617019971213
Test loss: 3.583599050839742
Validation loss: 3.6017

-------------------- Epoch 1835 --------------------
Train loss: 2.3993
Test loss: 2.3141898016134896
Test loss: 2.3974631130695343
Validation loss: 2.3142

-------------------- Epoch 1836 --------------------
Train loss: 2.2614
Test loss: 2.4147800356149673
Test loss: 2.4969910432895026
Validation loss: 2.4148

-------------------- Epoch 1837 --------------------
Train loss: 2.3239
Test loss: 1.762437601884206
Test loss: 1.7857440958420436
Validation loss: 1.7624

-------------------- Epoch 1838 --------------------
Train loss: 2.1525
Test loss: 2.94046188890934
Test loss: 3.043253223101298
Validation loss: 2.9405

-------------------- Epoch 1839 --------------------
Train loss: 2.3403
Test loss: 1.8936465779940288
Test loss: 1.940080593029658
Validation loss: 1.8936

-------------------- Epoch 1840 --------------------
Train loss: 2.3689
Test loss: 3.5246639251708984
Test loss: 3.6318376660346985
Validation loss: 3.5247

-------------------- Epoch 1841 --------------------
Train loss: 2.2935
Test loss: 1.7483426829179127
Test loss: 1.7999839584032695
Validation loss: 1.7483

-------------------- Epoch 1842 --------------------
Train loss: 2.2481
Test loss: 3.7267278830210366
Test loss: 3.8024685283501944
Validation loss: 3.7267

-------------------- Epoch 1843 --------------------
Train loss: 2.1295
Test loss: 2.0667400707801185
Test loss: 2.068284456928571
Validation loss: 2.0667

-------------------- Epoch 1844 --------------------
Train loss: 2.1532
Test loss: 1.6599225650231044
Test loss: 1.7005589803059895
Validation loss: 1.6599

-------------------- Epoch 1845 --------------------
Train loss: 2.3598
Test loss: 1.7984991421302159
Test loss: 1.8170479784409206
Validation loss: 1.7985

-------------------- Epoch 1846 --------------------
Train loss: 1.9629
Test loss: 1.7355399131774902
Test loss: 1.8276095141967137
Validation loss: 1.7355

-------------------- Epoch 1847 --------------------
Train loss: 2.3551
Test loss: 4.647327204545339
Test loss: 4.6656273901462555
Validation loss: 4.6473

-------------------- Epoch 1848 --------------------
Train loss: 3.6494
Test loss: 1.9615281075239182
Test loss: 2.0253020922342935
Validation loss: 1.9615

-------------------- Epoch 1849 --------------------
Train loss: 2.0918
Test loss: 2.8561101853847504
Test loss: 2.88216233253479
Validation loss: 2.8561

-------------------- Epoch 1850 --------------------
Train loss: 2.1913
Test loss: 2.2282245755195618
Test loss: 2.263220896323522
Validation loss: 2.2282

-------------------- Epoch 1851 --------------------
Train loss: 2.0561
Test loss: 1.6021375854810078
Test loss: 1.6655746797720592
Validation loss: 1.6021

-------------------- Epoch 1852 --------------------
Train loss: 2.0473
Test loss: 2.984831561644872
Test loss: 2.9859769145647683
Validation loss: 2.9848

-------------------- Epoch 1853 --------------------
Train loss: 2.4100
Test loss: 2.599489519993464
Test loss: 2.7365047931671143
Validation loss: 2.5995

-------------------- Epoch 1854 --------------------
Train loss: 2.2084
Test loss: 2.2695909440517426
Test loss: 2.2804109156131744
Validation loss: 2.2696

-------------------- Epoch 1855 --------------------
Train loss: 2.2070
Test loss: 1.8348726630210876
Test loss: 1.9165562291940053
Validation loss: 1.8349

-------------------- Epoch 1856 --------------------
Train loss: 1.8769
Test loss: 3.142756929000219
Test loss: 3.2380109230677285
Validation loss: 3.1428

-------------------- Epoch 1857 --------------------
Train loss: 2.1867
Test loss: 3.115191698074341
Test loss: 3.1802032192548118
Validation loss: 3.1152

-------------------- Epoch 1858 --------------------
Train loss: 2.1773
Test loss: 2.6562075714270272
Test loss: 2.7586435774962106
Validation loss: 2.6562

-------------------- Epoch 1859 --------------------
Train loss: 2.2726
Test loss: 2.1284101456403732
Test loss: 2.222627987464269
Validation loss: 2.1284

-------------------- Epoch 1860 --------------------
Train loss: 1.9992
Test loss: 1.639441728591919
Test loss: 1.6343797594308853
Validation loss: 1.6394

-------------------- Epoch 1861 --------------------
Train loss: 2.1047
Test loss: 3.3540064096450806
Test loss: 3.413954734802246
Validation loss: 3.3540

-------------------- Epoch 1862 --------------------
Train loss: 2.0011
Test loss: 2.0324556628863015
Test loss: 2.0449584623177848
Validation loss: 2.0325

-------------------- Epoch 1863 --------------------
Train loss: 2.0517
Test loss: 1.6021935890118282
Test loss: 1.6507925738890965
Validation loss: 1.6022

-------------------- Epoch 1864 --------------------
Train loss: 2.1169
Test loss: 1.7506397714217503
Test loss: 1.768222615122795
Validation loss: 1.7506

-------------------- Epoch 1865 --------------------
Train loss: 2.3063
Test loss: 1.9339383294185002
Test loss: 1.9947174737850826
Validation loss: 1.9339

-------------------- Epoch 1866 --------------------
Train loss: 2.0348
Test loss: 1.887875497341156
Test loss: 1.877745156486829
Validation loss: 1.8879

-------------------- Epoch 1867 --------------------
Train loss: 2.0980
Test loss: 2.498150110244751
Test loss: 2.563734620809555
Validation loss: 2.4982

-------------------- Epoch 1868 --------------------
Train loss: 2.1839
Test loss: 1.6081656614939372
Test loss: 1.612533728281657
Validation loss: 1.6082

-------------------- Epoch 1869 --------------------
Train loss: 2.0743
Test loss: 2.623874376217524
Test loss: 2.599576105674108
Validation loss: 2.6239

-------------------- Epoch 1870 --------------------
Train loss: 2.0964
Test loss: 2.008796120683352
Test loss: 2.0576491256554923
Validation loss: 2.0088

-------------------- Epoch 1871 --------------------
Train loss: 2.0501
Test loss: 1.8616031606992085
Test loss: 1.9484338661034901
Validation loss: 1.8616

-------------------- Epoch 1872 --------------------
Train loss: 2.0571
Test loss: 3.2259291311105094
Test loss: 3.2972777684529624
Validation loss: 3.2259

-------------------- Epoch 1873 --------------------
Train loss: 1.9381
Test loss: 1.6472251762946446
Test loss: 1.6670521249373753
Validation loss: 1.6472

-------------------- Epoch 1874 --------------------
Train loss: 2.0135
Test loss: 2.620442718267441
Test loss: 2.697584559520086
Validation loss: 2.6204

-------------------- Epoch 1875 --------------------
Train loss: 2.3934
Test loss: 2.9639099637667337
Test loss: 2.965910176436106
Validation loss: 2.9639

-------------------- Epoch 1876 --------------------
Train loss: 2.2471
Test loss: 1.7331533432006836
Test loss: 1.7812878837188084
Validation loss: 1.7332

-------------------- Epoch 1877 --------------------
Train loss: 1.9816
Test loss: 2.6118759910265603
Test loss: 2.6271520455678306
Validation loss: 2.6119

-------------------- Epoch 1878 --------------------
Train loss: 2.1417
Test loss: 1.833316798011462
Test loss: 1.875245715181033
Validation loss: 1.8333

-------------------- Epoch 1879 --------------------
Train loss: 2.0847
Test loss: 1.5448974817991257
Test loss: 1.55740853647391
New best validation loss: 1.5449, saving model weights to best_model_weights.pth

-------------------- Epoch 1880 --------------------
Train loss: 2.0039
Test loss: 2.5727449655532837
Test loss: 2.637149120370547
Validation loss: 2.5727

-------------------- Epoch 1881 --------------------
Train loss: 2.2320
Test loss: 3.561253567536672
Test loss: 3.5851208666960397
Validation loss: 3.5613

-------------------- Epoch 1882 --------------------
Train loss: 2.1164
Test loss: 2.2348551402489343
Test loss: 2.3042230804761252
Validation loss: 2.2349

-------------------- Epoch 1883 --------------------
Train loss: 2.1085
Test loss: 5.61648025115331
Test loss: 5.687065581480662
Validation loss: 5.6165

-------------------- Epoch 1884 --------------------
Train loss: 2.4387
Test loss: 3.6088774104913077
Test loss: 3.682330926259359
Validation loss: 3.6089

-------------------- Epoch 1885 --------------------
Train loss: 2.0223
Test loss: 1.7887647102276485
Test loss: 1.8052592525879543
Validation loss: 1.7888

-------------------- Epoch 1886 --------------------
Train loss: 1.9816
Test loss: 1.9729691048463185
Test loss: 2.024077186981837
Validation loss: 1.9730

-------------------- Epoch 1887 --------------------
Train loss: 1.9611
Test loss: 1.5860576430956523
Test loss: 1.6176859339078267
Validation loss: 1.5861

-------------------- Epoch 1888 --------------------
Train loss: 2.0494
Test loss: 2.197391058007876
Test loss: 2.2236134707927704
Validation loss: 2.1974

-------------------- Epoch 1889 --------------------
Train loss: 2.0255
Test loss: 4.28482989470164
Test loss: 4.333550920089086
Validation loss: 4.2848

-------------------- Epoch 1890 --------------------
Train loss: 2.0539
Test loss: 2.0513501167297363
Test loss: 2.1352175176143646
Validation loss: 2.0514

-------------------- Epoch 1891 --------------------
Train loss: 1.9344
Test loss: 1.7568319588899612
Test loss: 1.8128934303919475
Validation loss: 1.7568

-------------------- Epoch 1892 --------------------
Train loss: 1.8493
Test loss: 1.76396082341671
Test loss: 1.7610147794087727
Validation loss: 1.7640

-------------------- Epoch 1893 --------------------
Train loss: 2.0763
Test loss: 2.1841386556625366
Test loss: 2.2668930341800055
Validation loss: 2.1841

-------------------- Epoch 1894 --------------------
Train loss: 1.9770
Test loss: 3.29801352818807
Test loss: 3.3679108122984567
Validation loss: 3.2980

-------------------- Epoch 1895 --------------------
Train loss: 2.0876
Test loss: 1.5378605822722118
Test loss: 1.5289976745843887
New best validation loss: 1.5379, saving model weights to best_model_weights.pth

-------------------- Epoch 1896 --------------------
Train loss: 1.8475
Test loss: 1.8758644262949626
Test loss: 1.9449740648269653
Validation loss: 1.8759

-------------------- Epoch 1897 --------------------
Train loss: 1.9041
Test loss: 1.6057122697432835
Test loss: 1.644407441218694
Validation loss: 1.6057

-------------------- Epoch 1898 --------------------
Train loss: 1.9911
Test loss: 3.6139412422974906
Test loss: 3.650468587875366
Validation loss: 3.6139

-------------------- Epoch 1899 --------------------
Train loss: 1.9871
Test loss: 2.60955477754275
Test loss: 2.64607302347819
Validation loss: 2.6096

-------------------- Epoch 1900 --------------------
Train loss: 2.0412
Test loss: 2.2013539324204126
Test loss: 2.2058983594179153
Validation loss: 2.2014

-------------------- Epoch 1901 --------------------
Train loss: 1.8742
Test loss: 1.5405058811108272
Test loss: 1.5803186843792598
Validation loss: 1.5405

-------------------- Epoch 1902 --------------------
Train loss: 2.1760
Test loss: 2.0144527554512024
Test loss: 2.0366999556620917
Validation loss: 2.0145

-------------------- Epoch 1903 --------------------
Train loss: 1.8180
Test loss: 1.7356689025958378
Test loss: 1.7935921400785446
Validation loss: 1.7357

-------------------- Epoch 1904 --------------------
Train loss: 1.9382
Test loss: 1.5725653568903606
Test loss: 1.595588783423106
Validation loss: 1.5726

-------------------- Epoch 1905 --------------------
Train loss: 1.9865
Test loss: 2.0733994841575623
Test loss: 2.0766058514515557
Validation loss: 2.0734

-------------------- Epoch 1906 --------------------
Train loss: 1.9280
Test loss: 2.2426275461912155
Test loss: 2.22428190211455
Validation loss: 2.2426

-------------------- Epoch 1907 --------------------
Train loss: 2.2559
Test loss: 1.504883309205373
Test loss: 1.546979397535324
New best validation loss: 1.5049, saving model weights to best_model_weights.pth

-------------------- Epoch 1908 --------------------
Train loss: 1.8652
Test loss: 1.8205208082993825
Test loss: 1.8846581031878789
Validation loss: 1.8205

-------------------- Epoch 1909 --------------------
Train loss: 1.9517
Test loss: 1.8086648086706798
Test loss: 1.804486686984698
Validation loss: 1.8087

-------------------- Epoch 1910 --------------------
Train loss: 1.8362
Test loss: 1.6296712855497997
Test loss: 1.6703632324934006
Validation loss: 1.6297

-------------------- Epoch 1911 --------------------
Train loss: 1.8927
Test loss: 1.6534737348556519
Test loss: 1.684941237171491
Validation loss: 1.6535

-------------------- Epoch 1912 --------------------
Train loss: 1.8999
Test loss: 1.5849635352691014
Test loss: 1.6450106501579285
Validation loss: 1.5850

-------------------- Epoch 1913 --------------------
Train loss: 1.8359
Test loss: 2.174935186902682
Test loss: 2.1782153199116387
Validation loss: 2.1749

-------------------- Epoch 1914 --------------------
Train loss: 1.8737
Test loss: 2.972006986538569
Test loss: 3.00643453001976
Validation loss: 2.9720

-------------------- Epoch 1915 --------------------
Train loss: 2.3126
Test loss: 1.6164286782344182
Test loss: 1.6617483148972194
Validation loss: 1.6164

-------------------- Epoch 1916 --------------------
Train loss: 1.8956
Test loss: 1.7438311129808426
Test loss: 1.7964382618665695
Validation loss: 1.7438

-------------------- Epoch 1917 --------------------
Train loss: 1.9773
Test loss: 1.5695905536413193
Test loss: 1.6047438085079193
Validation loss: 1.5696

-------------------- Epoch 1918 --------------------
Train loss: 1.7591
Test loss: 1.6918131907780964
Test loss: 1.6856832454601924
Validation loss: 1.6918

-------------------- Epoch 1919 --------------------
Train loss: 1.8726
Test loss: 1.9289602935314178
Test loss: 2.0178548147281012
Validation loss: 1.9290

-------------------- Epoch 1920 --------------------
Train loss: 1.9115
Test loss: 5.462195595105489
Test loss: 5.511423110961914
Validation loss: 5.4622

-------------------- Epoch 1921 --------------------
Train loss: 2.1209
Test loss: 1.5807543595631917
Test loss: 1.6372581670681636
Validation loss: 1.5808

-------------------- Epoch 1922 --------------------
Train loss: 1.7878
Test loss: 1.7539826383193333
Test loss: 1.7490299691756566
Validation loss: 1.7540

-------------------- Epoch 1923 --------------------
Train loss: 1.8501
Test loss: 1.9289395709832509
Test loss: 1.9862258931001027
Validation loss: 1.9289

-------------------- Epoch 1924 --------------------
Train loss: 1.9122
Test loss: 1.9987010061740875
Test loss: 2.0677020301421485
Validation loss: 1.9987

-------------------- Epoch 1925 --------------------
Train loss: 1.9457
Test loss: 2.1693448523680368
Test loss: 2.173119972149531
Validation loss: 2.1693

-------------------- Epoch 1926 --------------------
Train loss: 1.7281
Test loss: 1.5181490282217662
Test loss: 1.5517983982960384
Validation loss: 1.5181

-------------------- Epoch 1927 --------------------
Train loss: 1.8912
Test loss: 1.6712660292784374
Test loss: 1.6886219878991444
Validation loss: 1.6713

-------------------- Epoch 1928 --------------------
Train loss: 1.7931
Test loss: 1.8326617032289505
Test loss: 1.889917219678561
Validation loss: 1.8327

-------------------- Epoch 1929 --------------------
Train loss: 1.9673
Test loss: 2.8327340483665466
Test loss: 2.8865655064582825
Validation loss: 2.8327

-------------------- Epoch 1930 --------------------
Train loss: 1.9061
Test loss: 1.9725333054860432
Test loss: 2.039167275031408
Validation loss: 1.9725

-------------------- Epoch 1931 --------------------
Train loss: 1.8159
Test loss: 2.0542344798644385
Test loss: 2.1045106053352356
Validation loss: 2.0542

-------------------- Epoch 1932 --------------------
Train loss: 1.7626
Test loss: 2.551783020297686
Test loss: 2.6014841894308725
Validation loss: 2.5518

-------------------- Epoch 1933 --------------------
Train loss: 1.8670
Test loss: 1.7425337036450703
Test loss: 1.7878069033225377
Validation loss: 1.7425

-------------------- Epoch 1934 --------------------
Train loss: 1.8917
Test loss: 1.5817614843448002
Test loss: 1.6230276574691136
Validation loss: 1.5818

-------------------- Epoch 1935 --------------------
Train loss: 1.7338
Test loss: 2.4030352234840393
Test loss: 2.427738666534424
Validation loss: 2.4030

-------------------- Epoch 1936 --------------------
Train loss: 1.6998
Test loss: 1.8267794797817867
Test loss: 1.8380865454673767
Validation loss: 1.8268

-------------------- Epoch 1937 --------------------
Train loss: 1.7609
Test loss: 1.6498045672972996
Test loss: 1.6649507284164429
Validation loss: 1.6498

-------------------- Epoch 1938 --------------------
Train loss: 1.6964
Test loss: 1.6475462168455124
Test loss: 1.710600917538007
Validation loss: 1.6475

-------------------- Epoch 1939 --------------------
Train loss: 1.7800
Test loss: 1.7631394465764363
Test loss: 1.7341875980297725
Validation loss: 1.7631

-------------------- Epoch 1940 --------------------
Train loss: 1.8249
Test loss: 2.0276042570670447
Test loss: 2.0742349922657013
Validation loss: 2.0276

-------------------- Epoch 1941 --------------------
Train loss: 1.8304
Test loss: 1.8648530890544255
Test loss: 1.926209385196368
Validation loss: 1.8649

-------------------- Epoch 1942 --------------------
Train loss: 1.7792
Test loss: 1.8192644168933232
Test loss: 1.847595085700353
Validation loss: 1.8193

-------------------- Epoch 1943 --------------------
Train loss: 1.9065
Test loss: 2.016080612937609
Test loss: 2.0835339973370233
Validation loss: 2.0161

-------------------- Epoch 1944 --------------------
Train loss: 2.1208
Test loss: 3.260926514863968
Test loss: 3.343880206346512
Validation loss: 3.2609

-------------------- Epoch 1945 --------------------
Train loss: 2.0736
Test loss: 1.5087618281443913
Test loss: 1.5569512446721394
Validation loss: 1.5088

-------------------- Epoch 1946 --------------------
Train loss: 1.7156
Test loss: 1.6984930783510208
Test loss: 1.7510998646418254
Validation loss: 1.6985

-------------------- Epoch 1947 --------------------
Train loss: 1.7273
Test loss: 1.7215067942937214
Test loss: 1.7493308931589127
Validation loss: 1.7215

-------------------- Epoch 1948 --------------------
Train loss: 1.7776
Test loss: 2.3489064425230026
Test loss: 2.3514835437138877
Validation loss: 2.3489

-------------------- Epoch 1949 --------------------
Train loss: 1.7963
Test loss: 2.0608029117186866
Test loss: 2.081733281413714
Validation loss: 2.0608

-------------------- Epoch 1950 --------------------
Train loss: 2.0843
Test loss: 2.140560065706571
Test loss: 2.2021434158086777
Validation loss: 2.1406

-------------------- Epoch 1951 --------------------
Train loss: 1.7302
Test loss: 1.723113735516866
Test loss: 1.788071279724439
Validation loss: 1.7231

-------------------- Epoch 1952 --------------------
Train loss: 1.7728
Test loss: 1.8003802200158436
Test loss: 1.8187794884045918
Validation loss: 1.8004

-------------------- Epoch 1953 --------------------
Train loss: 1.7772
Test loss: 1.6883521378040314
Test loss: 1.7248877783616383
Validation loss: 1.6884

-------------------- Epoch 1954 --------------------
Train loss: 1.6039
Test loss: 1.6438756932814915
Test loss: 1.6833166380723317
Validation loss: 1.6439

-------------------- Epoch 1955 --------------------
Train loss: 1.7612
Test loss: 2.281259387731552
Test loss: 2.33747806151708
Validation loss: 2.2813

-------------------- Epoch 1956 --------------------
Train loss: 1.6956
Test loss: 1.8157997230688732
Test loss: 1.8791600664456685
Validation loss: 1.8158

-------------------- Epoch 1957 --------------------
Train loss: 1.7105
Test loss: 2.6798653503259025
Test loss: 2.766908903916677
Validation loss: 2.6799

-------------------- Epoch 1958 --------------------
Train loss: 1.7301
Test loss: 1.4772096127271652
Test loss: 1.5541028181711833
New best validation loss: 1.4772, saving model weights to best_model_weights.pth

-------------------- Epoch 1959 --------------------
Train loss: 1.7651
Test loss: 1.5294731110334396
Test loss: 1.5889564206202824
Validation loss: 1.5295

-------------------- Epoch 1960 --------------------
Train loss: 2.0806
Test loss: 3.956347495317459
Test loss: 4.021539131800334
Validation loss: 3.9563

-------------------- Epoch 1961 --------------------
Train loss: 1.9133
Test loss: 1.5368244002262752
Test loss: 1.5562338878711064
Validation loss: 1.5368

-------------------- Epoch 1962 --------------------
Train loss: 1.7071
Test loss: 1.5832738528649013
Test loss: 1.6251943161090214
Validation loss: 1.5833

-------------------- Epoch 1963 --------------------
Train loss: 1.7341
Test loss: 1.5983521044254303
Test loss: 1.5926224042971928
Validation loss: 1.5984

-------------------- Epoch 1964 --------------------
Train loss: 1.7900
Test loss: 1.5818704317013423
Test loss: 1.6064513524373372
Validation loss: 1.5819

-------------------- Epoch 1965 --------------------
Train loss: 1.6035
Test loss: 1.6568047652641933
Test loss: 1.6807495305935543
Validation loss: 1.6568

-------------------- Epoch 1966 --------------------
Train loss: 1.7425
Test loss: 2.1741389483213425
Test loss: 2.204497347275416
Validation loss: 2.1741

-------------------- Epoch 1967 --------------------
Train loss: 1.7317
Test loss: 1.507540966073672
Test loss: 1.5509712994098663
Validation loss: 1.5075

-------------------- Epoch 1968 --------------------
Train loss: 1.7567
Test loss: 1.894793262084325
Test loss: 1.9365759044885635
Validation loss: 1.8948

-------------------- Epoch 1969 --------------------
Train loss: 1.8277
Test loss: 1.9854603360096614
Test loss: 2.0109184434016547
Validation loss: 1.9855

-------------------- Epoch 1970 --------------------
Train loss: 1.6642
Test loss: 1.6324350535869598
Test loss: 1.708983947833379
Validation loss: 1.6324

-------------------- Epoch 1971 --------------------
Train loss: 1.6097
Test loss: 1.8023448139429092
Test loss: 1.862771560748418
Validation loss: 1.8023

-------------------- Epoch 1972 --------------------
Train loss: 1.7877
Test loss: 1.5758229345083237
Test loss: 1.6460225582122803
Validation loss: 1.5758

-------------------- Epoch 1973 --------------------
Train loss: 1.7268
Test loss: 1.5570130497217178
Test loss: 1.591669683655103
Validation loss: 1.5570

-------------------- Epoch 1974 --------------------
Train loss: 1.7320
Test loss: 2.0409680157899857
Test loss: 2.0835814476013184
Validation loss: 2.0410

-------------------- Epoch 1975 --------------------
Train loss: 1.6684
Test loss: 2.3931790639956794
Test loss: 2.4120500137408576
Validation loss: 2.3932

-------------------- Epoch 1976 --------------------
Train loss: 1.7408
Test loss: 1.5980775952339172
Test loss: 1.607683703303337
Validation loss: 1.5981

-------------------- Epoch 1977 --------------------
Train loss: 1.8152
Test loss: 2.001839275161425
Test loss: 2.078524018327395
Validation loss: 2.0018

-------------------- Epoch 1978 --------------------
Train loss: 1.6646
Test loss: 1.48797511557738
Test loss: 1.5482302059729893
Validation loss: 1.4880

-------------------- Epoch 1979 --------------------
Train loss: 1.7956
Test loss: 1.6627821971972783
Test loss: 1.6505002280076344
Validation loss: 1.6628

-------------------- Epoch 1980 --------------------
Train loss: 1.6671
Test loss: 1.6897907952467601
Test loss: 1.7206007738908131
Validation loss: 1.6898

-------------------- Epoch 1981 --------------------
Train loss: 1.7937
Test loss: 2.4913024604320526
Test loss: 2.5758654475212097
Validation loss: 2.4913

-------------------- Epoch 1982 --------------------
Train loss: 1.7091
Test loss: 1.4948736305038135
Test loss: 1.5443675716718037
Validation loss: 1.4949

-------------------- Epoch 1983 --------------------
Train loss: 1.6532
Test loss: 1.6486186136802037
Test loss: 1.6731221030155818
Validation loss: 1.6486

-------------------- Epoch 1984 --------------------
Train loss: 1.7223
Test loss: 1.6591836263736088
Test loss: 1.735243906577428
Validation loss: 1.6592

-------------------- Epoch 1985 --------------------
Train loss: 1.6197
Test loss: 1.4730681975682576
Test loss: 1.5112393349409103
New best validation loss: 1.4731, saving model weights to best_model_weights.pth

-------------------- Epoch 1986 --------------------
Train loss: 1.5904
Test loss: 1.5740992724895477
Test loss: 1.6097385783990223
Validation loss: 1.5741

-------------------- Epoch 1987 --------------------
Train loss: 1.8904
Test loss: 1.5301525195439656
Test loss: 1.5637879520654678
Validation loss: 1.5302

-------------------- Epoch 1988 --------------------
Train loss: 1.6276
Test loss: 1.4672847241163254
Test loss: 1.5252761642138164
New best validation loss: 1.4673, saving model weights to best_model_weights.pth

-------------------- Epoch 1989 --------------------
Train loss: 1.6388
Test loss: 1.9309098720550537
Test loss: 1.9990332225958507
Validation loss: 1.9309

-------------------- Epoch 1990 --------------------
Train loss: 1.7636
Test loss: 1.8788104007641475
Test loss: 1.8751588414112728
Validation loss: 1.8788

-------------------- Epoch 1991 --------------------
Train loss: 1.7444
Test loss: 1.7226569851239522
Test loss: 1.7895019849141438
Validation loss: 1.7227

-------------------- Epoch 1992 --------------------
Train loss: 1.6082
Test loss: 2.204413707057635
Test loss: 2.194612135489782
Validation loss: 2.2044

-------------------- Epoch 1993 --------------------
Train loss: 1.6926
Test loss: 1.4669496168692906
Test loss: 1.50189970433712
New best validation loss: 1.4669, saving model weights to best_model_weights.pth

-------------------- Epoch 1994 --------------------
Train loss: 1.6175
Test loss: 1.478632276256879
Test loss: 1.53176415959994
Validation loss: 1.4786

-------------------- Epoch 1995 --------------------
Train loss: 1.6268
Test loss: 1.5162699520587921
Test loss: 1.5725735078255336
Validation loss: 1.5163

-------------------- Epoch 1996 --------------------
Train loss: 1.6236
Test loss: 1.9022790441910427
Test loss: 1.974709302186966
Validation loss: 1.9023

-------------------- Epoch 1997 --------------------
Train loss: 1.5955
Test loss: 1.4787530452013016
Test loss: 1.53920312722524
Validation loss: 1.4788

-------------------- Epoch 1998 --------------------
Train loss: 1.7730
Test loss: 1.7377227892478306
Test loss: 1.7949265787998836
Validation loss: 1.7377

-------------------- Epoch 1999 --------------------
Train loss: 1.6849
Test loss: 1.4683918009201686
Test loss: 1.5048082595070202
Validation loss: 1.4684

-------------------- Epoch 2000 --------------------
Train loss: 1.5857
Test loss: 1.4925101200739543
Test loss: 1.547612523039182
Validation loss: 1.4925

-------------------- Epoch 2001 --------------------
Train loss: 1.7204
Test loss: 1.5708382527033489
Test loss: 1.6389973411957424
Validation loss: 1.5708

-------------------- Epoch 2002 --------------------
Train loss: 1.6292
Test loss: 1.4568946361541748
Test loss: 1.5044602702061336
New best validation loss: 1.4569, saving model weights to best_model_weights.pth

-------------------- Epoch 2003 --------------------
Train loss: 1.6063
Test loss: 2.242395207285881
Test loss: 2.2487904727458954
Validation loss: 2.2424

-------------------- Epoch 2004 --------------------
Train loss: 1.7221
Test loss: 1.4609241237243016
Test loss: 1.5044277980923653
Validation loss: 1.4609

-------------------- Epoch 2005 --------------------
Train loss: 1.5615
Test loss: 1.8626285642385483
Test loss: 1.9157499919335048
Validation loss: 1.8626

-------------------- Epoch 2006 --------------------
Train loss: 1.6182
Test loss: 1.9561033348242443
Test loss: 1.9764681210120518
Validation loss: 1.9561

-------------------- Epoch 2007 --------------------
Train loss: 1.6345
Test loss: 1.553131212790807
Test loss: 1.5859365065892537
Validation loss: 1.5531

-------------------- Epoch 2008 --------------------
Train loss: 1.6225
Test loss: 1.5332453399896622
Test loss: 1.5618742207686107
Validation loss: 1.5332

-------------------- Epoch 2009 --------------------
Train loss: 1.6514
Test loss: 1.9571541398763657
Test loss: 1.9407179007927577
Validation loss: 1.9572

-------------------- Epoch 2010 --------------------
Train loss: 1.6104
Test loss: 2.3840489437182746
Test loss: 2.408088967204094
Validation loss: 2.3840

-------------------- Epoch 2011 --------------------
Train loss: 1.5886
Test loss: 1.9015937596559525
Test loss: 1.9441121468941371
Validation loss: 1.9016

-------------------- Epoch 2012 --------------------
Train loss: 1.5756
Test loss: 1.6553295403718948
Test loss: 1.7107816835244496
Validation loss: 1.6553

-------------------- Epoch 2013 --------------------
Train loss: 1.7906
Test loss: 2.424268419543902
Test loss: 2.4452063143253326
Validation loss: 2.4243

-------------------- Epoch 2014 --------------------
Train loss: 1.6084
Test loss: 1.488939141233762
Test loss: 1.524645835161209
Validation loss: 1.4889

-------------------- Epoch 2015 --------------------
Train loss: 1.7474
Test loss: 1.990717699130376
Test loss: 1.9984973122676213
Validation loss: 1.9907

-------------------- Epoch 2016 --------------------
Train loss: 1.6445
Test loss: 1.6299659858147304
Test loss: 1.6950256824493408
Validation loss: 1.6300

-------------------- Epoch 2017 --------------------
Train loss: 1.5941
Test loss: 1.4639422024289768
Test loss: 1.5075253595908482
Validation loss: 1.4639

-------------------- Epoch 2018 --------------------
Train loss: 1.6105
Test loss: 1.5501564939816792
Test loss: 1.56255046526591
Validation loss: 1.5502

-------------------- Epoch 2019 --------------------
Train loss: 1.6650
Test loss: 2.072746435801188
Test loss: 2.107096622387568
Validation loss: 2.0727

-------------------- Epoch 2020 --------------------
Train loss: 1.5523
Test loss: 1.6392129361629486
Test loss: 1.6625934193531673
Validation loss: 1.6392

-------------------- Epoch 2021 --------------------
Train loss: 1.5862
Test loss: 1.4829212476809819
Test loss: 1.5217503234744072
Validation loss: 1.4829

-------------------- Epoch 2022 --------------------
Train loss: 1.5206
Test loss: 1.4772740701834361
Test loss: 1.5166208694378536
Validation loss: 1.4773

-------------------- Epoch 2023 --------------------
Train loss: 1.5717
Test loss: 1.5096172839403152
Test loss: 1.5468525638182957
Validation loss: 1.5096

-------------------- Epoch 2024 --------------------
Train loss: 2.0787
Test loss: 1.5993022471666336
Test loss: 1.6461187899112701
Validation loss: 1.5993

-------------------- Epoch 2025 --------------------
Train loss: 1.5532
Test loss: 1.5892774959405263
Test loss: 1.626034011443456
Validation loss: 1.5893

-------------------- Epoch 2026 --------------------
Train loss: 1.5723
Test loss: 1.4729789346456528
Test loss: 1.5183479537566502
Validation loss: 1.4730

-------------------- Epoch 2027 --------------------
Train loss: 1.5246
Test loss: 1.523960883418719
Test loss: 1.5644193440675735
Validation loss: 1.5240

-------------------- Epoch 2028 --------------------
Train loss: 1.6537
Test loss: 1.5598127941290538
Test loss: 1.6067941039800644
Validation loss: 1.5598

-------------------- Epoch 2029 --------------------
Train loss: 1.5835
Test loss: 1.5462647378444672
Test loss: 1.586183915535609
Validation loss: 1.5463

-------------------- Epoch 2030 --------------------
Train loss: 1.6191
Test loss: 1.560757542649905
Test loss: 1.5940157771110535
Validation loss: 1.5608

-------------------- Epoch 2031 --------------------
Train loss: 1.5958
Test loss: 1.4367235725124676
Test loss: 1.4831338375806808
New best validation loss: 1.4367, saving model weights to best_model_weights.pth

-------------------- Epoch 2032 --------------------
Train loss: 1.5241
Test loss: 1.4809188544750214
Test loss: 1.5401520033677418
Validation loss: 1.4809

-------------------- Epoch 2033 --------------------
Train loss: 1.5665
Test loss: 1.9929713259140651
Test loss: 2.0213380505641303
Validation loss: 1.9930

-------------------- Epoch 2034 --------------------
Train loss: 1.6251
Test loss: 1.5347790519396465
Test loss: 1.597855418920517
Validation loss: 1.5348

-------------------- Epoch 2035 --------------------
Train loss: 1.5295
Test loss: 2.095017666618029
Test loss: 2.123745267589887
Validation loss: 2.0950

-------------------- Epoch 2036 --------------------
Train loss: 2.4694
Test loss: 1.4405754208564758
Test loss: 1.4819507549206417
Validation loss: 1.4406

-------------------- Epoch 2037 --------------------
Train loss: 1.5357
Test loss: 1.517570326725642
Test loss: 1.5388878732919693
Validation loss: 1.5176

-------------------- Epoch 2038 --------------------
Train loss: 1.4968
Test loss: 1.7078126966953278
Test loss: 1.7768428176641464
Validation loss: 1.7078

-------------------- Epoch 2039 --------------------
Train loss: 1.9727
Test loss: 2.0326910068591437
Test loss: 2.0480630546808243
Validation loss: 2.0327

-------------------- Epoch 2040 --------------------
Train loss: 1.5996
Test loss: 1.560831104715665
Test loss: 1.6151219060023625
Validation loss: 1.5608

-------------------- Epoch 2041 --------------------
Train loss: 1.7958
Test loss: 1.8316821257273357
Test loss: 1.883717159430186
Validation loss: 1.8317

-------------------- Epoch 2042 --------------------
Train loss: 1.6307
Test loss: 1.5393321563800175
Test loss: 1.580776462952296
Validation loss: 1.5393

-------------------- Epoch 2043 --------------------
Train loss: 1.4974
Test loss: 1.4364019831021626
Test loss: 1.4922553946574528
New best validation loss: 1.4364, saving model weights to best_model_weights.pth

-------------------- Epoch 2044 --------------------
Train loss: 1.6141
Test loss: 1.8146146436532338
Test loss: 1.862226774295171
Validation loss: 1.8146

-------------------- Epoch 2045 --------------------
Train loss: 1.6274
Test loss: 1.777664249142011
Test loss: 1.8126389135917027
Validation loss: 1.7777

-------------------- Epoch 2046 --------------------
Train loss: 1.6148
Test loss: 1.472085287173589
Test loss: 1.5219377676645915
Validation loss: 1.4721

-------------------- Epoch 2047 --------------------
Train loss: 1.5565
Test loss: 1.4921973546346028
Test loss: 1.5326954076687496
Validation loss: 1.4922

-------------------- Epoch 2048 --------------------
Train loss: 1.5102
Test loss: 1.4564674695332844
Test loss: 1.4954361567894618
Validation loss: 1.4565

-------------------- Epoch 2049 --------------------
Train loss: 1.5539
Test loss: 1.5889585614204407
Test loss: 1.6415823797384899
Validation loss: 1.5890

-------------------- Epoch 2050 --------------------
Train loss: 1.5071
Test loss: 1.9000373979409535
Test loss: 1.911477655172348
Validation loss: 1.9000

-------------------- Epoch 2051 --------------------
Train loss: 1.5683
Test loss: 1.615944688518842
Test loss: 1.6478642026583354
Validation loss: 1.6159

-------------------- Epoch 2052 --------------------
Train loss: 1.5473
Test loss: 1.4623290499051411
Test loss: 1.4876890828212102
Validation loss: 1.4623

-------------------- Epoch 2053 --------------------
Train loss: 1.5540
Test loss: 1.6193530013163884
Test loss: 1.6783026953538258
Validation loss: 1.6194

-------------------- Epoch 2054 --------------------
Train loss: 1.5038
Test loss: 1.5368148038784664
Test loss: 1.5887504418690999
Validation loss: 1.5368

-------------------- Epoch 2055 --------------------
Train loss: 1.5602
Test loss: 1.8929362495740254
Test loss: 1.9612264583508174
Validation loss: 1.8929

-------------------- Epoch 2056 --------------------
Train loss: 1.5209
Test loss: 1.5331459790468216
Test loss: 1.5885122468074162
Validation loss: 1.5331

-------------------- Epoch 2057 --------------------
Train loss: 1.5123
Test loss: 1.793888250986735
Test loss: 1.8522187918424606
Validation loss: 1.7939

-------------------- Epoch 2058 --------------------
Train loss: 1.5632
Test loss: 1.464293085038662
Test loss: 1.5133507624268532
Validation loss: 1.4643

-------------------- Epoch 2059 --------------------
Train loss: 1.5742
Test loss: 1.544060356914997
Test loss: 1.6027764479319255
Validation loss: 1.5441

-------------------- Epoch 2060 --------------------
Train loss: 1.5045
Test loss: 1.6403819421927135
Test loss: 1.7000857939322789
Validation loss: 1.6404

-------------------- Epoch 2061 --------------------
Train loss: 1.5039
Test loss: 1.471986676255862
Test loss: 1.5066456000010173
Validation loss: 1.4720

-------------------- Epoch 2062 --------------------
Train loss: 1.4787
Test loss: 1.5942861884832382
Test loss: 1.6136403481165569
Validation loss: 1.5943

-------------------- Epoch 2063 --------------------
Train loss: 1.5117
Test loss: 1.5886576424042385
Test loss: 1.6116472085316975
Validation loss: 1.5887

-------------------- Epoch 2064 --------------------
Train loss: 1.5323
Test loss: 1.5452060798803966
Test loss: 1.5967952112356822
Validation loss: 1.5452

-------------------- Epoch 2065 --------------------
Train loss: 1.6196
Test loss: 1.598896101117134
Test loss: 1.6396461576223373
Validation loss: 1.5989

-------------------- Epoch 2066 --------------------
Train loss: 1.5205
Test loss: 1.5922422260046005
Test loss: 1.650349075595538
Validation loss: 1.5922

-------------------- Epoch 2067 --------------------
Train loss: 1.4959
Test loss: 1.9084110508362453
Test loss: 1.9339368989070256
Validation loss: 1.9084

-------------------- Epoch 2068 --------------------
Train loss: 1.5329
Test loss: 1.6911833932002385
Test loss: 1.7301330765088399
Validation loss: 1.6912

-------------------- Epoch 2069 --------------------
Train loss: 1.4875
Test loss: 1.6399971197048824
Test loss: 1.7017975350220997
Validation loss: 1.6400

-------------------- Epoch 2070 --------------------
Train loss: 1.5258
Test loss: 1.5314695090055466
Test loss: 1.5719569673140843
Validation loss: 1.5315

-------------------- Epoch 2071 --------------------
Train loss: 1.5419
Test loss: 1.551962321003278
Test loss: 1.590032438437144
Validation loss: 1.5520

-------------------- Epoch 2072 --------------------
Train loss: 1.4940
Test loss: 1.45454906920592
Test loss: 1.5017634878555934
Validation loss: 1.4545

-------------------- Epoch 2073 --------------------
Train loss: 1.4889
Test loss: 1.593163549900055
Test loss: 1.6261188338200252
Validation loss: 1.5932

-------------------- Epoch 2074 --------------------
Train loss: 1.4808
Test loss: 1.5782640675703685
Test loss: 1.5960860947767894
Validation loss: 1.5783

-------------------- Epoch 2075 --------------------
Train loss: 1.5504
Test loss: 1.455840786298116
Test loss: 1.5137615849574406
Validation loss: 1.4558

-------------------- Epoch 2076 --------------------
Train loss: 1.4843
Test loss: 1.5684428835908573
Test loss: 1.6259782363971074
Validation loss: 1.5684

-------------------- Epoch 2077 --------------------
Train loss: 1.4759
Test loss: 1.4502763549486797
Test loss: 1.4890265514453251
Validation loss: 1.4503

-------------------- Epoch 2078 --------------------
Train loss: 1.6563
Test loss: 1.5821980585654576
Test loss: 1.6346280475457509
Validation loss: 1.5822

-------------------- Epoch 2079 --------------------
Train loss: 1.5145
Test loss: 1.4394379382332165
Test loss: 1.4807062596082687
Validation loss: 1.4394

-------------------- Epoch 2080 --------------------
Train loss: 1.4845
Test loss: 1.4613724499940872
Test loss: 1.5077234705289204
Validation loss: 1.4614

-------------------- Epoch 2081 --------------------
Train loss: 1.4794
Test loss: 1.4612389703591664
Test loss: 1.4990152021249135
Validation loss: 1.4612

-------------------- Epoch 2082 --------------------
Train loss: 1.4613
Test loss: 1.4736497898896534
Test loss: 1.5269407282272975
Validation loss: 1.4736

-------------------- Epoch 2083 --------------------
Train loss: 1.5254
Test loss: 1.5652516980965931
Test loss: 1.592782437801361
Validation loss: 1.5653

-------------------- Epoch 2084 --------------------
Train loss: 1.4943
Test loss: 1.4584616273641586
Test loss: 1.4925522754589717
Validation loss: 1.4585

-------------------- Epoch 2085 --------------------
Train loss: 1.4712
Test loss: 1.4510662257671356
Test loss: 1.5015566796064377
Validation loss: 1.4511

-------------------- Epoch 2086 --------------------
Train loss: 1.4952
Test loss: 1.5497083912293117
Test loss: 1.576697587966919
Validation loss: 1.5497

-------------------- Epoch 2087 --------------------
Train loss: 1.4874
Test loss: 1.4558984239896138
Test loss: 1.500423938035965
Validation loss: 1.4559

-------------------- Epoch 2088 --------------------
Train loss: 1.4550
Test loss: 1.9434496064980824
Test loss: 2.008231366674105
Validation loss: 1.9434

-------------------- Epoch 2089 --------------------
Train loss: 1.5304
Test loss: 1.4402890553077061
Test loss: 1.4788725227117538
Validation loss: 1.4403

-------------------- Epoch 2090 --------------------
Train loss: 1.4982
Test loss: 1.5092630684375763
Test loss: 1.5601635624965031
Validation loss: 1.5093

-------------------- Epoch 2091 --------------------
Train loss: 1.5053
Test loss: 1.6901375899712245
Test loss: 1.7496541092793148
Validation loss: 1.6901

-------------------- Epoch 2092 --------------------
Train loss: 1.4848
Test loss: 1.5178421189387639
Test loss: 1.540335476398468
Validation loss: 1.5178

-------------------- Epoch 2093 --------------------
Train loss: 1.8829
Test loss: 1.4661164234081905
Test loss: 1.5042054206132889
Validation loss: 1.4661

-------------------- Epoch 2094 --------------------
Train loss: 1.4797
Test loss: 1.4596698035796483
Test loss: 1.509500538309415
Validation loss: 1.4597

-------------------- Epoch 2095 --------------------
Train loss: 1.4744
Test loss: 1.6817767669757206
Test loss: 1.7215383003155391
Validation loss: 1.6818

-------------------- Epoch 2096 --------------------
Train loss: 1.5164
Test loss: 1.4486523220936458
Test loss: 1.4905279874801636
Validation loss: 1.4487

-------------------- Epoch 2097 --------------------
Train loss: 1.4778
Test loss: 1.5836405406395595
Test loss: 1.6205272376537323
Validation loss: 1.5836

-------------------- Epoch 2098 --------------------
Train loss: 1.4881
Test loss: 1.5851537237564723
Test loss: 1.637736901640892
Validation loss: 1.5852

-------------------- Epoch 2099 --------------------
Train loss: 1.4624
Test loss: 1.4619885335365932
Test loss: 1.495249221722285
Validation loss: 1.4620

-------------------- Epoch 2100 --------------------
Train loss: 1.5256
Test loss: 1.5966300517320633
Test loss: 1.6338049322366714
Validation loss: 1.5966

-------------------- Epoch 2101 --------------------
Train loss: 1.4721
Test loss: 1.4566660275061925
Test loss: 1.4879678388436635
Validation loss: 1.4567

-------------------- Epoch 2102 --------------------
Train loss: 1.6159
Test loss: 1.5169051736593246
Test loss: 1.5507157444953918
Validation loss: 1.5169

-------------------- Epoch 2103 --------------------
Train loss: 1.4471
Test loss: 1.5459991643826168
Test loss: 1.58097908894221
Validation loss: 1.5460

-------------------- Epoch 2104 --------------------
Train loss: 1.4599
Test loss: 1.4449278215567272
Test loss: 1.480191300312678
Validation loss: 1.4449

-------------------- Epoch 2105 --------------------
Train loss: 1.4661
Test loss: 1.4426682939132054
Test loss: 1.4768379479646683
Validation loss: 1.4427

-------------------- Epoch 2106 --------------------
Train loss: 1.4471
Test loss: 1.4513889104127884
Test loss: 1.5013254980246227
Validation loss: 1.4514

-------------------- Epoch 2107 --------------------
Train loss: 1.4557
Test loss: 1.458604097366333
Test loss: 1.4971061249574025
Validation loss: 1.4586

-------------------- Epoch 2108 --------------------
Train loss: 1.4691
Test loss: 1.4475861936807632
Test loss: 1.4920190821091335
Validation loss: 1.4476

-------------------- Epoch 2109 --------------------
Train loss: 1.4561
Test loss: 1.438076337178548
Test loss: 1.487984836101532
Validation loss: 1.4381

-------------------- Epoch 2110 --------------------
Train loss: 1.8627
Test loss: 1.5327669978141785
Test loss: 1.5635914007822673
Validation loss: 1.5328

-------------------- Epoch 2111 --------------------
Train loss: 1.4729
Test loss: 1.436688872675101
Test loss: 1.4854346017042797
Validation loss: 1.4367

-------------------- Epoch 2112 --------------------
Train loss: 1.4422
Test loss: 1.4367281446854274
Test loss: 1.4894006351629894
Validation loss: 1.4367

-------------------- Epoch 2113 --------------------
Train loss: 1.6212
Test loss: 1.5024004528919856
Test loss: 1.5436015576124191
Validation loss: 1.5024

-------------------- Epoch 2114 --------------------
Train loss: 1.4457
Test loss: 1.4452084004878998
Test loss: 1.4920525153477986
Validation loss: 1.4452

-------------------- Epoch 2115 --------------------
Train loss: 1.4594
Test loss: 1.4384807472427685
Test loss: 1.4818693473935127
Validation loss: 1.4385

-------------------- Epoch 2116 --------------------
Train loss: 1.8913
Test loss: 1.4461974526445072
Test loss: 1.4904559602340062
Validation loss: 1.4462

-------------------- Epoch 2117 --------------------
Train loss: 1.4431
Test loss: 1.4487562378247578
Test loss: 1.494974950949351
Validation loss: 1.4488

-------------------- Epoch 2118 --------------------
Train loss: 1.4307
Test loss: 1.4355331808328629
Test loss: 1.4812074576814969
New best validation loss: 1.4355, saving model weights to best_model_weights.pth

-------------------- Epoch 2119 --------------------
Train loss: 1.4457
Test loss: 1.450838416814804
Test loss: 1.5020537426074345
Validation loss: 1.4508

-------------------- Epoch 2120 --------------------
Train loss: 1.4430
Test loss: 1.5308728913466136
Test loss: 1.5922951400279999
Validation loss: 1.5309

-------------------- Epoch 2121 --------------------
Train loss: 1.4506
Test loss: 1.4331278825799625
Test loss: 1.479337138434251
New best validation loss: 1.4331, saving model weights to best_model_weights.pth

-------------------- Epoch 2122 --------------------
Train loss: 1.7540
Test loss: 1.4381600121657054
Test loss: 1.4863150641322136
Validation loss: 1.4382

-------------------- Epoch 2123 --------------------
Train loss: 1.6925
Test loss: 1.4716059317191441
Test loss: 1.504026745756467
Validation loss: 1.4716

-------------------- Epoch 2124 --------------------
Train loss: 1.4498
Test loss: 1.4319430366158485
Test loss: 1.4776556889216106
New best validation loss: 1.4319, saving model weights to best_model_weights.pth

-------------------- Epoch 2125 --------------------
Train loss: 1.4441
Test loss: 1.558576797445615
Test loss: 1.5918201605478923
Validation loss: 1.5586

-------------------- Epoch 2126 --------------------
Train loss: 1.6032
Test loss: 1.4572604795296986
Test loss: 1.501558909813563
Validation loss: 1.4573

-------------------- Epoch 2127 --------------------
Train loss: 1.4300
Test loss: 1.435959001382192
Test loss: 1.4803122505545616
Validation loss: 1.4360

-------------------- Epoch 2128 --------------------
Train loss: 1.4371
Test loss: 1.4310616527994473
Test loss: 1.4802149310708046
New best validation loss: 1.4311, saving model weights to best_model_weights.pth

-------------------- Epoch 2129 --------------------
Train loss: 1.4491
Test loss: 1.4642409682273865
Test loss: 1.501392086346944
Validation loss: 1.4642

-------------------- Epoch 2130 --------------------
Train loss: 1.4613
Test loss: 1.4428469811876614
Test loss: 1.4821476538976033
Validation loss: 1.4428

-------------------- Epoch 2131 --------------------
Train loss: 1.4444
Test loss: 1.4267940844098728
Test loss: 1.4707209542393684
New best validation loss: 1.4268, saving model weights to best_model_weights.pth

-------------------- Epoch 2132 --------------------
Train loss: 1.4309
Test loss: 1.4621003518501918
Test loss: 1.500249480207761
Validation loss: 1.4621

-------------------- Epoch 2133 --------------------
Train loss: 2.4101
Test loss: 1.56187937160333
Test loss: 1.6034264067808788
Validation loss: 1.5619

-------------------- Epoch 2134 --------------------
Train loss: 1.4329
Test loss: 1.4263338794310887
Test loss: 1.4800142124295235
New best validation loss: 1.4263, saving model weights to best_model_weights.pth

-------------------- Epoch 2135 --------------------
Train loss: 1.6538
Test loss: 1.4386938338478406
Test loss: 1.48146141320467
Validation loss: 1.4387

-------------------- Epoch 2136 --------------------
Train loss: 1.4203
Test loss: 1.4417559628685315
Test loss: 1.484164463977019
Validation loss: 1.4418

-------------------- Epoch 2137 --------------------
Train loss: 1.4412
Test loss: 1.4590385605891545
Test loss: 1.503038873275121
Validation loss: 1.4590

-------------------- Epoch 2138 --------------------
Train loss: 1.4208
Test loss: 1.4609019607305527
Test loss: 1.5091112107038498
Validation loss: 1.4609

-------------------- Epoch 2139 --------------------
Train loss: 1.4246
Test loss: 1.438177893559138
Test loss: 1.48660043378671
Validation loss: 1.4382

-------------------- Epoch 2140 --------------------
Train loss: 1.4246
Test loss: 1.4723486204942067
Test loss: 1.518507773677508
Validation loss: 1.4723

-------------------- Epoch 2141 --------------------
Train loss: 1.4431
Test loss: 1.5139281104008357
Test loss: 1.542539969086647
Validation loss: 1.5139

-------------------- Epoch 2142 --------------------
Train loss: 1.4361
Test loss: 1.4291312098503113
Test loss: 1.4679511214296024
Validation loss: 1.4291

-------------------- Epoch 2143 --------------------
Train loss: 1.4217
Test loss: 1.4589561000466347
Test loss: 1.5039531240860622
Validation loss: 1.4590

-------------------- Epoch 2144 --------------------
Train loss: 1.5418
Test loss: 1.438836467762788
Test loss: 1.4797477970520656
Validation loss: 1.4388

-------------------- Epoch 2145 --------------------
Train loss: 1.4242
Test loss: 1.4616167570153873
Test loss: 1.4989689340194066
Validation loss: 1.4616

-------------------- Epoch 2146 --------------------
Train loss: 1.4210
Test loss: 1.4383672525485356
Test loss: 1.4804669717947643
Validation loss: 1.4384

-------------------- Epoch 2147 --------------------
Train loss: 1.4203
Test loss: 1.4260615309079487
Test loss: 1.4688207904497783
New best validation loss: 1.4261, saving model weights to best_model_weights.pth

-------------------- Epoch 2148 --------------------
Train loss: 1.8639
Test loss: 1.513458435734113
Test loss: 1.5408859451611836
Validation loss: 1.5135

-------------------- Epoch 2149 --------------------
Train loss: 1.4972
Test loss: 1.4828375031550725
Test loss: 1.5201934178670247
Validation loss: 1.4828

-------------------- Epoch 2150 --------------------
Train loss: 1.5186
Test loss: 1.5323836306730907
Test loss: 1.556838924686114
Validation loss: 1.5324

-------------------- Epoch 2151 --------------------
Train loss: 1.4313
Test loss: 1.4268466557065647
Test loss: 1.4695617780089378
Validation loss: 1.4268

-------------------- Epoch 2152 --------------------
Train loss: 1.4254
Test loss: 1.4252950549125671
Test loss: 1.4709389805793762
New best validation loss: 1.4253, saving model weights to best_model_weights.pth

-------------------- Epoch 2153 --------------------
Train loss: 1.4126
Test loss: 1.432386393348376
Test loss: 1.4797956322630246
Validation loss: 1.4324

-------------------- Epoch 2154 --------------------
Train loss: 1.4158
Test loss: 1.4515703121821086
Test loss: 1.4971019526322682
Validation loss: 1.4516

-------------------- Epoch 2155 --------------------
Train loss: 1.4143
Test loss: 1.4264663358529408
Test loss: 1.47039678444465
Validation loss: 1.4265

-------------------- Epoch 2156 --------------------
Train loss: 1.4588
Test loss: 1.4655157178640366
Test loss: 1.5167694091796875
Validation loss: 1.4655

-------------------- Epoch 2157 --------------------
Train loss: 1.4138
Test loss: 1.4589759955803554
Test loss: 1.5071936796108882
Validation loss: 1.4590

-------------------- Epoch 2158 --------------------
Train loss: 1.4182
Test loss: 1.4429316893219948
Test loss: 1.4801077445348103
Validation loss: 1.4429

-------------------- Epoch 2159 --------------------
Train loss: 1.4168
Test loss: 1.4509931951761246
Test loss: 1.4966365297635396
Validation loss: 1.4510

-------------------- Epoch 2160 --------------------
Train loss: 1.4179
Test loss: 1.4296097159385681
Test loss: 1.4738457848628361
Validation loss: 1.4296

-------------------- Epoch 2161 --------------------
Train loss: 1.4040
Test loss: 1.4313864260911942
Test loss: 1.4806610097487767
Validation loss: 1.4314

-------------------- Epoch 2162 --------------------
Train loss: 1.4171
Test loss: 1.4746286223332088
Test loss: 1.5046116610368092
Validation loss: 1.4746

-------------------- Epoch 2163 --------------------
Train loss: 1.4094
Test loss: 1.4900373990337055
Test loss: 1.527225171526273
Validation loss: 1.4900

-------------------- Epoch 2164 --------------------
Train loss: 1.4125
Test loss: 1.4493762254714966
Test loss: 1.4844334522883098
Validation loss: 1.4494

-------------------- Epoch 2165 --------------------
Train loss: 1.4159
Test loss: 1.431579704085986
Test loss: 1.4745202163855236
Validation loss: 1.4316

-------------------- Epoch 2166 --------------------
Train loss: 1.4059
Test loss: 1.4325691610574722
Test loss: 1.4722036545475323
Validation loss: 1.4326

-------------------- Epoch 2167 --------------------
Train loss: 1.4090
Test loss: 1.429586465160052
Test loss: 1.4696110685666401
Validation loss: 1.4296

-------------------- Epoch 2168 --------------------
Train loss: 1.4029
Test loss: 1.4279431328177452
Test loss: 1.4711248601476352
Validation loss: 1.4279

-------------------- Epoch 2169 --------------------
Train loss: 1.4212
Test loss: 1.4323703746000926
Test loss: 1.476133719086647
Validation loss: 1.4324

-------------------- Epoch 2170 --------------------
Train loss: 1.4081
Test loss: 1.4347806423902512
Test loss: 1.4768091291189194
Validation loss: 1.4348

-------------------- Epoch 2171 --------------------
Train loss: 1.4036
Test loss: 1.429610977570216
Test loss: 1.4759928956627846
Validation loss: 1.4296

-------------------- Epoch 2172 --------------------
Train loss: 1.4122
Test loss: 1.4289830724398296
Test loss: 1.4728298385938008
Validation loss: 1.4290

-------------------- Epoch 2173 --------------------
Train loss: 1.4037
Test loss: 1.4313190231720607
Test loss: 1.4737908467650414
Validation loss: 1.4313

-------------------- Epoch 2174 --------------------
Train loss: 1.4092
Test loss: 1.4399822453657787
Test loss: 1.483827682832877
Validation loss: 1.4400

-------------------- Epoch 2175 --------------------
Train loss: 1.4096
Test loss: 1.43067467212677
Test loss: 1.4702989185849826
Validation loss: 1.4307

-------------------- Epoch 2176 --------------------
Train loss: 1.4106
Test loss: 1.431167150537173
Test loss: 1.4706044395764668
Validation loss: 1.4312

-------------------- Epoch 2177 --------------------
Train loss: 1.4027
Test loss: 1.4274197469154994
Test loss: 1.469219279785951
Validation loss: 1.4274

-------------------- Epoch 2178 --------------------
Train loss: 2.0021
Test loss: 1.4272375206152599
Test loss: 1.4714229827125866
Validation loss: 1.4272

-------------------- Epoch 2179 --------------------
Train loss: 1.4014
Test loss: 1.4271414031585057
Test loss: 1.4701453372836113
Validation loss: 1.4271

-------------------- Epoch 2180 --------------------
Train loss: 1.4301
Test loss: 1.4446238329013188
Test loss: 1.4830878352125485
Validation loss: 1.4446

-------------------- Epoch 2181 --------------------
Train loss: 1.4149
Test loss: 1.4272848467032115
Test loss: 1.4691826850175858
Validation loss: 1.4273

-------------------- Epoch 2182 --------------------
Train loss: 1.4099
Test loss: 1.4268081411719322
Test loss: 1.469208113849163
Validation loss: 1.4268

-------------------- Epoch 2183 --------------------
Train loss: 1.3947
Test loss: 1.4344603319962819
Test loss: 1.4768704548478127
Validation loss: 1.4345

-------------------- Epoch 2184 --------------------
Train loss: 1.4086
Test loss: 1.425538954635461
Test loss: 1.4695589169859886
Validation loss: 1.4255

-------------------- Epoch 2185 --------------------
Train loss: 1.6004
Test loss: 1.4290196696917217
Test loss: 1.4735567048192024
Validation loss: 1.4290

-------------------- Epoch 2186 --------------------
Train loss: 1.4068
Test loss: 1.4266434411207836
Test loss: 1.469257893661658
Validation loss: 1.4266

-------------------- Epoch 2187 --------------------
Train loss: 1.3958
Test loss: 1.430939291914304
Test loss: 1.4773310124874115
Validation loss: 1.4309

-------------------- Epoch 2188 --------------------
Train loss: 1.7474
Test loss: 1.4266246631741524
Test loss: 1.4693085898955662
Validation loss: 1.4266

-------------------- Epoch 2189 --------------------
Train loss: 1.4001
Test loss: 1.4300713787476222
Test loss: 1.4733561823765438
Validation loss: 1.4301

-------------------- Epoch 2190 --------------------
Train loss: 1.3961
Test loss: 1.430408589541912
Test loss: 1.4728529850641887
Validation loss: 1.4304

-------------------- Epoch 2191 --------------------
Train loss: 1.3965
Test loss: 1.4281665210922558
Test loss: 1.4713893582423527
Validation loss: 1.4282

-------------------- Epoch 2192 --------------------
Train loss: 1.4004
Test loss: 1.4343342234690983
Test loss: 1.4803913061817486
Validation loss: 1.4343

-------------------- Epoch 2193 --------------------
Train loss: 1.6041
Test loss: 1.4257368942101796
Test loss: 1.4692607671022415
Validation loss: 1.4257

-------------------- Epoch 2194 --------------------
Train loss: 1.3970
Test loss: 1.4265777419010799
Test loss: 1.4704907536506653
Validation loss: 1.4266

-------------------- Epoch 2195 --------------------
Train loss: 1.4002
Test loss: 1.4282019436359406
Test loss: 1.4699085627992947
Validation loss: 1.4282

-------------------- Epoch 2196 --------------------
Train loss: 1.4015
Test loss: 1.4312857290108998
Test loss: 1.4754944071173668
Validation loss: 1.4313

-------------------- Epoch 2197 --------------------
Train loss: 1.3969
Test loss: 1.4291425148646038
Test loss: 1.470378654698531
Validation loss: 1.4291

-------------------- Epoch 2198 --------------------
Train loss: 1.3980
Test loss: 1.4322530875603359
Test loss: 1.4782120510935783
Validation loss: 1.4323

-------------------- Epoch 2199 --------------------
Train loss: 1.4006
Test loss: 1.4294040525952976
Test loss: 1.4724904944499333
Validation loss: 1.4294

-------------------- Epoch 2200 --------------------
Train loss: 1.3957
Test loss: 1.4264643490314484
Test loss: 1.4689465214808781
Validation loss: 1.4265

-------------------- Epoch 2201 --------------------
Train loss: 1.4008
Test loss: 1.4272915696104367
Test loss: 1.4691940074165661
Validation loss: 1.4273

-------------------- Epoch 2202 --------------------
Train loss: 1.3995
Test loss: 1.427122471233209
Test loss: 1.4686521639426549
Validation loss: 1.4271

-------------------- Epoch 2203 --------------------
Train loss: 1.3970
Test loss: 1.4277995948990185
Test loss: 1.4721767380833626
Validation loss: 1.4278

-------------------- Epoch 2204 --------------------
Train loss: 1.3894
Test loss: 1.4277929440140724
Test loss: 1.4690733328461647
Validation loss: 1.4278

-------------------- Epoch 2205 --------------------
Train loss: 1.3930
Test loss: 1.4261311143636703
Test loss: 1.4682299867272377
Validation loss: 1.4261

-------------------- Epoch 2206 --------------------
Train loss: 1.8932
Test loss: 1.4263366808493931
Test loss: 1.4688862984379132
Validation loss: 1.4263

-------------------- Epoch 2207 --------------------
Train loss: 1.3967
Test loss: 1.4278782208760579
Test loss: 1.4688615649938583
Validation loss: 1.4279

-------------------- Epoch 2208 --------------------
Train loss: 1.3944
Test loss: 1.4270270789662998
Test loss: 1.4686984245975812
Validation loss: 1.4270

-------------------- Epoch 2209 --------------------
Train loss: 1.3919
Test loss: 1.4264924650390942
Test loss: 1.4691411902507145
Validation loss: 1.4265

-------------------- Epoch 2210 --------------------
Train loss: 1.3968
Test loss: 1.4270569384098053
Test loss: 1.4704414134224255
Validation loss: 1.4271

-------------------- Epoch 2211 --------------------
Train loss: 1.3901
Test loss: 1.4265134806434314
Test loss: 1.4703504194815953
Validation loss: 1.4265

-------------------- Epoch 2212 --------------------
Train loss: 1.3935
Test loss: 1.4261849969625473
Test loss: 1.468781441450119
Validation loss: 1.4262

-------------------- Epoch 2213 --------------------
Train loss: 1.4649
Test loss: 1.4267168616255124
Test loss: 1.4686889722943306
Validation loss: 1.4267

-------------------- Epoch 2214 --------------------
Train loss: 1.3917
Test loss: 1.4260418266057968
Test loss: 1.4688523337244987
Validation loss: 1.4260

-------------------- Epoch 2215 --------------------
Train loss: 1.3941
Test loss: 1.4266278843084972
Test loss: 1.4699871341387432
Validation loss: 1.4266

-------------------- Epoch 2216 --------------------
Train loss: 1.3879
Test loss: 1.4264102602998416
Test loss: 1.46857488155365
Validation loss: 1.4264

-------------------- Epoch 2217 --------------------
Train loss: 1.3898
Test loss: 1.4265205189585686
Test loss: 1.4696720466017723
Validation loss: 1.4265

-------------------- Epoch 2218 --------------------
Train loss: 1.3970
Test loss: 1.4264474113782246
Test loss: 1.4695501203338306
Validation loss: 1.4264

-------------------- Epoch 2219 --------------------
Train loss: 1.4659
Test loss: 1.4264725695053737
Test loss: 1.4687215213974316
Validation loss: 1.4265

-------------------- Epoch 2220 --------------------
Train loss: 1.3918
Test loss: 1.4262730007370312
Test loss: 1.4692396620909374
Validation loss: 1.4263

-------------------- Epoch 2221 --------------------
Train loss: 1.6561
Test loss: 2.842023437221845
Test loss: 2.918590029080709
Validation loss: 2.8420

-------------------- Epoch 2222 --------------------
Train loss: 1.6173
Test loss: 1.7086832374334335
Test loss: 1.7771934072176616
Validation loss: 1.7087

-------------------- Epoch 2223 --------------------
Train loss: 1.6926
Test loss: 1.9641864597797394
Test loss: 2.0120045443375907
Validation loss: 1.9642

-------------------- Epoch 2224 --------------------
Train loss: 1.6676
Test loss: 2.7858371982971826
Test loss: 2.853579709927241
Validation loss: 2.7858

-------------------- Epoch 2225 --------------------
Train loss: 1.7048
Test loss: 2.853849778572718
Test loss: 2.9493846396605172
Validation loss: 2.8538

-------------------- Epoch 2226 --------------------
Train loss: 1.6185
Test loss: 1.9412109007438023
Test loss: 2.005116954445839
Validation loss: 1.9412

-------------------- Epoch 2227 --------------------
Train loss: 1.6301
Test loss: 1.8222815444072087
Test loss: 1.88138547539711
Validation loss: 1.8223

-------------------- Epoch 2228 --------------------
Train loss: 1.7655
Test loss: 2.9522341390450797
Test loss: 2.9692382216453552
Validation loss: 2.9522

-------------------- Epoch 2229 --------------------
Train loss: 1.8295
Test loss: 1.7685747394959133
Test loss: 1.7985908389091492
Validation loss: 1.7686

-------------------- Epoch 2230 --------------------
Train loss: 1.6237
Test loss: 1.5529491553703945
Test loss: 1.5820260345935822
Validation loss: 1.5529

-------------------- Epoch 2231 --------------------
Train loss: 2.1030
Test loss: 1.996624047557513
Test loss: 2.0647554645935693
Validation loss: 1.9966

-------------------- Epoch 2232 --------------------
Train loss: 1.7875
Test loss: 2.218070313334465
Test loss: 2.2702700346708298
Validation loss: 2.2181

-------------------- Epoch 2233 --------------------
Train loss: 1.6635
Test loss: 2.021341343720754
Test loss: 2.090896104772886
Validation loss: 2.0213

-------------------- Epoch 2234 --------------------
Train loss: 1.5507
Test loss: 1.5197678705056508
Test loss: 1.5686205327510834
Validation loss: 1.5198

-------------------- Epoch 2235 --------------------
Train loss: 1.5299
Test loss: 1.650027021765709
Test loss: 1.6823992431163788
Validation loss: 1.6500

-------------------- Epoch 2236 --------------------
Train loss: 1.7531
Test loss: 1.763159101208051
Test loss: 1.786263644695282
Validation loss: 1.7632

-------------------- Epoch 2237 --------------------
Train loss: 1.6000
Test loss: 2.340908855199814
Test loss: 2.397287314136823
Validation loss: 2.3409

-------------------- Epoch 2238 --------------------
Train loss: 1.7286
Test loss: 1.660218859712283
Test loss: 1.7210512161254883
Validation loss: 1.6602

-------------------- Epoch 2239 --------------------
Train loss: 1.5934
Test loss: 1.496554121375084
Test loss: 1.5333728442589443
Validation loss: 1.4966

-------------------- Epoch 2240 --------------------
Train loss: 1.6264
Test loss: 1.7784674714008968
Test loss: 1.7680043975512187
Validation loss: 1.7785

-------------------- Epoch 2241 --------------------
Train loss: 1.6313
Test loss: 1.5480589518944423
Test loss: 1.5524518887201946
Validation loss: 1.5481

-------------------- Epoch 2242 --------------------
Train loss: 1.6215
Test loss: 1.6263703852891922
Test loss: 1.6531871408224106
Validation loss: 1.6264

-------------------- Epoch 2243 --------------------
Train loss: 1.7319
Test loss: 2.429832806189855
Test loss: 2.4783815989891687
Validation loss: 2.4298

-------------------- Epoch 2244 --------------------
Train loss: 1.6428
Test loss: 1.656355584661166
Test loss: 1.6713382452726364
Validation loss: 1.6564

-------------------- Epoch 2245 --------------------
Train loss: 1.6282
Test loss: 1.5002061029275258
Test loss: 1.5525353501240413
Validation loss: 1.5002

-------------------- Epoch 2246 --------------------
Train loss: 1.5485
Test loss: 2.2036836246649423
Test loss: 2.2432841708262763
Validation loss: 2.2037

-------------------- Epoch 2247 --------------------
Train loss: 1.6492
Test loss: 1.6053608655929565
Test loss: 1.6380082021156948
Validation loss: 1.6054

-------------------- Epoch 2248 --------------------
Train loss: 1.6605
Test loss: 2.1761774768431983
Test loss: 2.1937493632237115
Validation loss: 2.1762

-------------------- Epoch 2249 --------------------
Train loss: 1.6024
Test loss: 1.477333868543307
Test loss: 1.4999705304702122
Validation loss: 1.4773

-------------------- Epoch 2250 --------------------
Train loss: 1.6282
Test loss: 1.4925621648629506
Test loss: 1.5669562021891277
Validation loss: 1.4926

-------------------- Epoch 2251 --------------------
Train loss: 1.6664
Test loss: 2.014876514673233
Test loss: 2.01884455482165
Validation loss: 2.0149

-------------------- Epoch 2252 --------------------
Train loss: 1.5905
Test loss: 1.5391314725081127
Test loss: 1.5587354252735774
Validation loss: 1.5391

-------------------- Epoch 2253 --------------------
Train loss: 1.7403
Test loss: 1.6014642367760341
Test loss: 1.6486392617225647
Validation loss: 1.6015

-------------------- Epoch 2254 --------------------
Train loss: 1.6249
Test loss: 1.7913701385259628
Test loss: 1.866208404302597
Validation loss: 1.7914

-------------------- Epoch 2255 --------------------
Train loss: 1.9214
Test loss: 3.31409482161204
Test loss: 3.3542869289716086
Validation loss: 3.3141

-------------------- Epoch 2256 --------------------
Train loss: 1.7346
Test loss: 1.6591658492883046
Test loss: 1.6947234570980072
Validation loss: 1.6592

-------------------- Epoch 2257 --------------------
Train loss: 1.6200
Test loss: 1.62162813047568
Test loss: 1.6500353912512462
Validation loss: 1.6216

-------------------- Epoch 2258 --------------------
Train loss: 1.7954
Test loss: 1.4736866056919098
Test loss: 1.5157863199710846
Validation loss: 1.4737

-------------------- Epoch 2259 --------------------
Train loss: 1.5794
Test loss: 2.2389200727144876
Test loss: 2.3148447473843894
Validation loss: 2.2389

-------------------- Epoch 2260 --------------------
Train loss: 1.7860
Test loss: 2.5549403627713523
Test loss: 2.5678694744904837
Validation loss: 2.5549

-------------------- Epoch 2261 --------------------
Train loss: 1.6202
Test loss: 1.5436595280965169
Test loss: 1.5913282185792923
Validation loss: 1.5437

-------------------- Epoch 2262 --------------------
Train loss: 1.5868
Test loss: 1.6682611852884293
Test loss: 1.7262056022882462
Validation loss: 1.6683

-------------------- Epoch 2263 --------------------
Train loss: 1.6854
Test loss: 1.6309302200873692
Test loss: 1.6470979104439418
Validation loss: 1.6309

-------------------- Epoch 2264 --------------------
Train loss: 1.6818
Test loss: 1.6033230970303218
Test loss: 1.633958141009013
Validation loss: 1.6033

-------------------- Epoch 2265 --------------------
Train loss: 1.6909
Test loss: 1.4730956852436066
Test loss: 1.5173799594243367
Validation loss: 1.4731

-------------------- Epoch 2266 --------------------
Train loss: 1.6631
Test loss: 2.264071762561798
Test loss: 2.3526811599731445
Validation loss: 2.2641

-------------------- Epoch 2267 --------------------
Train loss: 1.7285
Test loss: 3.478451192378998
Test loss: 3.5401543776194253
Validation loss: 3.4785

-------------------- Epoch 2268 --------------------
Train loss: 1.9031
Test loss: 1.5688789536555607
Test loss: 1.5936442017555237
Validation loss: 1.5689

-------------------- Epoch 2269 --------------------
Train loss: 1.6138
Test loss: 1.6270528982083003
Test loss: 1.6863677302996318
Validation loss: 1.6271

-------------------- Epoch 2270 --------------------
Train loss: 1.6955
Test loss: 1.57401738067468
Test loss: 1.6341000994046528
Validation loss: 1.5740

-------------------- Epoch 2271 --------------------
Train loss: 1.5698
Test loss: 2.0151538252830505
Test loss: 2.028538544972738
Validation loss: 2.0152

-------------------- Epoch 2272 --------------------
Train loss: 1.5624
Test loss: 1.5275638177990913
Test loss: 1.5852257013320923
Validation loss: 1.5276

-------------------- Epoch 2273 --------------------
Train loss: 1.6698
Test loss: 1.9337448676427205
Test loss: 1.964615136384964
Validation loss: 1.9337

-------------------- Epoch 2274 --------------------
Train loss: 1.6387
Test loss: 2.1430103232463202
Test loss: 2.161398639281591
Validation loss: 2.1430

-------------------- Epoch 2275 --------------------
Train loss: 1.6476
Test loss: 1.554349606235822
Test loss: 1.5823703159888585
Validation loss: 1.5543

-------------------- Epoch 2276 --------------------
Train loss: 1.7244
Test loss: 1.994853913784027
Test loss: 2.033121849099795
Validation loss: 1.9949

-------------------- Epoch 2277 --------------------
Train loss: 1.6557
Test loss: 1.7990934650103252
Test loss: 1.7819374253352482
Validation loss: 1.7991

-------------------- Epoch 2278 --------------------
Train loss: 1.6893
Test loss: 1.754184901714325
Test loss: 1.814394901196162
Validation loss: 1.7542

-------------------- Epoch 2279 --------------------
Train loss: 1.6859
Test loss: 1.6553287853797276
Test loss: 1.6586199551820755
Validation loss: 1.6553

-------------------- Epoch 2280 --------------------
Train loss: 1.6003
Test loss: 1.6510983556509018
Test loss: 1.6984510173400242
Validation loss: 1.6511

-------------------- Epoch 2281 --------------------
Train loss: 1.6241
Test loss: 1.6713296324014664
Test loss: 1.7278279960155487
Validation loss: 1.6713

-------------------- Epoch 2282 --------------------
Train loss: 2.0051
Test loss: 1.9472656448682149
Test loss: 2.010562832156817
Validation loss: 1.9473

-------------------- Epoch 2283 --------------------
Train loss: 1.6402
Test loss: 2.0556930849949517
Test loss: 2.1315236737330756
Validation loss: 2.0557

-------------------- Epoch 2284 --------------------
Train loss: 1.5956
Test loss: 2.2719521472851434
Test loss: 2.3397667904694877
Validation loss: 2.2720

-------------------- Epoch 2285 --------------------
Train loss: 1.6141
Test loss: 2.356417492032051
Test loss: 2.3977262576421103
Validation loss: 2.3564

-------------------- Epoch 2286 --------------------
Train loss: 1.7300
Test loss: 2.188946748773257
Test loss: 2.238777533173561
Validation loss: 2.1889

-------------------- Epoch 2287 --------------------
Train loss: 1.6554
Test loss: 1.549769992629687
Test loss: 1.6084964623053868
Validation loss: 1.5498

-------------------- Epoch 2288 --------------------
Train loss: 1.6354
Test loss: 1.9550995081663132
Test loss: 1.9627930372953415
Validation loss: 1.9551

-------------------- Epoch 2289 --------------------
Train loss: 1.6699
Test loss: 2.6533967653910318
Test loss: 2.659805119037628
Validation loss: 2.6534

-------------------- Epoch 2290 --------------------
Train loss: 1.6338
Test loss: 2.183852637807528
Test loss: 2.1644317408402762
Validation loss: 2.1839

-------------------- Epoch 2291 --------------------
Train loss: 1.6643
Test loss: 1.5287588785092037
Test loss: 1.6228956133127213
Validation loss: 1.5288

-------------------- Epoch 2292 --------------------
Train loss: 2.6052
Test loss: 1.5684841225544612
Test loss: 1.6056178510189056
Validation loss: 1.5685

-------------------- Epoch 2293 --------------------
Train loss: 2.2135
Test loss: 1.5685646831989288
Test loss: 1.622075657049815
Validation loss: 1.5686

-------------------- Epoch 2294 --------------------
Train loss: 1.9859
Test loss: 1.9772617320219676
Test loss: 1.9528398017088573
Validation loss: 1.9773

-------------------- Epoch 2295 --------------------
Train loss: 1.6267
Test loss: 1.9740900198618572
Test loss: 2.010314886768659
Validation loss: 1.9741

-------------------- Epoch 2296 --------------------
Train loss: 1.5989
Test loss: 1.8878776580095291
Test loss: 1.9552966058254242
Validation loss: 1.8879

-------------------- Epoch 2297 --------------------
Train loss: 1.6569
Test loss: 1.672484536965688
Test loss: 1.679125080506007
Validation loss: 1.6725

-------------------- Epoch 2298 --------------------
Train loss: 1.6005
Test loss: 1.7110792795817058
Test loss: 1.7260178526242573
Validation loss: 1.7111

-------------------- Epoch 2299 --------------------
Train loss: 1.5898
Test loss: 1.492908924818039
Test loss: 1.5315110087394714
Validation loss: 1.4929

-------------------- Epoch 2300 --------------------
Train loss: 1.7354
Test loss: 2.005259076754252
Test loss: 2.0312021921078363
Validation loss: 2.0053

-------------------- Epoch 2301 --------------------
Train loss: 1.6305
Test loss: 1.7982731411854427
Test loss: 1.85189850628376
Validation loss: 1.7983

-------------------- Epoch 2302 --------------------
Train loss: 1.6702
Test loss: 2.391722987095515
Test loss: 2.428290302554766
Validation loss: 2.3917

-------------------- Epoch 2303 --------------------
Train loss: 1.6017
Test loss: 1.8348180154959361
Test loss: 1.897921120127042
Validation loss: 1.8348

-------------------- Epoch 2304 --------------------
Train loss: 1.7500
Test loss: 1.4425906389951706
Test loss: 1.4904350514213245
Validation loss: 1.4426

-------------------- Epoch 2305 --------------------
Train loss: 1.6184
Test loss: 1.716969832777977
Test loss: 1.7314413686593373
Validation loss: 1.7170

-------------------- Epoch 2306 --------------------
Train loss: 1.9315
Test loss: 2.0877671390771866
Test loss: 2.0819163968165717
Validation loss: 2.0878

-------------------- Epoch 2307 --------------------
Train loss: 1.7211
Test loss: 1.495343878865242
Test loss: 1.5303145200014114
Validation loss: 1.4953

-------------------- Epoch 2308 --------------------
Train loss: 1.6100
Test loss: 2.010454917947451
Test loss: 2.1020084768533707
Validation loss: 2.0105

-------------------- Epoch 2309 --------------------
Train loss: 1.7945
Test loss: 1.9347360928853352
Test loss: 1.9574823379516602
Validation loss: 1.9347

-------------------- Epoch 2310 --------------------
Train loss: 1.7942
Test loss: 1.828125496705373
Test loss: 1.8508060177167256
Validation loss: 1.8281

-------------------- Epoch 2311 --------------------
Train loss: 1.6812
Test loss: 1.783471331000328
Test loss: 1.8254647453625996
Validation loss: 1.7835

-------------------- Epoch 2312 --------------------
Train loss: 1.6229
Test loss: 1.6138076186180115
Test loss: 1.6646442065636318
Validation loss: 1.6138

-------------------- Epoch 2313 --------------------
Train loss: 1.7406
Test loss: 2.236280843615532
Test loss: 2.2706917375326157
Validation loss: 2.2363

-------------------- Epoch 2314 --------------------
Train loss: 1.5688
Test loss: 1.6885786106189091
Test loss: 1.7519315828879674
Validation loss: 1.6886

-------------------- Epoch 2315 --------------------
Train loss: 1.5834
Test loss: 1.4980365584294002
Test loss: 1.5454694579044979
Validation loss: 1.4980

-------------------- Epoch 2316 --------------------
Train loss: 1.5827
Test loss: 1.4970983465512593
Test loss: 1.5297989149888356
Validation loss: 1.4971

-------------------- Epoch 2317 --------------------
Train loss: 2.1523
Test loss: 1.999060943722725
Test loss: 2.017714892824491
Validation loss: 1.9991

-------------------- Epoch 2318 --------------------
Train loss: 1.5426
Test loss: 1.598633701602618
Test loss: 1.595354547103246
Validation loss: 1.5986

-------------------- Epoch 2319 --------------------
Train loss: 1.5205
Test loss: 1.6666596035162609
Test loss: 1.733893911043803
Validation loss: 1.6667

-------------------- Epoch 2320 --------------------
Train loss: 1.6551
Test loss: 1.52476471165816
Test loss: 1.5854720175266266
Validation loss: 1.5248

-------------------- Epoch 2321 --------------------
Train loss: 1.6254
Test loss: 1.686804602543513
Test loss: 1.736104354262352
Validation loss: 1.6868

-------------------- Epoch 2322 --------------------
Train loss: 1.5792
Test loss: 1.8851120173931122
Test loss: 1.9410901069641113
Validation loss: 1.8851

-------------------- Epoch 2323 --------------------
Train loss: 1.5988
Test loss: 1.6820493042469025
Test loss: 1.7350646207729976
Validation loss: 1.6820

-------------------- Epoch 2324 --------------------
Train loss: 1.6247
Test loss: 1.5766254315773647
Test loss: 1.6388085683186848
Validation loss: 1.5766

-------------------- Epoch 2325 --------------------
Train loss: 1.6444
Test loss: 1.6723339607318242
Test loss: 1.7136090298493702
Validation loss: 1.6723

-------------------- Epoch 2326 --------------------
Train loss: 1.6793
Test loss: 1.8325416495402653
Test loss: 1.8772643059492111
Validation loss: 1.8325

-------------------- Epoch 2327 --------------------
Train loss: 1.6332
Test loss: 1.4609656905134518
Test loss: 1.5062918066978455
Validation loss: 1.4610

-------------------- Epoch 2328 --------------------
Train loss: 1.6348
Test loss: 1.60552217066288
Test loss: 1.6568468411763508
Validation loss: 1.6055

-------------------- Epoch 2329 --------------------
Train loss: 1.6321
Test loss: 1.434881905714671
Test loss: 1.4837362294395764
Validation loss: 1.4349

-------------------- Epoch 2330 --------------------
Train loss: 2.0194
Test loss: 1.4846753080685933
Test loss: 1.5413579891125362
Validation loss: 1.4847

-------------------- Epoch 2331 --------------------
Train loss: 1.5276
Test loss: 1.4725603262583415
Test loss: 1.513913671175639
Validation loss: 1.4726

-------------------- Epoch 2332 --------------------
Train loss: 1.6963
Test loss: 1.6067705005407333
Test loss: 1.6546065111955006
Validation loss: 1.6068

-------------------- Epoch 2333 --------------------
Train loss: 1.7204
Test loss: 1.5642853776613872
Test loss: 1.6210456043481827
Validation loss: 1.5643

-------------------- Epoch 2334 --------------------
Train loss: 1.6091
Test loss: 1.544489249587059
Test loss: 1.5707315703233082
Validation loss: 1.5445

-------------------- Epoch 2335 --------------------
Train loss: 1.5854
Test loss: 1.6527832945187886
Test loss: 1.6767913848161697
Validation loss: 1.6528

-------------------- Epoch 2336 --------------------
Train loss: 1.6285
Test loss: 1.925122966368993
Test loss: 1.9722153147061665
Validation loss: 1.9251

-------------------- Epoch 2337 --------------------
Train loss: 1.8288
Test loss: 1.4990402807792027
Test loss: 1.5292619268099468
Validation loss: 1.4990

-------------------- Epoch 2338 --------------------
Train loss: 1.5441
Test loss: 1.4774621228377025
Test loss: 1.5389221608638763
Validation loss: 1.4775

-------------------- Epoch 2339 --------------------
Train loss: 1.5003
Test loss: 1.7669980029265087
Test loss: 1.8329290399948757
Validation loss: 1.7670

-------------------- Epoch 2340 --------------------
Train loss: 1.6328
Test loss: 1.7263938238223393
Test loss: 1.8170938740173976
Validation loss: 1.7264

-------------------- Epoch 2341 --------------------
Train loss: 1.7158
Test loss: 2.0029518753290176
Test loss: 2.0792531619469323
Validation loss: 2.0030

-------------------- Epoch 2342 --------------------
Train loss: 1.6303
Test loss: 1.9383533746004105
Test loss: 1.9486174235741298
Validation loss: 1.9384

-------------------- Epoch 2343 --------------------
Train loss: 1.8099
Test loss: 1.4618265678485234
Test loss: 1.4765095959107082
Validation loss: 1.4618

-------------------- Epoch 2344 --------------------
Train loss: 1.5721
Test loss: 1.7043538590272267
Test loss: 1.7520675857861836
Validation loss: 1.7044

-------------------- Epoch 2345 --------------------
Train loss: 1.6683
Test loss: 1.5716087718804677
Test loss: 1.6267249931891758
Validation loss: 1.5716

-------------------- Epoch 2346 --------------------
Train loss: 1.6231
Test loss: 1.7517140607039134
Test loss: 1.8215512186288834
Validation loss: 1.7517

-------------------- Epoch 2347 --------------------
Train loss: 1.5574
Test loss: 1.6475404798984528
Test loss: 1.6634877373774846
Validation loss: 1.6475

-------------------- Epoch 2348 --------------------
Train loss: 1.5870
Test loss: 1.7081157366434734
Test loss: 1.7461485366026561
Validation loss: 1.7081

-------------------- Epoch 2349 --------------------
Train loss: 1.6120
Test loss: 1.7159168670574825
Test loss: 1.725358893473943
Validation loss: 1.7159

-------------------- Epoch 2350 --------------------
Train loss: 1.6662
Test loss: 1.5327552805344264
Test loss: 1.5675094276666641
Validation loss: 1.5328

-------------------- Epoch 2351 --------------------
Train loss: 1.6130
Test loss: 1.6292566905419033
Test loss: 1.7010107686122258
Validation loss: 1.6293

-------------------- Epoch 2352 --------------------
Train loss: 1.6648
Test loss: 1.571090007821719
Test loss: 1.5976700435082118
Validation loss: 1.5711

-------------------- Epoch 2353 --------------------
Train loss: 1.5559
Test loss: 1.7661902258793514
Test loss: 1.8045689562956493
Validation loss: 1.7662

-------------------- Epoch 2354 --------------------
Train loss: 1.5590
Test loss: 2.922151873509089
Test loss: 2.914161801338196
Validation loss: 2.9222

-------------------- Epoch 2355 --------------------
Train loss: 1.6681
Test loss: 1.5734359075625737
Test loss: 1.6371825238068898
Validation loss: 1.5734

-------------------- Epoch 2356 --------------------
Train loss: 1.7275
Test loss: 3.265815943479538
Test loss: 3.266678810119629
Validation loss: 3.2658

-------------------- Epoch 2357 --------------------
Train loss: 1.7771
Test loss: 1.4684657951196034
Test loss: 1.521921527882417
Validation loss: 1.4685

-------------------- Epoch 2358 --------------------
Train loss: 1.7712
Test loss: 1.6401250312725704
Test loss: 1.685391406218211
Validation loss: 1.6401

-------------------- Epoch 2359 --------------------
Train loss: 1.6994
Test loss: 2.14658123254776
Test loss: 2.1896178225676217
Validation loss: 2.1466

-------------------- Epoch 2360 --------------------
Train loss: 1.6967
Test loss: 1.4919727991024654
Test loss: 1.5099665770928066
Validation loss: 1.4920

-------------------- Epoch 2361 --------------------
Train loss: 1.6226
Test loss: 1.8036569207906723
Test loss: 1.8624370396137238
Validation loss: 1.8037

-------------------- Epoch 2362 --------------------
Train loss: 1.6231
Test loss: 1.527939885854721
Test loss: 1.563725878794988
Validation loss: 1.5279

-------------------- Epoch 2363 --------------------
Train loss: 1.5582
Test loss: 1.466104323665301
Test loss: 1.486440087358157
Validation loss: 1.4661

-------------------- Epoch 2364 --------------------
Train loss: 1.5231
Test loss: 2.0603707333405814
Test loss: 2.0590057522058487
Validation loss: 2.0604

-------------------- Epoch 2365 --------------------
Train loss: 1.6976
Test loss: 1.7657660295565922
Test loss: 1.839406485358874
Validation loss: 1.7658

-------------------- Epoch 2366 --------------------
Train loss: 1.5771
Test loss: 1.7924338380495708
Test loss: 1.8512589832146962
Validation loss: 1.7924

-------------------- Epoch 2367 --------------------
Train loss: 1.6560
Test loss: 1.6499905635913212
Test loss: 1.6559818387031555
Validation loss: 1.6500

-------------------- Epoch 2368 --------------------
Train loss: 1.5655
Test loss: 2.583718409140905
Test loss: 2.634818355242411
Validation loss: 2.5837

-------------------- Epoch 2369 --------------------
Train loss: 1.7016
Test loss: 1.4494763910770416
Test loss: 1.4828847820560138
Validation loss: 1.4495

-------------------- Epoch 2370 --------------------
Train loss: 1.9775
Test loss: 1.440702885389328
Test loss: 1.4859156062205632
Validation loss: 1.4407

-------------------- Epoch 2371 --------------------
Train loss: 1.5715
Test loss: 1.4711222002903621
Test loss: 1.5303135414918263
Validation loss: 1.4711

-------------------- Epoch 2372 --------------------
Train loss: 1.5844
Test loss: 1.8840895394484203
Test loss: 1.8925866136948268
Validation loss: 1.8841

-------------------- Epoch 2373 --------------------
Train loss: 1.5777
Test loss: 1.924251119295756
Test loss: 1.9356515556573868
Validation loss: 1.9243

-------------------- Epoch 2374 --------------------
Train loss: 1.7031
Test loss: 1.8252331018447876
Test loss: 1.8533237675825756
Validation loss: 1.8252

-------------------- Epoch 2375 --------------------
Train loss: 1.5538
Test loss: 1.7220294972260792
Test loss: 1.7799161473910015
Validation loss: 1.7220

-------------------- Epoch 2376 --------------------
Train loss: 1.6583
Test loss: 2.544664512077967
Test loss: 2.6237601041793823
Validation loss: 2.5447

-------------------- Epoch 2377 --------------------
Train loss: 1.6609
Test loss: 1.5264823486407597
Test loss: 1.5806919236977894
Validation loss: 1.5265

-------------------- Epoch 2378 --------------------
Train loss: 1.6081
Test loss: 1.8750082949797313
Test loss: 1.9069991459449132
Validation loss: 1.8750

-------------------- Epoch 2379 --------------------
Train loss: 1.5165
Test loss: 1.643833155433337
Test loss: 1.7033404558897018
Validation loss: 1.6438

-------------------- Epoch 2380 --------------------
Train loss: 1.7359
Test loss: 2.0468534429868064
Test loss: 2.0626776417096457
Validation loss: 2.0469

-------------------- Epoch 2381 --------------------
Train loss: 1.5244
Test loss: 1.5025229007005692
Test loss: 1.519365708033244
Validation loss: 1.5025

-------------------- Epoch 2382 --------------------
Train loss: 2.0907
Test loss: 1.8591630160808563
Test loss: 1.8917455275853474
Validation loss: 1.8592

-------------------- Epoch 2383 --------------------
Train loss: 2.0386
Test loss: 2.796310991048813
Test loss: 2.865210622549057
Validation loss: 2.7963

-------------------- Epoch 2384 --------------------
Train loss: 1.7144
Test loss: 1.5377649615208309
Test loss: 1.5882375637690227
Validation loss: 1.5378

-------------------- Epoch 2385 --------------------
Train loss: 1.6098
Test loss: 1.51362740000089
Test loss: 1.5531256347894669
Validation loss: 1.5136

-------------------- Epoch 2386 --------------------
Train loss: 1.6202
Test loss: 1.4749291837215424
Test loss: 1.4986518025398254
Validation loss: 1.4749

-------------------- Epoch 2387 --------------------
Train loss: 1.5729
Test loss: 1.6749260971943538
Test loss: 1.7368331005175908
Validation loss: 1.6749

-------------------- Epoch 2388 --------------------
Train loss: 1.9173
Test loss: 2.3684768875439963
Test loss: 2.3734383285045624
Validation loss: 2.3685

-------------------- Epoch 2389 --------------------
Train loss: 1.7828
Test loss: 1.5587357506155968
Test loss: 1.620121642947197
Validation loss: 1.5587

-------------------- Epoch 2390 --------------------
Train loss: 1.5201
Test loss: 1.8576227724552155
Test loss: 1.9231742024421692
Validation loss: 1.8576

-------------------- Epoch 2391 --------------------
Train loss: 1.5389
Test loss: 1.465232605735461
Test loss: 1.5093464404344559
Validation loss: 1.4652

-------------------- Epoch 2392 --------------------
Train loss: 1.4956
Test loss: 1.8487194180488586
Test loss: 1.9278176526228588
Validation loss: 1.8487

-------------------- Epoch 2393 --------------------
Train loss: 1.9484
Test loss: 1.485209196805954
Test loss: 1.5326342930396397
Validation loss: 1.4852

-------------------- Epoch 2394 --------------------
Train loss: 1.5018
Test loss: 1.5378000686566036
Test loss: 1.5873829523722331
Validation loss: 1.5378

-------------------- Epoch 2395 --------------------
Train loss: 1.6882
Test loss: 1.486674999197324
Test loss: 1.500846763451894
Validation loss: 1.4867

-------------------- Epoch 2396 --------------------
Train loss: 1.5538
Test loss: 1.8477288782596588
Test loss: 1.8548497805992763
Validation loss: 1.8477

-------------------- Epoch 2397 --------------------
Train loss: 1.6999
Test loss: 1.7379178553819656
Test loss: 1.799808661142985
Validation loss: 1.7379

-------------------- Epoch 2398 --------------------
Train loss: 1.5150
Test loss: 1.6934987554947536
Test loss: 1.7281950215498607
Validation loss: 1.6935

-------------------- Epoch 2399 --------------------
Train loss: 2.0413
Test loss: 1.4713433881600697
Test loss: 1.5121674786011379
Validation loss: 1.4713

-------------------- Epoch 2400 --------------------
Train loss: 1.5690
Test loss: 1.471758484840393
Test loss: 1.5126532713572185
Validation loss: 1.4718

-------------------- Epoch 2401 --------------------
Train loss: 1.5068
Test loss: 1.7373345146576564
Test loss: 1.7821062157551448
Validation loss: 1.7373

-------------------- Epoch 2402 --------------------
Train loss: 1.6009
Test loss: 1.745327706138293
Test loss: 1.7583710153897603
Validation loss: 1.7453

-------------------- Epoch 2403 --------------------
Train loss: 1.5382
Test loss: 1.8004631946484249
Test loss: 1.8665296882390976
Validation loss: 1.8005

-------------------- Epoch 2404 --------------------
Train loss: 1.6049
Test loss: 1.8804067720969517
Test loss: 1.9074633767207463
Validation loss: 1.8804

-------------------- Epoch 2405 --------------------
Train loss: 1.5781
Test loss: 1.6392863939205806
Test loss: 1.6880958875020344
Validation loss: 1.6393

-------------------- Epoch 2406 --------------------
Train loss: 1.8473
Test loss: 2.2089137931664786
Test loss: 2.220033898949623
Validation loss: 2.2089

-------------------- Epoch 2407 --------------------
Train loss: 2.1035
Test loss: 2.716296821832657
Test loss: 2.7256948947906494
Validation loss: 2.7163

-------------------- Epoch 2408 --------------------
Train loss: 1.8918
Test loss: 1.5498064855734508
Test loss: 1.6052766839663188
Validation loss: 1.5498

-------------------- Epoch 2409 --------------------
Train loss: 1.6066
Test loss: 1.6073688169320424
Test loss: 1.6411295980215073
Validation loss: 1.6074

-------------------- Epoch 2410 --------------------
Train loss: 1.8581
Test loss: 1.6639242619276047
Test loss: 1.6866558690865834
Validation loss: 1.6639

-------------------- Epoch 2411 --------------------
Train loss: 1.6423
Test loss: 1.4646242409944534
Test loss: 1.4947894513607025
Validation loss: 1.4646

-------------------- Epoch 2412 --------------------
Train loss: 1.5929
Test loss: 2.0989525417486825
Test loss: 2.1637565344572067
Validation loss: 2.0990

-------------------- Epoch 2413 --------------------
Train loss: 1.5382
Test loss: 1.4774064868688583
Test loss: 1.4983992725610733
Validation loss: 1.4774

-------------------- Epoch 2414 --------------------
Train loss: 1.5492
Test loss: 1.4674995839595795
Test loss: 1.508109872539838
Validation loss: 1.4675

-------------------- Epoch 2415 --------------------
Train loss: 1.5749
Test loss: 1.5114644120136898
Test loss: 1.5495702823003132
Validation loss: 1.5115

-------------------- Epoch 2416 --------------------
Train loss: 1.6411
Test loss: 1.7228811035553615
Test loss: 1.7865846206744511
Validation loss: 1.7229

-------------------- Epoch 2417 --------------------
Train loss: 1.5406
Test loss: 1.818391313155492
Test loss: 1.9094526966412861
Validation loss: 1.8184

-------------------- Epoch 2418 --------------------
Train loss: 1.4701
Test loss: 2.2075652529795966
Test loss: 2.2869971692562103
Validation loss: 2.2076

-------------------- Epoch 2419 --------------------
Train loss: 1.5334
Test loss: 1.445181245605151
Test loss: 1.4699847648541133
Validation loss: 1.4452

-------------------- Epoch 2420 --------------------
Train loss: 1.5333
Test loss: 1.9572028915087383
Test loss: 1.9510031193494797
Validation loss: 1.9572

-------------------- Epoch 2421 --------------------
Train loss: 1.6220
Test loss: 2.9088032643000283
Test loss: 2.9589659770329795
Validation loss: 2.9088

-------------------- Epoch 2422 --------------------
Train loss: 1.5660
Test loss: 1.472866714000702
Test loss: 1.5376095672448475
Validation loss: 1.4729

-------------------- Epoch 2423 --------------------
Train loss: 1.6094
Test loss: 2.0190581530332565
Test loss: 2.0744506071011224
Validation loss: 2.0191

-------------------- Epoch 2424 --------------------
Train loss: 1.6321
Test loss: 1.7607162098089855
Test loss: 1.8146299769481022
Validation loss: 1.7607

-------------------- Epoch 2425 --------------------
Train loss: 1.5905
Test loss: 1.4348815778891246
Test loss: 1.4827144344647725
Validation loss: 1.4349

-------------------- Epoch 2426 --------------------
Train loss: 1.6618
Test loss: 1.8712423592805862
Test loss: 1.8962333301703136
Validation loss: 1.8712

-------------------- Epoch 2427 --------------------
Train loss: 1.5785
Test loss: 2.2073691536982856
Test loss: 2.1945227881272635
Validation loss: 2.2074

-------------------- Epoch 2428 --------------------
Train loss: 1.6501
Test loss: 2.7376584907372794
Test loss: 2.7572403947512307
Validation loss: 2.7377

-------------------- Epoch 2429 --------------------
Train loss: 1.6440
Test loss: 1.571948193013668
Test loss: 1.627603366971016
Validation loss: 1.5719

-------------------- Epoch 2430 --------------------
Train loss: 1.4985
Test loss: 1.9940099815527599
Test loss: 2.0325340181589127
Validation loss: 1.9940

-------------------- Epoch 2431 --------------------
Train loss: 1.6751
Test loss: 1.9082752416531246
Test loss: 1.9289368987083435
Validation loss: 1.9083

-------------------- Epoch 2432 --------------------
Train loss: 1.6372
Test loss: 2.275848920146624
Test loss: 2.35729226966699
Validation loss: 2.2758

-------------------- Epoch 2433 --------------------
Train loss: 1.5945
Test loss: 1.9907356997330983
Test loss: 1.987665260831515
Validation loss: 1.9907

-------------------- Epoch 2434 --------------------
Train loss: 1.5840
Test loss: 1.5305258135000865
Test loss: 1.562803566455841
Validation loss: 1.5305

-------------------- Epoch 2435 --------------------
Train loss: 1.5200
Test loss: 1.6187876909971237
Test loss: 1.671323264638583
Validation loss: 1.6188

-------------------- Epoch 2436 --------------------
Train loss: 1.5671
Test loss: 1.4778857479492824
Test loss: 1.5223881751298904
Validation loss: 1.4779

-------------------- Epoch 2437 --------------------
Train loss: 1.6218
Test loss: 1.7436191687981288
Test loss: 1.8173030465841293
Validation loss: 1.7436

-------------------- Epoch 2438 --------------------
Train loss: 1.6355
Test loss: 1.4905571440855663
Test loss: 1.509169802069664
Validation loss: 1.4906

-------------------- Epoch 2439 --------------------
Train loss: 1.5826
Test loss: 1.620485246181488
Test loss: 1.6314348379770915
Validation loss: 1.6205

-------------------- Epoch 2440 --------------------
Train loss: 1.5193
Test loss: 1.9386983613173168
Test loss: 2.018962115049362
Validation loss: 1.9387

-------------------- Epoch 2441 --------------------
Train loss: 1.6502
Test loss: 1.4598055680592854
Test loss: 1.5215908586978912
Validation loss: 1.4598

-------------------- Epoch 2442 --------------------
Train loss: 1.5208
Test loss: 1.4302118023236592
Test loss: 1.4843430022398632
Validation loss: 1.4302

-------------------- Epoch 2443 --------------------
Train loss: 1.5434
Test loss: 1.460021232565244
Test loss: 1.5072210331757863
Validation loss: 1.4600

-------------------- Epoch 2444 --------------------
Train loss: 1.5402
Test loss: 1.4410297522942226
Test loss: 1.4771433969338734
Validation loss: 1.4410

-------------------- Epoch 2445 --------------------
Train loss: 1.5129
Test loss: 1.6981810579697292
Test loss: 1.732013429204623
Validation loss: 1.6982

-------------------- Epoch 2446 --------------------
Train loss: 1.6028
Test loss: 1.4728505661090214
Test loss: 1.507428914308548
Validation loss: 1.4729

-------------------- Epoch 2447 --------------------
Train loss: 1.5867
Test loss: 1.5275665422280629
Test loss: 1.5557921330134075
Validation loss: 1.5276

-------------------- Epoch 2448 --------------------
Train loss: 1.6396
Test loss: 1.7575953056414921
Test loss: 1.8208670169115067
Validation loss: 1.7576

-------------------- Epoch 2449 --------------------
Train loss: 1.5195
Test loss: 2.1851793626944223
Test loss: 2.263520196080208
Validation loss: 2.1852

-------------------- Epoch 2450 --------------------
Train loss: 1.6017
Test loss: 1.4473903725544612
Test loss: 1.491168146332105
Validation loss: 1.4474

-------------------- Epoch 2451 --------------------
Train loss: 1.5524
Test loss: 1.455069785316785
Test loss: 1.4759987344344456
Validation loss: 1.4551

-------------------- Epoch 2452 --------------------
Train loss: 1.5368
Test loss: 1.4443430056174595
Test loss: 1.4701670209566753
Validation loss: 1.4443

-------------------- Epoch 2453 --------------------
Train loss: 1.5687
Test loss: 1.8437690039475758
Test loss: 1.871184100707372
Validation loss: 1.8438

-------------------- Epoch 2454 --------------------
Train loss: 1.6406
Test loss: 1.4853628426790237
Test loss: 1.505059500535329
Validation loss: 1.4854

-------------------- Epoch 2455 --------------------
Train loss: 1.5394
Test loss: 1.4915615071853001
Test loss: 1.550581455230713
Validation loss: 1.4916

-------------------- Epoch 2456 --------------------
Train loss: 1.5133
Test loss: 2.2360322177410126
Test loss: 2.3213799794514975
Validation loss: 2.2360

-------------------- Epoch 2457 --------------------
Train loss: 1.6998
Test loss: 1.6575456460316975
Test loss: 1.6567158699035645
Validation loss: 1.6575

-------------------- Epoch 2458 --------------------
Train loss: 1.6124
Test loss: 2.2387572129567466
Test loss: 2.320969447493553
Validation loss: 2.2388

-------------------- Epoch 2459 --------------------
Train loss: 2.3961
Test loss: 2.1429235686858497
Test loss: 2.1444867998361588
Validation loss: 2.1429

-------------------- Epoch 2460 --------------------
Train loss: 1.5837
Test loss: 1.4994903753201168
Test loss: 1.529029443860054
Validation loss: 1.4995

-------------------- Epoch 2461 --------------------
Train loss: 1.5244
Test loss: 1.449593000113964
Test loss: 1.5008038133382797
Validation loss: 1.4496

-------------------- Epoch 2462 --------------------
Train loss: 1.9050
Test loss: 2.166493684053421
Test loss: 2.2055714229742684
Validation loss: 2.1665

-------------------- Epoch 2463 --------------------
Train loss: 1.6002
Test loss: 1.5262511372566223
Test loss: 1.574225256840388
Validation loss: 1.5263

-------------------- Epoch 2464 --------------------
Train loss: 1.6706
Test loss: 2.5993116398652396
Test loss: 2.679267078638077
Validation loss: 2.5993

-------------------- Epoch 2465 --------------------
Train loss: 1.5855
Test loss: 1.8991490354140599
Test loss: 1.9684482713540394
Validation loss: 1.8991

-------------------- Epoch 2466 --------------------
Train loss: 1.4983
Test loss: 1.4294354617595673
Test loss: 1.486975868542989
Validation loss: 1.4294

-------------------- Epoch 2467 --------------------
Train loss: 1.4860
Test loss: 1.7234693219264348
Test loss: 1.786158079902331
Validation loss: 1.7235

-------------------- Epoch 2468 --------------------
Train loss: 1.5596
Test loss: 1.5568501899639766
Test loss: 1.6130388776461284
Validation loss: 1.5569

-------------------- Epoch 2469 --------------------
Train loss: 1.6989
Test loss: 1.9059608330329258
Test loss: 1.9241161892811458
Validation loss: 1.9060

-------------------- Epoch 2470 --------------------
Train loss: 1.5153
Test loss: 1.6637088110049565
Test loss: 1.722458655635516
Validation loss: 1.6637

-------------------- Epoch 2471 --------------------
Train loss: 1.5351
Test loss: 1.4654699638485909
Test loss: 1.5128864695628483
Validation loss: 1.4655

-------------------- Epoch 2472 --------------------
Train loss: 1.5585
Test loss: 1.5312237789233525
Test loss: 1.5822185277938843
Validation loss: 1.5312

-------------------- Epoch 2473 --------------------
Train loss: 1.5299
Test loss: 1.59210304915905
Test loss: 1.60693721473217
Validation loss: 1.5921

-------------------- Epoch 2474 --------------------
Train loss: 1.5542
Test loss: 1.7248094926277797
Test loss: 1.7607141137123108
Validation loss: 1.7248

-------------------- Epoch 2475 --------------------
Train loss: 1.5890
Test loss: 1.4466536591450374
Test loss: 1.4821516275405884
Validation loss: 1.4467

-------------------- Epoch 2476 --------------------
Train loss: 1.4425
Test loss: 1.730747068921725
Test loss: 1.7726937929789226
Validation loss: 1.7307

-------------------- Epoch 2477 --------------------
Train loss: 1.5056
Test loss: 1.5329465319712956
Test loss: 1.583329200744629
Validation loss: 1.5329

-------------------- Epoch 2478 --------------------
Train loss: 1.5736
Test loss: 1.8196231325467427
Test loss: 1.8306222707033157
Validation loss: 1.8196

-------------------- Epoch 2479 --------------------
Train loss: 1.6205
Test loss: 1.6636211971441905
Test loss: 1.7090922147035599
Validation loss: 1.6636

-------------------- Epoch 2480 --------------------
Train loss: 1.4833
Test loss: 1.6691486090421677
Test loss: 1.7268983622392018
Validation loss: 1.6691

-------------------- Epoch 2481 --------------------
Train loss: 1.6098
Test loss: 1.7723290473222733
Test loss: 1.808532138665517
Validation loss: 1.7723

-------------------- Epoch 2482 --------------------
Train loss: 1.5038
Test loss: 1.4994755188624065
Test loss: 1.54518927137057
Validation loss: 1.4995

-------------------- Epoch 2483 --------------------
Train loss: 1.5110
Test loss: 1.5924861977497737
Test loss: 1.6293511042992275
Validation loss: 1.5925

-------------------- Epoch 2484 --------------------
Train loss: 1.5762
Test loss: 1.7589730024337769
Test loss: 1.7710950175921123
Validation loss: 1.7590

-------------------- Epoch 2485 --------------------
Train loss: 1.5603
Test loss: 1.5341959794362385
Test loss: 1.5857720325390499
Validation loss: 1.5342

-------------------- Epoch 2486 --------------------
Train loss: 1.4943
Test loss: 1.4852184330423672
Test loss: 1.5480637848377228
Validation loss: 1.4852

-------------------- Epoch 2487 --------------------
Train loss: 1.4657
Test loss: 2.049912393093109
Test loss: 2.1064352691173553
Validation loss: 2.0499

-------------------- Epoch 2488 --------------------
Train loss: 1.5117
Test loss: 1.636953537662824
Test loss: 1.7129592498143513
Validation loss: 1.6370

-------------------- Epoch 2489 --------------------
Train loss: 1.8561
Test loss: 1.521439825495084
Test loss: 1.5720185538132985
Validation loss: 1.5214

-------------------- Epoch 2490 --------------------
Train loss: 1.4991
Test loss: 1.5160557329654694
Test loss: 1.574323500196139
Validation loss: 1.5161

-------------------- Epoch 2491 --------------------
Train loss: 1.6013
Test loss: 1.8524508227904637
Test loss: 1.908564989765485
Validation loss: 1.8525

-------------------- Epoch 2492 --------------------
Train loss: 1.5154
Test loss: 1.7068975120782852
Test loss: 1.7699160774548848
Validation loss: 1.7069

-------------------- Epoch 2493 --------------------
Train loss: 1.5511
Test loss: 1.6393090883890789
Test loss: 1.701571211218834
Validation loss: 1.6393

-------------------- Epoch 2494 --------------------
Train loss: 1.4852
Test loss: 1.608664517601331
Test loss: 1.6180189301570256
Validation loss: 1.6087

-------------------- Epoch 2495 --------------------
Train loss: 1.4794
Test loss: 1.5088274081548054
Test loss: 1.5682041694720585
Validation loss: 1.5088

-------------------- Epoch 2496 --------------------
Train loss: 1.5138
Test loss: 2.183719754219055
Test loss: 2.2789302617311478
Validation loss: 2.1837

-------------------- Epoch 2497 --------------------
Train loss: 1.5529
Test loss: 1.7392224371433258
Test loss: 1.7974017610152562
Validation loss: 1.7392

-------------------- Epoch 2498 --------------------
Train loss: 1.5381
Test loss: 1.4621447871128719
Test loss: 1.5090740422407787
Validation loss: 1.4621

-------------------- Epoch 2499 --------------------
Train loss: 1.5009
Test loss: 1.4450306246678035
Test loss: 1.49875691284736
Validation loss: 1.4450

-------------------- Epoch 2500 --------------------
Train loss: 1.4974
Test loss: 1.4538487295309703
Test loss: 1.500707171857357
Validation loss: 1.4538

-------------------- Epoch 2501 --------------------
Train loss: 1.5048
Test loss: 1.981642449895541
Test loss: 2.0555100589990616
Validation loss: 1.9816

-------------------- Epoch 2502 --------------------
Train loss: 2.0600
Test loss: 2.844678079088529
Test loss: 2.8964858452479043
Validation loss: 2.8447

-------------------- Epoch 2503 --------------------
Train loss: 1.6722
Test loss: 1.541253576676051
Test loss: 1.595889816681544
Validation loss: 1.5413

-------------------- Epoch 2504 --------------------
Train loss: 1.5511
Test loss: 1.710684910416603
Test loss: 1.7679601609706879
Validation loss: 1.7107

-------------------- Epoch 2505 --------------------
Train loss: 1.4918
Test loss: 1.5097008397181828
Test loss: 1.543316274881363
Validation loss: 1.5097

-------------------- Epoch 2506 --------------------
Train loss: 1.4911
Test loss: 2.54841356476148
Test loss: 2.634582112232844
Validation loss: 2.5484

-------------------- Epoch 2507 --------------------
Train loss: 1.7902
Test loss: 1.975948120156924
Test loss: 1.9981129219134648
Validation loss: 1.9759

-------------------- Epoch 2508 --------------------
Train loss: 1.4874
Test loss: 1.611445352435112
Test loss: 1.6374322871367137
Validation loss: 1.6114

-------------------- Epoch 2509 --------------------
Train loss: 1.5038
Test loss: 1.4403033331036568
Test loss: 1.47858893374602
Validation loss: 1.4403

-------------------- Epoch 2510 --------------------
Train loss: 1.5161
Test loss: 1.4679202089707057
Test loss: 1.494235058625539
Validation loss: 1.4679

-------------------- Epoch 2511 --------------------
Train loss: 1.5127
Test loss: 1.440036843220393
Test loss: 1.4782084375619888
Validation loss: 1.4400

-------------------- Epoch 2512 --------------------
Train loss: 1.5375
Test loss: 1.4400491788983345
Test loss: 1.494303231438001
Validation loss: 1.4400

-------------------- Epoch 2513 --------------------
Train loss: 1.5016
Test loss: 1.7724967151880264
Test loss: 1.8092141449451447
Validation loss: 1.7725

-------------------- Epoch 2514 --------------------
Train loss: 1.4679
Test loss: 1.4527202099561691
Test loss: 1.4949668844540913
Validation loss: 1.4527

-------------------- Epoch 2515 --------------------
Train loss: 1.4972
Test loss: 1.4545704796910286
Test loss: 1.4849288910627365
Validation loss: 1.4546

-------------------- Epoch 2516 --------------------
Train loss: 1.4558
Test loss: 1.4193640872836113
Test loss: 1.4592914208769798
New best validation loss: 1.4194, saving model weights to best_model_weights.pth

-------------------- Epoch 2517 --------------------
Train loss: 1.5165
Test loss: 1.4807061428825061
Test loss: 1.5193412403265636
Validation loss: 1.4807

-------------------- Epoch 2518 --------------------
Train loss: 1.5140
Test loss: 1.7189790954192479
Test loss: 1.7534261892239253
Validation loss: 1.7190

-------------------- Epoch 2519 --------------------
Train loss: 1.5503
Test loss: 1.6126736998558044
Test loss: 1.62821364402771
Validation loss: 1.6127

-------------------- Epoch 2520 --------------------
Train loss: 1.5855
Test loss: 1.5263851185639699
Test loss: 1.5806066294511159
Validation loss: 1.5264

-------------------- Epoch 2521 --------------------
Train loss: 1.5092
Test loss: 1.456916555762291
Test loss: 1.4968837648630142
Validation loss: 1.4569

-------------------- Epoch 2522 --------------------
Train loss: 1.4696
Test loss: 1.4874914189179738
Test loss: 1.5408702790737152
Validation loss: 1.4875

-------------------- Epoch 2523 --------------------
Train loss: 1.5132
Test loss: 1.6436081677675247
Test loss: 1.7029823958873749
Validation loss: 1.6436

-------------------- Epoch 2524 --------------------
Train loss: 1.4974
Test loss: 1.7520743360122044
Test loss: 1.7939826250076294
Validation loss: 1.7521

-------------------- Epoch 2525 --------------------
Train loss: 1.4829
Test loss: 1.550586183865865
Test loss: 1.59308061003685
Validation loss: 1.5506

-------------------- Epoch 2526 --------------------
Train loss: 1.5185
Test loss: 1.6246746480464935
Test loss: 1.678207889199257
Validation loss: 1.6247

-------------------- Epoch 2527 --------------------
Train loss: 1.5124
Test loss: 1.4585639188687007
Test loss: 1.5113203873236973
Validation loss: 1.4586

-------------------- Epoch 2528 --------------------
Train loss: 1.5187
Test loss: 1.6491717596848805
Test loss: 1.673420712351799
Validation loss: 1.6492

-------------------- Epoch 2529 --------------------
Train loss: 1.5567
Test loss: 1.5579111526409786
Test loss: 1.609641393025716
Validation loss: 1.5579

-------------------- Epoch 2530 --------------------
Train loss: 1.5064
Test loss: 1.5120456963777542
Test loss: 1.585355207324028
Validation loss: 1.5120

-------------------- Epoch 2531 --------------------
Train loss: 1.5295
Test loss: 1.4765810370445251
Test loss: 1.5070489446322124
Validation loss: 1.4766

-------------------- Epoch 2532 --------------------
Train loss: 1.4588
Test loss: 1.693074991305669
Test loss: 1.7261360039313633
Validation loss: 1.6931

-------------------- Epoch 2533 --------------------
Train loss: 1.5027
Test loss: 1.446492003897826
Test loss: 1.495318129658699
Validation loss: 1.4465

-------------------- Epoch 2534 --------------------
Train loss: 2.4076
Test loss: 1.7895969996849697
Test loss: 1.8287220845619838
Validation loss: 1.7896

-------------------- Epoch 2535 --------------------
Train loss: 1.5245
Test loss: 1.4254626681407292
Test loss: 1.4683779577414195
Validation loss: 1.4255

-------------------- Epoch 2536 --------------------
Train loss: 1.4701
Test loss: 1.7923041979471843
Test loss: 1.8426658709843953
Validation loss: 1.7923

-------------------- Epoch 2537 --------------------
Train loss: 1.4858
Test loss: 1.442401945590973
Test loss: 1.4968801885843277
Validation loss: 1.4424

-------------------- Epoch 2538 --------------------
Train loss: 1.4660
Test loss: 1.4895596653223038
Test loss: 1.5382272104422252
Validation loss: 1.4896

-------------------- Epoch 2539 --------------------
Train loss: 1.4480
Test loss: 1.6335462033748627
Test loss: 1.695708304643631
Validation loss: 1.6335

-------------------- Epoch 2540 --------------------
Train loss: 1.4924
Test loss: 1.432809129357338
Test loss: 1.4729322691758473
Validation loss: 1.4328

-------------------- Epoch 2541 --------------------
Train loss: 1.5423
Test loss: 2.0717902729908624
Test loss: 2.146225849787394
Validation loss: 2.0718

-------------------- Epoch 2542 --------------------
Train loss: 1.5398
Test loss: 1.7100760291020076
Test loss: 1.7434744387865067
Validation loss: 1.7101

-------------------- Epoch 2543 --------------------
Train loss: 1.4982
Test loss: 1.5204020788272221
Test loss: 1.5446325639883678
Validation loss: 1.5204

-------------------- Epoch 2544 --------------------
Train loss: 1.5123
Test loss: 1.5704814592997234
Test loss: 1.6362848927577336
Validation loss: 1.5705

-------------------- Epoch 2545 --------------------
Train loss: 1.5460
Test loss: 1.5465733259916306
Test loss: 1.606252799431483
Validation loss: 1.5466

-------------------- Epoch 2546 --------------------
Train loss: 1.7087
Test loss: 1.4881644546985626
Test loss: 1.5423891892035801
Validation loss: 1.4882

-------------------- Epoch 2547 --------------------
Train loss: 1.4775
Test loss: 1.4266248593727748
Test loss: 1.4601878474156063
Validation loss: 1.4266

-------------------- Epoch 2548 --------------------
Train loss: 1.4967
Test loss: 1.5323539872964222
Test loss: 1.5493843952814739
Validation loss: 1.5324

-------------------- Epoch 2549 --------------------
Train loss: 1.4678
Test loss: 1.575944150487582
Test loss: 1.604479084412257
Validation loss: 1.5759

-------------------- Epoch 2550 --------------------
Train loss: 1.4855
Test loss: 1.6609434982140858
Test loss: 1.66594398021698
Validation loss: 1.6609

-------------------- Epoch 2551 --------------------
Train loss: 1.5306
Test loss: 1.8580129792292912
Test loss: 1.929541101058324
Validation loss: 1.8580

-------------------- Epoch 2552 --------------------
Train loss: 1.5360
Test loss: 2.1621276984612146
Test loss: 2.2544901371002197
Validation loss: 2.1621

-------------------- Epoch 2553 --------------------
Train loss: 1.5062
Test loss: 1.4724240178863208
Test loss: 1.5166065370043118
Validation loss: 1.4724

-------------------- Epoch 2554 --------------------
Train loss: 1.5372
Test loss: 1.4793512895703316
Test loss: 1.530118058125178
Validation loss: 1.4794

-------------------- Epoch 2555 --------------------
Train loss: 1.5532
Test loss: 1.4877962917089462
Test loss: 1.5272612522045772
Validation loss: 1.4878

-------------------- Epoch 2556 --------------------
Train loss: 1.4397
Test loss: 1.426855633656184
Test loss: 1.4653435697158177
Validation loss: 1.4269

-------------------- Epoch 2557 --------------------
Train loss: 1.5521
Test loss: 1.9329538245995839
Test loss: 1.9479069064060848
Validation loss: 1.9330

-------------------- Epoch 2558 --------------------
Train loss: 1.5047
Test loss: 1.436749537785848
Test loss: 1.4823725720246632
Validation loss: 1.4367

-------------------- Epoch 2559 --------------------
Train loss: 1.4359
Test loss: 1.6153449515501659
Test loss: 1.6484859983126323
Validation loss: 1.6153

-------------------- Epoch 2560 --------------------
Train loss: 1.4397
Test loss: 1.802648350596428
Test loss: 1.863612433274587
Validation loss: 1.8026

-------------------- Epoch 2561 --------------------
Train loss: 1.4215
Test loss: 1.44878584643205
Test loss: 1.5037263830502827
Validation loss: 1.4488

-------------------- Epoch 2562 --------------------
Train loss: 1.4709
Test loss: 1.4539685373504956
Test loss: 1.5091627935568492
Validation loss: 1.4540

-------------------- Epoch 2563 --------------------
Train loss: 1.4591
Test loss: 1.5295429130395253
Test loss: 1.5593346307675044
Validation loss: 1.5295

-------------------- Epoch 2564 --------------------
Train loss: 1.5349
Test loss: 1.4299384305874507
Test loss: 1.476484549542268
Validation loss: 1.4299

-------------------- Epoch 2565 --------------------
Train loss: 1.4868
Test loss: 1.4875330924987793
Test loss: 1.5060234367847443
Validation loss: 1.4875

-------------------- Epoch 2566 --------------------
Train loss: 1.5130
Test loss: 1.6343658069769542
Test loss: 1.696656142671903
Validation loss: 1.6344

-------------------- Epoch 2567 --------------------
Train loss: 1.4700
Test loss: 1.6116174459457397
Test loss: 1.6460231691598892
Validation loss: 1.6116

-------------------- Epoch 2568 --------------------
Train loss: 1.5268
Test loss: 2.5310553212960563
Test loss: 2.5374816407759986
Validation loss: 2.5311

-------------------- Epoch 2569 --------------------
Train loss: 1.5343
Test loss: 1.4424992774923642
Test loss: 1.4673653120795886
Validation loss: 1.4425

-------------------- Epoch 2570 --------------------
Train loss: 1.4771
Test loss: 1.954951912164688
Test loss: 2.00662795205911
Validation loss: 1.9550

-------------------- Epoch 2571 --------------------
Train loss: 1.4466
Test loss: 1.4494682202736537
Test loss: 1.5064785008629162
Validation loss: 1.4495

-------------------- Epoch 2572 --------------------
Train loss: 1.4330
Test loss: 1.443739448984464
Test loss: 1.4699952999750774
Validation loss: 1.4437

-------------------- Epoch 2573 --------------------
Train loss: 1.5080
Test loss: 1.9183031966288884
Test loss: 1.9461749543746312
Validation loss: 1.9183

-------------------- Epoch 2574 --------------------
Train loss: 1.5122
Test loss: 1.8521235038836796
Test loss: 1.908903847138087
Validation loss: 1.8521

-------------------- Epoch 2575 --------------------
Train loss: 1.4709
Test loss: 1.502680778503418
Test loss: 1.5648878514766693
Validation loss: 1.5027

-------------------- Epoch 2576 --------------------
Train loss: 1.4808
Test loss: 1.4942608575026195
Test loss: 1.5197767863670986
Validation loss: 1.4943

-------------------- Epoch 2577 --------------------
Train loss: 1.5475
Test loss: 1.4913152928153675
Test loss: 1.5291067312161128
Validation loss: 1.4913

-------------------- Epoch 2578 --------------------
Train loss: 1.5482
Test loss: 1.5076003322998683
Test loss: 1.546811451514562
Validation loss: 1.5076

-------------------- Epoch 2579 --------------------
Train loss: 1.5535
Test loss: 1.4586246609687805
Test loss: 1.5065127660830815
Validation loss: 1.4586

-------------------- Epoch 2580 --------------------
Train loss: 1.4385
Test loss: 1.4995254079500835
Test loss: 1.560275877515475
Validation loss: 1.4995

-------------------- Epoch 2581 --------------------
Train loss: 1.5204
Test loss: 1.55012542506059
Test loss: 1.5795572598775227
Validation loss: 1.5501

-------------------- Epoch 2582 --------------------
Train loss: 1.4235
Test loss: 1.4984353234370549
Test loss: 1.5380962938070297
Validation loss: 1.4984

-------------------- Epoch 2583 --------------------
Train loss: 1.4891
Test loss: 1.5702314128478367
Test loss: 1.6335826019446056
Validation loss: 1.5702

-------------------- Epoch 2584 --------------------
Train loss: 1.4532
Test loss: 1.4729141741991043
Test loss: 1.5260733713706334
Validation loss: 1.4729

-------------------- Epoch 2585 --------------------
Train loss: 1.4903
Test loss: 1.6242885788281758
Test loss: 1.6887935250997543
Validation loss: 1.6243

-------------------- Epoch 2586 --------------------
Train loss: 1.4695
Test loss: 1.5947952171166737
Test loss: 1.6110583146413167
Validation loss: 1.5948

-------------------- Epoch 2587 --------------------
Train loss: 1.4451
Test loss: 1.5049552222092946
Test loss: 1.561282088359197
Validation loss: 1.5050

-------------------- Epoch 2588 --------------------
Train loss: 1.4526
Test loss: 1.4621653258800507
Test loss: 1.4790909886360168
Validation loss: 1.4622

-------------------- Epoch 2589 --------------------
Train loss: 1.4898
Test loss: 1.509894202152888
Test loss: 1.5176747838656108
Validation loss: 1.5099

-------------------- Epoch 2590 --------------------
Train loss: 1.4407
Test loss: 1.4566212097803752
Test loss: 1.5073362837235134
Validation loss: 1.4566

-------------------- Epoch 2591 --------------------
Train loss: 1.5205
Test loss: 2.155013586084048
Test loss: 2.230655605594317
Validation loss: 2.1550

-------------------- Epoch 2592 --------------------
Train loss: 1.5214
Test loss: 1.701323573788007
Test loss: 1.717492346962293
Validation loss: 1.7013

-------------------- Epoch 2593 --------------------
Train loss: 1.4258
Test loss: 1.4653179869055748
Test loss: 1.5167355785767238
Validation loss: 1.4653

-------------------- Epoch 2594 --------------------
Train loss: 1.4439
Test loss: 1.4445251325766246
Test loss: 1.4881676187117894
Validation loss: 1.4445

-------------------- Epoch 2595 --------------------
Train loss: 1.4618
Test loss: 1.598600114385287
Test loss: 1.6121720125277836
Validation loss: 1.5986

-------------------- Epoch 2596 --------------------
Train loss: 1.4835
Test loss: 1.455541953444481
Test loss: 1.4833866010109584
Validation loss: 1.4555

-------------------- Epoch 2597 --------------------
Train loss: 1.6556
Test loss: 1.7734812200069427
Test loss: 1.8149720877408981
Validation loss: 1.7735

-------------------- Epoch 2598 --------------------
Train loss: 1.4388
Test loss: 1.418050043284893
Test loss: 1.4744078268607457
New best validation loss: 1.4181, saving model weights to best_model_weights.pth

-------------------- Epoch 2599 --------------------
Train loss: 1.4604
Test loss: 1.7267504533131917
Test loss: 1.7598614146312077
Validation loss: 1.7268

-------------------- Epoch 2600 --------------------
Train loss: 1.5895
Test loss: 1.6169247676928837
Test loss: 1.6511807988087337
Validation loss: 1.6169

-------------------- Epoch 2601 --------------------
Train loss: 1.4364
Test loss: 1.5299243330955505
Test loss: 1.576551268498103
Validation loss: 1.5299

-------------------- Epoch 2602 --------------------
Train loss: 1.4725
Test loss: 1.4677901566028595
Test loss: 1.5152347534894943
Validation loss: 1.4678

-------------------- Epoch 2603 --------------------
Train loss: 1.4442
Test loss: 1.4326240867376328
Test loss: 1.4686708897352219
Validation loss: 1.4326

-------------------- Epoch 2604 --------------------
Train loss: 1.4702
Test loss: 1.4654400646686554
Test loss: 1.5073314309120178
Validation loss: 1.4654

-------------------- Epoch 2605 --------------------
Train loss: 1.4298
Test loss: 1.4490161885817845
Test loss: 1.4789429356654484
Validation loss: 1.4490

-------------------- Epoch 2606 --------------------
Train loss: 1.4671
Test loss: 1.5097079128026962
Test loss: 1.5315508097410202
Validation loss: 1.5097

-------------------- Epoch 2607 --------------------
Train loss: 1.4879
Test loss: 1.4321645498275757
Test loss: 1.4739395429690678
Validation loss: 1.4322

-------------------- Epoch 2608 --------------------
Train loss: 1.4961
Test loss: 1.4319044426083565
Test loss: 1.4724050909280777
Validation loss: 1.4319

-------------------- Epoch 2609 --------------------
Train loss: 1.4562
Test loss: 1.5365993231534958
Test loss: 1.577309454480807
Validation loss: 1.5366

-------------------- Epoch 2610 --------------------
Train loss: 1.4409
Test loss: 1.6056999762852986
Test loss: 1.6450584630171459
Validation loss: 1.6057

-------------------- Epoch 2611 --------------------
Train loss: 1.4784
Test loss: 1.5253332704305649
Test loss: 1.5772702395915985
Validation loss: 1.5253

-------------------- Epoch 2612 --------------------
Train loss: 1.4622
Test loss: 1.4238970379034679
Test loss: 1.4604683021704357
Validation loss: 1.4239

-------------------- Epoch 2613 --------------------
Train loss: 1.4512
Test loss: 1.4608296950658162
Test loss: 1.5221572170654933
Validation loss: 1.4608

-------------------- Epoch 2614 --------------------
Train loss: 1.4120
Test loss: 1.5235712677240372
Test loss: 1.6030177821715672
Validation loss: 1.5236

-------------------- Epoch 2615 --------------------
Train loss: 1.4491
Test loss: 1.5295717964569728
Test loss: 1.5682006975015004
Validation loss: 1.5296

-------------------- Epoch 2616 --------------------
Train loss: 1.7378
Test loss: 1.9252912203470867
Test loss: 1.9434599926074345
Validation loss: 1.9253

-------------------- Epoch 2617 --------------------
Train loss: 1.4623
Test loss: 1.5802010297775269
Test loss: 1.6374026636282604
Validation loss: 1.5802

-------------------- Epoch 2618 --------------------
Train loss: 1.4715
Test loss: 1.4196921239296596
Test loss: 1.4773196280002594
Validation loss: 1.4197

-------------------- Epoch 2619 --------------------
Train loss: 1.4807
Test loss: 1.4740288257598877
Test loss: 1.5210963586966197
Validation loss: 1.4740

-------------------- Epoch 2620 --------------------
Train loss: 1.4702
Test loss: 1.533892000714938
Test loss: 1.590232754747073
Validation loss: 1.5339

-------------------- Epoch 2621 --------------------
Train loss: 1.4372
Test loss: 1.5109662065903346
Test loss: 1.5486285984516144
Validation loss: 1.5110

-------------------- Epoch 2622 --------------------
Train loss: 1.4681
Test loss: 1.7385411908229191
Test loss: 1.7501247177521388
Validation loss: 1.7385

-------------------- Epoch 2623 --------------------
Train loss: 1.6537
Test loss: 1.485575293501218
Test loss: 1.5085049867630005
Validation loss: 1.4856

-------------------- Epoch 2624 --------------------
Train loss: 1.4341
Test loss: 1.71941144267718
Test loss: 1.7844208329916
Validation loss: 1.7194

-------------------- Epoch 2625 --------------------
Train loss: 1.5943
Test loss: 1.7607429673274357
Test loss: 1.7765524238348007
Validation loss: 1.7607

-------------------- Epoch 2626 --------------------
Train loss: 1.4476
Test loss: 1.4608415563901265
Test loss: 1.5098751038312912
Validation loss: 1.4608

-------------------- Epoch 2627 --------------------
Train loss: 1.4265
Test loss: 1.4995340357224147
Test loss: 1.5249048719803493
Validation loss: 1.4995

-------------------- Epoch 2628 --------------------
Train loss: 1.4203
Test loss: 1.437206854422887
Test loss: 1.468732590476672
Validation loss: 1.4372

-------------------- Epoch 2629 --------------------
Train loss: 1.4416
Test loss: 1.5835208942492802
Test loss: 1.6149538854757945
Validation loss: 1.5835

-------------------- Epoch 2630 --------------------
Train loss: 1.4263
Test loss: 1.4200629591941833
Test loss: 1.4611455003420513
Validation loss: 1.4201

-------------------- Epoch 2631 --------------------
Train loss: 1.4670
Test loss: 1.4084044148524602
Test loss: 1.4538129369417827
New best validation loss: 1.4084, saving model weights to best_model_weights.pth

-------------------- Epoch 2632 --------------------
Train loss: 1.4332
Test loss: 1.5391663362582524
Test loss: 1.5961723526318867
Validation loss: 1.5392

-------------------- Epoch 2633 --------------------
Train loss: 1.4317
Test loss: 1.589376449584961
Test loss: 1.610878472526868
Validation loss: 1.5894

-------------------- Epoch 2634 --------------------
Train loss: 1.4758
Test loss: 1.498674139380455
Test loss: 1.532242884238561
Validation loss: 1.4987

-------------------- Epoch 2635 --------------------
Train loss: 1.7555
Test loss: 2.236464569965998
Test loss: 2.2942458242177963
Validation loss: 2.2365

-------------------- Epoch 2636 --------------------
Train loss: 1.5135
Test loss: 1.4248543481032054
Test loss: 1.4737162987391155
Validation loss: 1.4249

-------------------- Epoch 2637 --------------------
Train loss: 1.4182
Test loss: 1.4263904343048732
Test loss: 1.4644153167804081
Validation loss: 1.4264

-------------------- Epoch 2638 --------------------
Train loss: 1.4268
Test loss: 1.4115427484114964
Test loss: 1.4514313464363415
Validation loss: 1.4115

-------------------- Epoch 2639 --------------------
Train loss: 1.4415
Test loss: 1.4524309486150742
Test loss: 1.486499269803365
Validation loss: 1.4524

-------------------- Epoch 2640 --------------------
Train loss: 1.4404
Test loss: 1.490631952881813
Test loss: 1.5475058406591415
Validation loss: 1.4906

-------------------- Epoch 2641 --------------------
Train loss: 1.4226
Test loss: 1.4760659635066986
Test loss: 1.5256491750478745
Validation loss: 1.4761

-------------------- Epoch 2642 --------------------
Train loss: 1.4074
Test loss: 1.55267400542895
Test loss: 1.6112398008505504
Validation loss: 1.5527

-------------------- Epoch 2643 --------------------
Train loss: 1.8510
Test loss: 2.0475549548864365
Test loss: 2.0691122164328895
Validation loss: 2.0476

-------------------- Epoch 2644 --------------------
Train loss: 1.4467
Test loss: 1.4229035054643948
Test loss: 1.457678958773613
Validation loss: 1.4229

-------------------- Epoch 2645 --------------------
Train loss: 1.4067
Test loss: 1.6329726229111354
Test loss: 1.672927017013232
Validation loss: 1.6330

-------------------- Epoch 2646 --------------------
Train loss: 1.4692
Test loss: 1.5077333847681682
Test loss: 1.5557503054539363
Validation loss: 1.5077

-------------------- Epoch 2647 --------------------
Train loss: 1.4175
Test loss: 1.4492835700511932
Test loss: 1.4860486512382824
Validation loss: 1.4493

-------------------- Epoch 2648 --------------------
Train loss: 1.4110
Test loss: 1.4441024859746296
Test loss: 1.4882845828930538
Validation loss: 1.4441

-------------------- Epoch 2649 --------------------
Train loss: 1.4571
Test loss: 1.6490959078073502
Test loss: 1.6866904993851979
Validation loss: 1.6491

-------------------- Epoch 2650 --------------------
Train loss: 1.4917
Test loss: 1.5531362692515056
Test loss: 1.6068654259045918
Validation loss: 1.5531

-------------------- Epoch 2651 --------------------
Train loss: 1.4346
Test loss: 1.4408959647019703
Test loss: 1.4892295897006989
Validation loss: 1.4409

-------------------- Epoch 2652 --------------------
Train loss: 1.4329
Test loss: 1.6959214856227238
Test loss: 1.7247612377007802
Validation loss: 1.6959

-------------------- Epoch 2653 --------------------
Train loss: 1.4375
Test loss: 1.4527896444002788
Test loss: 1.4996495967109997
Validation loss: 1.4528

-------------------- Epoch 2654 --------------------
Train loss: 1.4202
Test loss: 1.4308027476072311
Test loss: 1.4810433586438496
Validation loss: 1.4308

-------------------- Epoch 2655 --------------------
Train loss: 1.4241
Test loss: 1.421979198853175
Test loss: 1.4581473072369893
Validation loss: 1.4220

-------------------- Epoch 2656 --------------------
Train loss: 1.4246
Test loss: 1.8447215755780537
Test loss: 1.846996322274208
Validation loss: 1.8447

-------------------- Epoch 2657 --------------------
Train loss: 1.5642
Test loss: 1.4558194155494373
Test loss: 1.4902140696843464
Validation loss: 1.4558

-------------------- Epoch 2658 --------------------
Train loss: 1.4575
Test loss: 1.4234184324741364
Test loss: 1.467367169757684
Validation loss: 1.4234

-------------------- Epoch 2659 --------------------
Train loss: 1.4847
Test loss: 1.8907531996568043
Test loss: 1.899536704023679
Validation loss: 1.8908

-------------------- Epoch 2660 --------------------
Train loss: 1.4919
Test loss: 1.4526010354359944
Test loss: 1.4804821014404297
Validation loss: 1.4526

-------------------- Epoch 2661 --------------------
Train loss: 1.4192
Test loss: 1.5109114944934845
Test loss: 1.5676819185415904
Validation loss: 1.5109

-------------------- Epoch 2662 --------------------
Train loss: 1.4158
Test loss: 1.4883583039045334
Test loss: 1.5476735333601634
Validation loss: 1.4884

-------------------- Epoch 2663 --------------------
Train loss: 1.4213
Test loss: 1.4364866862694423
Test loss: 1.4964436541001003
Validation loss: 1.4365

-------------------- Epoch 2664 --------------------
Train loss: 1.4664
Test loss: 1.426815206805865
Test loss: 1.4561845461527507
Validation loss: 1.4268

-------------------- Epoch 2665 --------------------
Train loss: 1.4037
Test loss: 1.4365938504536946
Test loss: 1.5010917286078136
Validation loss: 1.4366

-------------------- Epoch 2666 --------------------
Train loss: 1.4137
Test loss: 1.4917830228805542
Test loss: 1.5471770912408829
Validation loss: 1.4918

-------------------- Epoch 2667 --------------------
Train loss: 1.4430
Test loss: 1.6127522240082424
Test loss: 1.6728206425905228
Validation loss: 1.6128

-------------------- Epoch 2668 --------------------
Train loss: 1.4135
Test loss: 1.439683586359024
Test loss: 1.4905405441919963
Validation loss: 1.4397

-------------------- Epoch 2669 --------------------
Train loss: 1.4447
Test loss: 1.6526344915231068
Test loss: 1.6737671395142872
Validation loss: 1.6526

-------------------- Epoch 2670 --------------------
Train loss: 1.4343
Test loss: 1.6579655905564625
Test loss: 1.7215123176574707
Validation loss: 1.6580

-------------------- Epoch 2671 --------------------
Train loss: 1.4501
Test loss: 1.5990349302689235
Test loss: 1.657117451230685
Validation loss: 1.5990

-------------------- Epoch 2672 --------------------
Train loss: 1.4151
Test loss: 1.6887415250142415
Test loss: 1.7510551859935124
Validation loss: 1.6887

-------------------- Epoch 2673 --------------------
Train loss: 1.4476
Test loss: 1.42043836414814
Test loss: 1.4528290157516797
Validation loss: 1.4204

-------------------- Epoch 2674 --------------------
Train loss: 1.4437
Test loss: 1.4108006730675697
Test loss: 1.460205502808094
Validation loss: 1.4108

-------------------- Epoch 2675 --------------------
Train loss: 1.4117
Test loss: 1.4270797570546467
Test loss: 1.4823707441488903
Validation loss: 1.4271

-------------------- Epoch 2676 --------------------
Train loss: 1.4352
Test loss: 1.4380813191334407
Test loss: 1.4768778334061305
Validation loss: 1.4381

-------------------- Epoch 2677 --------------------
Train loss: 1.4180
Test loss: 1.4509712159633636
Test loss: 1.5044586410125096
Validation loss: 1.4510

-------------------- Epoch 2678 --------------------
Train loss: 1.4323
Test loss: 1.5662970344225566
Test loss: 1.6110350638628006
Validation loss: 1.5663

-------------------- Epoch 2679 --------------------
Train loss: 1.4466
Test loss: 1.49575279156367
Test loss: 1.5621911237637203
Validation loss: 1.4958

-------------------- Epoch 2680 --------------------
Train loss: 1.4313
Test loss: 1.4349947919448216
Test loss: 1.4864424616098404
Validation loss: 1.4350

-------------------- Epoch 2681 --------------------
Train loss: 1.4519
Test loss: 1.6009468287229538
Test loss: 1.6233396182457607
Validation loss: 1.6009

-------------------- Epoch 2682 --------------------
Train loss: 1.4141
Test loss: 1.5448652009169261
Test loss: 1.5956333925326665
Validation loss: 1.5449

-------------------- Epoch 2683 --------------------
Train loss: 1.4273
Test loss: 1.4384304210543633
Test loss: 1.4754100864132245
Validation loss: 1.4384

-------------------- Epoch 2684 --------------------
Train loss: 1.4323
Test loss: 1.412504365046819
Test loss: 1.4513718287150066
Validation loss: 1.4125

-------------------- Epoch 2685 --------------------
Train loss: 1.3892
Test loss: 1.4418350458145142
Test loss: 1.4872757842143376
Validation loss: 1.4418

-------------------- Epoch 2686 --------------------
Train loss: 1.4019
Test loss: 1.409620036681493
Test loss: 1.4530128439267476
Validation loss: 1.4096

-------------------- Epoch 2687 --------------------
Train loss: 1.4433
Test loss: 1.522999830543995
Test loss: 1.5604472011327744
Validation loss: 1.5230

-------------------- Epoch 2688 --------------------
Train loss: 1.4259
Test loss: 1.421439677476883
Test loss: 1.4612075264255207
Validation loss: 1.4214

-------------------- Epoch 2689 --------------------
Train loss: 1.4200
Test loss: 1.4798660775025685
Test loss: 1.5246259396274884
Validation loss: 1.4799

-------------------- Epoch 2690 --------------------
Train loss: 1.4238
Test loss: 1.4352571616570156
Test loss: 1.4947201907634735
Validation loss: 1.4353

-------------------- Epoch 2691 --------------------
Train loss: 1.4757
Test loss: 1.6198601921399434
Test loss: 1.632562239964803
Validation loss: 1.6199

-------------------- Epoch 2692 --------------------
Train loss: 1.6730
Test loss: 1.5297196457783382
Test loss: 1.586244523525238
Validation loss: 1.5297

-------------------- Epoch 2693 --------------------
Train loss: 1.3934
Test loss: 1.4961056560277939
Test loss: 1.5255646854639053
Validation loss: 1.4961

-------------------- Epoch 2694 --------------------
Train loss: 1.3897
Test loss: 1.4228742619355519
Test loss: 1.4818373769521713
Validation loss: 1.4229

-------------------- Epoch 2695 --------------------
Train loss: 1.4784
Test loss: 1.421898792187373
Test loss: 1.457471748193105
Validation loss: 1.4219

-------------------- Epoch 2696 --------------------
Train loss: 1.4162
Test loss: 1.4364521155754726
Test loss: 1.4818994974096615
Validation loss: 1.4365

-------------------- Epoch 2697 --------------------
Train loss: 1.3906
Test loss: 1.4091958180069923
Test loss: 1.458189696073532
Validation loss: 1.4092

-------------------- Epoch 2698 --------------------
Train loss: 1.3933
Test loss: 1.6078060021003087
Test loss: 1.6670117030541103
Validation loss: 1.6078

-------------------- Epoch 2699 --------------------
Train loss: 1.3935
Test loss: 1.4160788630445797
Test loss: 1.466177836060524
Validation loss: 1.4161

-------------------- Epoch 2700 --------------------
Train loss: 1.3919
Test loss: 1.7442638377348583
Test loss: 1.8019648691018422
Validation loss: 1.7443

-------------------- Epoch 2701 --------------------
Train loss: 1.4320
Test loss: 1.456378350655238
Test loss: 1.4866582155227661
Validation loss: 1.4564

-------------------- Epoch 2702 --------------------
Train loss: 1.4277
Test loss: 1.4632055113712947
Test loss: 1.4956370542446773
Validation loss: 1.4632

-------------------- Epoch 2703 --------------------
Train loss: 1.4282
Test loss: 1.478123779098193
Test loss: 1.5067905187606812
Validation loss: 1.4781

-------------------- Epoch 2704 --------------------
Train loss: 1.3862
Test loss: 1.4185690879821777
Test loss: 1.4545472760995228
Validation loss: 1.4186

-------------------- Epoch 2705 --------------------
Train loss: 1.4174
Test loss: 1.4607668270667393
Test loss: 1.4994125763575237
Validation loss: 1.4608

-------------------- Epoch 2706 --------------------
Train loss: 1.5598
Test loss: 1.6162546575069427
Test loss: 1.648137132326762
Validation loss: 1.6163

-------------------- Epoch 2707 --------------------
Train loss: 1.4141
Test loss: 1.5742551932732265
Test loss: 1.6404474526643753
Validation loss: 1.5743

-------------------- Epoch 2708 --------------------
Train loss: 1.4285
Test loss: 1.4094831546147664
Test loss: 1.4502850100398064
Validation loss: 1.4095

-------------------- Epoch 2709 --------------------
Train loss: 1.3959
Test loss: 1.45272596180439
Test loss: 1.5093470513820648
Validation loss: 1.4527

-------------------- Epoch 2710 --------------------
Train loss: 1.4011
Test loss: 1.4404898062348366
Test loss: 1.4780270929137866
Validation loss: 1.4405

-------------------- Epoch 2711 --------------------
Train loss: 1.4282
Test loss: 1.4237922454873722
Test loss: 1.478520728647709
Validation loss: 1.4238

-------------------- Epoch 2712 --------------------
Train loss: 1.4000
Test loss: 1.4610678106546402
Test loss: 1.5061874041954677
Validation loss: 1.4611

-------------------- Epoch 2713 --------------------
Train loss: 1.4023
Test loss: 1.428501586119334
Test loss: 1.4788360297679901
Validation loss: 1.4285

-------------------- Epoch 2714 --------------------
Train loss: 1.4467
Test loss: 1.408827173213164
Test loss: 1.451072891553243
Validation loss: 1.4088

-------------------- Epoch 2715 --------------------
Train loss: 1.4286
Test loss: 1.4644386072953541
Test loss: 1.5001337081193924
Validation loss: 1.4644

-------------------- Epoch 2716 --------------------
Train loss: 1.4134
Test loss: 1.4128844539324443
Test loss: 1.4480248242616653
Validation loss: 1.4129

-------------------- Epoch 2717 --------------------
Train loss: 1.4170
Test loss: 1.4138754705588024
Test loss: 1.4521677220861118
Validation loss: 1.4139

-------------------- Epoch 2718 --------------------
Train loss: 1.3943
Test loss: 1.4360881944497426
Test loss: 1.4942326198021572
Validation loss: 1.4361

-------------------- Epoch 2719 --------------------
Train loss: 1.4157
Test loss: 1.4890460073947906
Test loss: 1.5147799750169118
Validation loss: 1.4890

-------------------- Epoch 2720 --------------------
Train loss: 1.4138
Test loss: 1.4383941690127056
Test loss: 1.4836682230234146
Validation loss: 1.4384

-------------------- Epoch 2721 --------------------
Train loss: 1.3956
Test loss: 1.4558972070614498
Test loss: 1.4868162274360657
Validation loss: 1.4559

-------------------- Epoch 2722 --------------------
Train loss: 1.4143
Test loss: 1.457485208908717
Test loss: 1.4912675966819127
Validation loss: 1.4575

-------------------- Epoch 2723 --------------------
Train loss: 1.4562
Test loss: 1.8224268158276875
Test loss: 1.869773382941882
Validation loss: 1.8224

-------------------- Epoch 2724 --------------------
Train loss: 1.4253
Test loss: 1.6653156628211339
Test loss: 1.6946924775838852
Validation loss: 1.6653

-------------------- Epoch 2725 --------------------
Train loss: 1.4205
Test loss: 1.4258785843849182
Test loss: 1.4774314761161804
Validation loss: 1.4259

-------------------- Epoch 2726 --------------------
Train loss: 1.3914
Test loss: 1.4635277365644772
Test loss: 1.5009061843156815
Validation loss: 1.4635

-------------------- Epoch 2727 --------------------
Train loss: 1.4018
Test loss: 1.4078934788703918
Test loss: 1.4480470592776935
New best validation loss: 1.4079, saving model weights to best_model_weights.pth

-------------------- Epoch 2728 --------------------
Train loss: 1.3886
Test loss: 1.4142791132132213
Test loss: 1.4432074179251988
Validation loss: 1.4143

-------------------- Epoch 2729 --------------------
Train loss: 1.3888
Test loss: 1.4023725638786952
Test loss: 1.442091390490532
New best validation loss: 1.4024, saving model weights to best_model_weights.pth

-------------------- Epoch 2730 --------------------
Train loss: 1.3827
Test loss: 1.4379640171925228
Test loss: 1.4659521629412968
Validation loss: 1.4380

-------------------- Epoch 2731 --------------------
Train loss: 1.4018
Test loss: 1.430011789004008
Test loss: 1.481038714448611
Validation loss: 1.4300

-------------------- Epoch 2732 --------------------
Train loss: 1.4002
Test loss: 1.4251525849103928
Test loss: 1.461669569214185
Validation loss: 1.4252

-------------------- Epoch 2733 --------------------
Train loss: 1.3874
Test loss: 1.4324078857898712
Test loss: 1.4710903068383534
Validation loss: 1.4324

-------------------- Epoch 2734 --------------------
Train loss: 1.4025
Test loss: 1.5087076375881832
Test loss: 1.563501998782158
Validation loss: 1.5087

-------------------- Epoch 2735 --------------------
Train loss: 1.4080
Test loss: 1.4170313253998756
Test loss: 1.465236430366834
Validation loss: 1.4170

-------------------- Epoch 2736 --------------------
Train loss: 1.3886
Test loss: 1.412746141354243
Test loss: 1.4578769604365032
Validation loss: 1.4127

-------------------- Epoch 2737 --------------------
Train loss: 1.4983
Test loss: 1.4112665330370266
Test loss: 1.4490504190325737
Validation loss: 1.4113

-------------------- Epoch 2738 --------------------
Train loss: 1.7603
Test loss: 1.49601877729098
Test loss: 1.5249473253885906
Validation loss: 1.4960

-------------------- Epoch 2739 --------------------
Train loss: 1.3797
Test loss: 1.4520181616147358
Test loss: 1.4998500694831212
Validation loss: 1.4520

-------------------- Epoch 2740 --------------------
Train loss: 1.4274
Test loss: 1.6193861464659374
Test loss: 1.684342011809349
Validation loss: 1.6194

-------------------- Epoch 2741 --------------------
Train loss: 1.3850
Test loss: 1.5198698490858078
Test loss: 1.5787846793731053
Validation loss: 1.5199

-------------------- Epoch 2742 --------------------
Train loss: 1.4028
Test loss: 1.649575635790825
Test loss: 1.674445241689682
Validation loss: 1.6496

-------------------- Epoch 2743 --------------------
Train loss: 1.4043
Test loss: 1.4235696643590927
Test loss: 1.4614281530181568
Validation loss: 1.4236

-------------------- Epoch 2744 --------------------
Train loss: 1.4087
Test loss: 1.450157567858696
Test loss: 1.4829770823319752
Validation loss: 1.4502

-------------------- Epoch 2745 --------------------
Train loss: 1.3781
Test loss: 1.4846419592698414
Test loss: 1.5214961369832356
Validation loss: 1.4846

-------------------- Epoch 2746 --------------------
Train loss: 1.4085
Test loss: 1.406006487707297
Test loss: 1.4556656380494435
Validation loss: 1.4060

-------------------- Epoch 2747 --------------------
Train loss: 1.4079
Test loss: 1.4309474279483159
Test loss: 1.4771868884563446
Validation loss: 1.4309

-------------------- Epoch 2748 --------------------
Train loss: 1.4844
Test loss: 1.4204668998718262
Test loss: 1.4603220423062642
Validation loss: 1.4205

-------------------- Epoch 2749 --------------------
Train loss: 1.3764
Test loss: 1.4373786201079686
Test loss: 1.4707088619470596
Validation loss: 1.4374

-------------------- Epoch 2750 --------------------
Train loss: 1.3884
Test loss: 1.962862824400266
Test loss: 1.9773638397455215
Validation loss: 1.9629

-------------------- Epoch 2751 --------------------
Train loss: 1.4749
Test loss: 1.4162534475326538
Test loss: 1.4631643816828728
Validation loss: 1.4163

-------------------- Epoch 2752 --------------------
Train loss: 1.4016
Test loss: 1.4482314040263493
Test loss: 1.4864483972390492
Validation loss: 1.4482

-------------------- Epoch 2753 --------------------
Train loss: 1.3812
Test loss: 1.4889031151930492
Test loss: 1.5367342332998912
Validation loss: 1.4889

-------------------- Epoch 2754 --------------------
Train loss: 1.4074
Test loss: 1.446995163957278
Test loss: 1.4944627036650975
Validation loss: 1.4470

-------------------- Epoch 2755 --------------------
Train loss: 1.3857
Test loss: 1.4079601466655731
Test loss: 1.4537188013394673
Validation loss: 1.4080

-------------------- Epoch 2756 --------------------
Train loss: 1.3976
Test loss: 1.41498002409935
Test loss: 1.4555006970961888
Validation loss: 1.4150

-------------------- Epoch 2757 --------------------
Train loss: 1.3791
Test loss: 1.4421749686201413
Test loss: 1.4758891314268112
Validation loss: 1.4422

-------------------- Epoch 2758 --------------------
Train loss: 1.3795
Test loss: 1.4703199863433838
Test loss: 1.5175255884726842
Validation loss: 1.4703

-------------------- Epoch 2759 --------------------
Train loss: 1.3751
Test loss: 1.4763952443997066
Test loss: 1.5254560311635335
Validation loss: 1.4764

-------------------- Epoch 2760 --------------------
Train loss: 1.4394
Test loss: 1.4776297882199287
Test loss: 1.5163662632306416
Validation loss: 1.4776

-------------------- Epoch 2761 --------------------
Train loss: 1.3934
Test loss: 1.413236990571022
Test loss: 1.4566625530521076
Validation loss: 1.4132

-------------------- Epoch 2762 --------------------
Train loss: 1.4423
Test loss: 1.4453536073366802
Test loss: 1.473662440975507
Validation loss: 1.4454

-------------------- Epoch 2763 --------------------
Train loss: 1.3790
Test loss: 1.4060294404625893
Test loss: 1.4466820359230042
Validation loss: 1.4060

-------------------- Epoch 2764 --------------------
Train loss: 1.3933
Test loss: 1.4419233798980713
Test loss: 1.4904570629199345
Validation loss: 1.4419

-------------------- Epoch 2765 --------------------
Train loss: 1.3793
Test loss: 1.4041863257686298
Test loss: 1.441150297721227
Validation loss: 1.4042

-------------------- Epoch 2766 --------------------
Train loss: 1.3792
Test loss: 1.4265299315253894
Test loss: 1.4614773641029994
Validation loss: 1.4265

-------------------- Epoch 2767 --------------------
Train loss: 1.3777
Test loss: 1.4288300325473149
Test loss: 1.4660611773530643
Validation loss: 1.4288

-------------------- Epoch 2768 --------------------
Train loss: 1.4328
Test loss: 1.4217428987224896
Test loss: 1.4646183277169864
Validation loss: 1.4217

-------------------- Epoch 2769 --------------------
Train loss: 1.3955
Test loss: 1.4069521104296048
Test loss: 1.449160431822141
Validation loss: 1.4070

-------------------- Epoch 2770 --------------------
Train loss: 1.5003
Test loss: 1.4174528444806735
Test loss: 1.4596231778462727
Validation loss: 1.4175

-------------------- Epoch 2771 --------------------
Train loss: 1.3814
Test loss: 1.4216579770048459
Test loss: 1.4607993563016255
Validation loss: 1.4217

-------------------- Epoch 2772 --------------------
Train loss: 1.3715
Test loss: 1.4693671613931656
Test loss: 1.5127459118763606
Validation loss: 1.4694

-------------------- Epoch 2773 --------------------
Train loss: 1.3732
Test loss: 1.4104398638010025
Test loss: 1.4482584844032924
Validation loss: 1.4104

-------------------- Epoch 2774 --------------------
Train loss: 1.3831
Test loss: 1.5027263015508652
Test loss: 1.5612603624661763
Validation loss: 1.5027

-------------------- Epoch 2775 --------------------
Train loss: 1.3757
Test loss: 1.4044053554534912
Test loss: 1.4460113868117332
Validation loss: 1.4044

-------------------- Epoch 2776 --------------------
Train loss: 1.3732
Test loss: 1.4256207173069317
Test loss: 1.4687107801437378
Validation loss: 1.4256

-------------------- Epoch 2777 --------------------
Train loss: 1.3729
Test loss: 1.4302551796038945
Test loss: 1.4764736046393712
Validation loss: 1.4303

-------------------- Epoch 2778 --------------------
Train loss: 1.3743
Test loss: 1.4103877892096837
Test loss: 1.453988139828046
Validation loss: 1.4104

-------------------- Epoch 2779 --------------------
Train loss: 1.3757
Test loss: 1.4069861595829327
Test loss: 1.4463981837034225
Validation loss: 1.4070

-------------------- Epoch 2780 --------------------
Train loss: 1.3701
Test loss: 1.413684534529845
Test loss: 1.4569981048504512
Validation loss: 1.4137

-------------------- Epoch 2781 --------------------
Train loss: 1.3640
Test loss: 1.4127142528692882
Test loss: 1.4593727712829907
Validation loss: 1.4127

-------------------- Epoch 2782 --------------------
Train loss: 1.3676
Test loss: 1.4060019105672836
Test loss: 1.4510528941949208
Validation loss: 1.4060

-------------------- Epoch 2783 --------------------
Train loss: 1.3948
Test loss: 1.6174987902243931
Test loss: 1.678212746977806
Validation loss: 1.6175

-------------------- Epoch 2784 --------------------
Train loss: 1.3924
Test loss: 1.4305439318219821
Test loss: 1.4643717308839161
Validation loss: 1.4305

-------------------- Epoch 2785 --------------------
Train loss: 1.3693
Test loss: 1.4440689881642659
Test loss: 1.4934991002082825
Validation loss: 1.4441

-------------------- Epoch 2786 --------------------
Train loss: 1.5806
Test loss: 1.4062059720357258
Test loss: 1.4499259019891422
Validation loss: 1.4062

-------------------- Epoch 2787 --------------------
Train loss: 1.3720
Test loss: 1.4095356340209644
Test loss: 1.4444374019900958
Validation loss: 1.4095

-------------------- Epoch 2788 --------------------
Train loss: 1.3890
Test loss: 1.4137048820654552
Test loss: 1.4532389665643375
Validation loss: 1.4137

-------------------- Epoch 2789 --------------------
Train loss: 1.3813
Test loss: 1.495931163430214
Test loss: 1.5248717566331227
Validation loss: 1.4959

-------------------- Epoch 2790 --------------------
Train loss: 1.7320
Test loss: 1.464862937728564
Test loss: 1.5010510633389156
Validation loss: 1.4649

-------------------- Epoch 2791 --------------------
Train loss: 1.3938
Test loss: 1.4050477345784504
Test loss: 1.452357940375805
Validation loss: 1.4050

-------------------- Epoch 2792 --------------------
Train loss: 1.3747
Test loss: 1.4218890766302745
Test loss: 1.45632270971934
Validation loss: 1.4219

-------------------- Epoch 2793 --------------------
Train loss: 1.3842
Test loss: 1.4208042522271473
Test loss: 1.4525575215617816
Validation loss: 1.4208

-------------------- Epoch 2794 --------------------
Train loss: 1.3707
Test loss: 1.4099050785104434
Test loss: 1.4468917772173882
Validation loss: 1.4099

-------------------- Epoch 2795 --------------------
Train loss: 1.3846
Test loss: 1.4073471029599507
Test loss: 1.451248159011205
Validation loss: 1.4073

-------------------- Epoch 2796 --------------------
Train loss: 1.3648
Test loss: 1.40935580432415
Test loss: 1.4529736563563347
Validation loss: 1.4094

-------------------- Epoch 2797 --------------------
Train loss: 1.3636
Test loss: 1.40119764705499
Test loss: 1.4438215121626854
New best validation loss: 1.4012, saving model weights to best_model_weights.pth

-------------------- Epoch 2798 --------------------
Train loss: 1.3722
Test loss: 1.431518907348315
Test loss: 1.4651569326718648
Validation loss: 1.4315

-------------------- Epoch 2799 --------------------
Train loss: 1.3687
Test loss: 1.516695722937584
Test loss: 1.5741871545712154
Validation loss: 1.5167

-------------------- Epoch 2800 --------------------
Train loss: 1.3737
Test loss: 1.4564887682596843
Test loss: 1.4842764834562938
Validation loss: 1.4565

-------------------- Epoch 2801 --------------------
Train loss: 1.3694
Test loss: 1.405383477608363
Test loss: 1.4474720160166423
Validation loss: 1.4054

-------------------- Epoch 2802 --------------------
Train loss: 1.3768
Test loss: 1.4103816573818524
Test loss: 1.4561387648185093
Validation loss: 1.4104

-------------------- Epoch 2803 --------------------
Train loss: 1.3873
Test loss: 1.4074737280607224
Test loss: 1.4484116261204083
Validation loss: 1.4075

-------------------- Epoch 2804 --------------------
Train loss: 1.3737
Test loss: 1.4400849118828773
Test loss: 1.4732858091592789
Validation loss: 1.4401

-------------------- Epoch 2805 --------------------
Train loss: 1.3607
Test loss: 1.4992301712433498
Test loss: 1.5542811304330826
Validation loss: 1.4992

-------------------- Epoch 2806 --------------------
Train loss: 1.3832
Test loss: 1.4486749644080799
Test loss: 1.4879105190436046
Validation loss: 1.4487

-------------------- Epoch 2807 --------------------
Train loss: 1.3758
Test loss: 1.4015781333049138
Test loss: 1.4445923243959744
Validation loss: 1.4016

-------------------- Epoch 2808 --------------------
Train loss: 1.3751
Test loss: 1.414584105213483
Test loss: 1.455936166147391
Validation loss: 1.4146

-------------------- Epoch 2809 --------------------
Train loss: 1.3851
Test loss: 1.4361212402582169
Test loss: 1.483544036746025
Validation loss: 1.4361

-------------------- Epoch 2810 --------------------
Train loss: 1.3641
Test loss: 1.4145771513382595
Test loss: 1.4561139990886052
Validation loss: 1.4146

-------------------- Epoch 2811 --------------------
Train loss: 1.3768
Test loss: 1.4155157208442688
Test loss: 1.4657417436440785
Validation loss: 1.4155

-------------------- Epoch 2812 --------------------
Train loss: 1.3887
Test loss: 1.4084917679429054
Test loss: 1.4564699307084084
Validation loss: 1.4085

-------------------- Epoch 2813 --------------------
Train loss: 1.3830
Test loss: 1.5060885846614838
Test loss: 1.5324282000462215
Validation loss: 1.5061

-------------------- Epoch 2814 --------------------
Train loss: 1.3707
Test loss: 1.4045742551485698
Test loss: 1.4527514775594075
Validation loss: 1.4046

-------------------- Epoch 2815 --------------------
Train loss: 1.3673
Test loss: 1.4573416312535603
Test loss: 1.4898323466380436
Validation loss: 1.4573

-------------------- Epoch 2816 --------------------
Train loss: 1.3724
Test loss: 1.4096602996190388
Test loss: 1.4495259051521618
Validation loss: 1.4097

-------------------- Epoch 2817 --------------------
Train loss: 1.3659
Test loss: 1.4099635531504948
Test loss: 1.4492621272802353
Validation loss: 1.4100

-------------------- Epoch 2818 --------------------
Train loss: 1.3739
Test loss: 1.4019570897022884
Test loss: 1.4437207529942195
Validation loss: 1.4020

-------------------- Epoch 2819 --------------------
Train loss: 1.3632
Test loss: 1.4066008230050404
Test loss: 1.4522388204932213
Validation loss: 1.4066

-------------------- Epoch 2820 --------------------
Train loss: 1.3737
Test loss: 1.420969198147456
Test loss: 1.4678555950522423
Validation loss: 1.4210

-------------------- Epoch 2821 --------------------
Train loss: 1.3677
Test loss: 1.4227098350723584
Test loss: 1.456464817126592
Validation loss: 1.4227

-------------------- Epoch 2822 --------------------
Train loss: 1.3613
Test loss: 1.4000003064672153
Test loss: 1.4449881662925084
New best validation loss: 1.4000, saving model weights to best_model_weights.pth

-------------------- Epoch 2823 --------------------
Train loss: 1.3632
Test loss: 1.4016094505786896
Test loss: 1.4473342547814052
Validation loss: 1.4016

-------------------- Epoch 2824 --------------------
Train loss: 1.3736
Test loss: 1.403023436665535
Test loss: 1.4479455972711246
Validation loss: 1.4030

-------------------- Epoch 2825 --------------------
Train loss: 1.3504
Test loss: 1.4227197915315628
Test loss: 1.4701954573392868
Validation loss: 1.4227

-------------------- Epoch 2826 --------------------
Train loss: 1.3652
Test loss: 1.4053999533255894
Test loss: 1.4457076614101727
Validation loss: 1.4054

-------------------- Epoch 2827 --------------------
Train loss: 1.3618
Test loss: 1.4042699386676152
Test loss: 1.448234664897124
Validation loss: 1.4043

-------------------- Epoch 2828 --------------------
Train loss: 1.3671
Test loss: 1.424146403868993
Test loss: 1.4695728222529094
Validation loss: 1.4241

-------------------- Epoch 2829 --------------------
Train loss: 1.3766
Test loss: 1.4139231195052464
Test loss: 1.4601342007517815
Validation loss: 1.4139

-------------------- Epoch 2830 --------------------
Train loss: 1.3715
Test loss: 1.4206196665763855
Test loss: 1.4551424582799275
Validation loss: 1.4206

-------------------- Epoch 2831 --------------------
Train loss: 1.3613
Test loss: 1.4434356341759365
Test loss: 1.479844609896342
Validation loss: 1.4434

-------------------- Epoch 2832 --------------------
Train loss: 1.6709
Test loss: 1.4398117611805599
Test loss: 1.4758278528849285
Validation loss: 1.4398

-------------------- Epoch 2833 --------------------
Train loss: 1.3597
Test loss: 1.4089281509319942
Test loss: 1.4479648942748706
Validation loss: 1.4089

-------------------- Epoch 2834 --------------------
Train loss: 1.3639
Test loss: 1.4320171624422073
Test loss: 1.4697752570112546
Validation loss: 1.4320

-------------------- Epoch 2835 --------------------
Train loss: 1.3663
Test loss: 1.414057197670142
Test loss: 1.451915830373764
Validation loss: 1.4141

-------------------- Epoch 2836 --------------------
Train loss: 1.3539
Test loss: 1.4054594511787097
Test loss: 1.444642496605714
Validation loss: 1.4055

-------------------- Epoch 2837 --------------------
Train loss: 1.4347
Test loss: 1.4137761717041333
Test loss: 1.4515400951107342
Validation loss: 1.4138

-------------------- Epoch 2838 --------------------
Train loss: 1.5907
Test loss: 1.4132051765918732
Test loss: 1.4577002575000126
Validation loss: 1.4132

-------------------- Epoch 2839 --------------------
Train loss: 1.3525
Test loss: 1.405902937054634
Test loss: 1.4477346315979958
Validation loss: 1.4059

-------------------- Epoch 2840 --------------------
Train loss: 1.3612
Test loss: 1.4041687548160553
Test loss: 1.4428754200537999
Validation loss: 1.4042

-------------------- Epoch 2841 --------------------
Train loss: 1.3590
Test loss: 1.409174993634224
Test loss: 1.4507320846120517
Validation loss: 1.4092

-------------------- Epoch 2842 --------------------
Train loss: 1.3609
Test loss: 1.4076594809691112
Test loss: 1.4522160962224007
Validation loss: 1.4077

-------------------- Epoch 2843 --------------------
Train loss: 1.3590
Test loss: 1.4061947017908096
Test loss: 1.4549019038677216
Validation loss: 1.4062

-------------------- Epoch 2844 --------------------
Train loss: 1.3563
Test loss: 1.4026680116852124
Test loss: 1.4491593837738037
Validation loss: 1.4027

-------------------- Epoch 2845 --------------------
Train loss: 1.3782
Test loss: 1.4113835493723552
Test loss: 1.4499136904875438
Validation loss: 1.4114

-------------------- Epoch 2846 --------------------
Train loss: 1.3630
Test loss: 1.418993314107259
Test loss: 1.4650617813070614
Validation loss: 1.4190

-------------------- Epoch 2847 --------------------
Train loss: 1.9199
Test loss: 1.4027430439988773
Test loss: 1.4473297720154126
Validation loss: 1.4027

-------------------- Epoch 2848 --------------------
Train loss: 1.3580
Test loss: 1.4261097808678944
Test loss: 1.464295655488968
Validation loss: 1.4261

-------------------- Epoch 2849 --------------------
Train loss: 1.4127
Test loss: 1.4023525267839432
Test loss: 1.4464064066608746
Validation loss: 1.4024

-------------------- Epoch 2850 --------------------
Train loss: 1.3633
Test loss: 1.4215124150117238
Test loss: 1.4671556800603867
Validation loss: 1.4215

-------------------- Epoch 2851 --------------------
Train loss: 1.3600
Test loss: 1.408353624244531
Test loss: 1.4490883226195972
Validation loss: 1.4084

-------------------- Epoch 2852 --------------------
Train loss: 1.3543
Test loss: 1.4001905818780263
Test loss: 1.4449858566125233
Validation loss: 1.4002

-------------------- Epoch 2853 --------------------
Train loss: 1.3538
Test loss: 1.401567357281844
Test loss: 1.442529834806919
Validation loss: 1.4016

-------------------- Epoch 2854 --------------------
Train loss: 1.3597
Test loss: 1.407048578063647
Test loss: 1.449676384528478
Validation loss: 1.4070

-------------------- Epoch 2855 --------------------
Train loss: 1.3614
Test loss: 1.4011700004339218
Test loss: 1.443039243419965
Validation loss: 1.4012

-------------------- Epoch 2856 --------------------
Train loss: 1.3537
Test loss: 1.4026288663347561
Test loss: 1.4428248008092244
Validation loss: 1.4026

-------------------- Epoch 2857 --------------------
Train loss: 1.3684
Test loss: 1.4068441987037659
Test loss: 1.4466138035058975
Validation loss: 1.4068

-------------------- Epoch 2858 --------------------
Train loss: 1.3600
Test loss: 1.4032517572244008
Test loss: 1.4447183931867282
Validation loss: 1.4033

-------------------- Epoch 2859 --------------------
Train loss: 1.3509
Test loss: 1.4039498716592789
Test loss: 1.4447223097085953
Validation loss: 1.4039

-------------------- Epoch 2860 --------------------
Train loss: 1.3530
Test loss: 1.408523107568423
Test loss: 1.4515274191896121
Validation loss: 1.4085

-------------------- Epoch 2861 --------------------
Train loss: 1.3485
Test loss: 1.4051850736141205
Test loss: 1.4470456540584564
Validation loss: 1.4052

-------------------- Epoch 2862 --------------------
Train loss: 1.4238
Test loss: 1.4074339369932811
Test loss: 1.447744478782018
Validation loss: 1.4074

-------------------- Epoch 2863 --------------------
Train loss: 1.3804
Test loss: 1.4126381600896518
Test loss: 1.4495836918552716
Validation loss: 1.4126

-------------------- Epoch 2864 --------------------
Train loss: 1.3569
Test loss: 1.400707500676314
Test loss: 1.4465940843025844
Validation loss: 1.4007

-------------------- Epoch 2865 --------------------
Train loss: 1.3533
Test loss: 1.4224538604418437
Test loss: 1.4714048902193706
Validation loss: 1.4225

-------------------- Epoch 2866 --------------------
Train loss: 1.3565
Test loss: 1.402306005358696
Test loss: 1.4439006596803665
Validation loss: 1.4023

-------------------- Epoch 2867 --------------------
Train loss: 1.3610
Test loss: 1.4016974841554959
Test loss: 1.4428437625368435
Validation loss: 1.4017

-------------------- Epoch 2868 --------------------
Train loss: 1.3527
Test loss: 1.401336707174778
Test loss: 1.4428141042590141
Validation loss: 1.4013

-------------------- Epoch 2869 --------------------
Train loss: 1.3619
Test loss: 1.4018647447228432
Test loss: 1.4446530813972156
Validation loss: 1.4019

-------------------- Epoch 2870 --------------------
Train loss: 1.5246
Test loss: 1.4119555999835331
Test loss: 1.4533257881800334
Validation loss: 1.4120

-------------------- Epoch 2871 --------------------
Train loss: 1.3555
Test loss: 1.4045447359482448
Test loss: 1.4473903278509777
Validation loss: 1.4045

-------------------- Epoch 2872 --------------------
Train loss: 1.3523
Test loss: 1.4121291190385818
Test loss: 1.4580214669307072
Validation loss: 1.4121

-------------------- Epoch 2873 --------------------
Train loss: 1.3494
Test loss: 1.410759374499321
Test loss: 1.4486670568585396
Validation loss: 1.4108

-------------------- Epoch 2874 --------------------
Train loss: 1.3649
Test loss: 1.408501202861468
Test loss: 1.452391433219115
Validation loss: 1.4085

-------------------- Epoch 2875 --------------------
Train loss: 1.3632
Test loss: 1.4053864205876987
Test loss: 1.4504762316743534
Validation loss: 1.4054

-------------------- Epoch 2876 --------------------
Train loss: 1.3505
Test loss: 1.40715495745341
Test loss: 1.4541716252764065
Validation loss: 1.4072

-------------------- Epoch 2877 --------------------
Train loss: 1.5109
Test loss: 1.406389149526755
Test loss: 1.4455893859267235
Validation loss: 1.4064

-------------------- Epoch 2878 --------------------
Train loss: 1.3544
Test loss: 1.4059002523620923
Test loss: 1.4443663160006206
Validation loss: 1.4059

-------------------- Epoch 2879 --------------------
Train loss: 1.3562
Test loss: 1.406073436141014
Test loss: 1.4487489064534504
Validation loss: 1.4061

-------------------- Epoch 2880 --------------------
Train loss: 1.3503
Test loss: 1.401583934823672
Test loss: 1.445593347152074
Validation loss: 1.4016

-------------------- Epoch 2881 --------------------
Train loss: 1.3554
Test loss: 1.406797523299853
Test loss: 1.4499852905670803
Validation loss: 1.4068

-------------------- Epoch 2882 --------------------
Train loss: 1.3523
Test loss: 1.4008823856711388
Test loss: 1.4436549221475918
Validation loss: 1.4009

-------------------- Epoch 2883 --------------------
Train loss: 1.3481
Test loss: 1.4033626193801563
Test loss: 1.4430086265007656
Validation loss: 1.4034

-------------------- Epoch 2884 --------------------
Train loss: 1.3548
Test loss: 1.4018804902831714
Test loss: 1.4431469291448593
Validation loss: 1.4019

-------------------- Epoch 2885 --------------------
Train loss: 1.3590
Test loss: 1.4022277891635895
Test loss: 1.448610154290994
Validation loss: 1.4022

-------------------- Epoch 2886 --------------------
Train loss: 1.3526
Test loss: 1.4030895108977954
Test loss: 1.4444541359941165
Validation loss: 1.4031

-------------------- Epoch 2887 --------------------
Train loss: 1.3491
Test loss: 1.3999293545881908
Test loss: 1.4437433083852131
New best validation loss: 1.3999, saving model weights to best_model_weights.pth

-------------------- Epoch 2888 --------------------
Train loss: 1.5462
Test loss: 1.4058631211519241
Test loss: 1.4464193160335224
Validation loss: 1.4059

-------------------- Epoch 2889 --------------------
Train loss: 1.3542
Test loss: 1.4069786270459492
Test loss: 1.45068455239137
Validation loss: 1.4070

-------------------- Epoch 2890 --------------------
Train loss: 1.3574
Test loss: 1.4050030782818794
Test loss: 1.4449061304330826
Validation loss: 1.4050

-------------------- Epoch 2891 --------------------
Train loss: 1.3496
Test loss: 1.4208371937274933
Test loss: 1.4579285656412442
Validation loss: 1.4208

-------------------- Epoch 2892 --------------------
Train loss: 1.3507
Test loss: 1.4028637905915577
Test loss: 1.4453752636909485
Validation loss: 1.4029

-------------------- Epoch 2893 --------------------
Train loss: 1.3488
Test loss: 1.4045060500502586
Test loss: 1.4444560607274373
Validation loss: 1.4045

-------------------- Epoch 2894 --------------------
Train loss: 1.3515
Test loss: 1.4019835342963536
Test loss: 1.4459674557050068
Validation loss: 1.4020

-------------------- Epoch 2895 --------------------
Train loss: 1.3525
Test loss: 1.4018150145808856
Test loss: 1.4437839885552723
Validation loss: 1.4018

-------------------- Epoch 2896 --------------------
Train loss: 1.3512
Test loss: 1.401181809604168
Test loss: 1.4426354095339775
Validation loss: 1.4012

-------------------- Epoch 2897 --------------------
Train loss: 1.3549
Test loss: 1.404179145892461
Test loss: 1.444423149029414
Validation loss: 1.4042

-------------------- Epoch 2898 --------------------
Train loss: 1.3466
Test loss: 1.429593488574028
Test loss: 1.477857381105423
Validation loss: 1.4296

-------------------- Epoch 2899 --------------------
Train loss: 1.3555
Test loss: 1.4050522521138191
Test loss: 1.4444389045238495
Validation loss: 1.4051

-------------------- Epoch 2900 --------------------
Train loss: 1.3508
Test loss: 1.4110717947284381
Test loss: 1.4483408406376839
Validation loss: 1.4111

-------------------- Epoch 2901 --------------------
Train loss: 1.3765
Test loss: 1.4061794156829517
Test loss: 1.44523186981678
Validation loss: 1.4062

-------------------- Epoch 2902 --------------------
Train loss: 1.3464
Test loss: 1.4007747521003087
Test loss: 1.4420957118272781
Validation loss: 1.4008

-------------------- Epoch 2903 --------------------
Train loss: 1.7616
Test loss: 1.4098938927054405
Test loss: 1.4477872103452682
Validation loss: 1.4099

-------------------- Epoch 2904 --------------------
Train loss: 1.3494
Test loss: 1.4005213603377342
Test loss: 1.4429795841375987
Validation loss: 1.4005

-------------------- Epoch 2905 --------------------
Train loss: 1.3434
Test loss: 1.401547831793626
Test loss: 1.4428043961524963
Validation loss: 1.4015

-------------------- Epoch 2906 --------------------
Train loss: 1.3483
Test loss: 1.401649701098601
Test loss: 1.443363179763158
Validation loss: 1.4016

-------------------- Epoch 2907 --------------------
Train loss: 1.3431
Test loss: 1.4028699497381847
Test loss: 1.4451148435473442
Validation loss: 1.4029

-------------------- Epoch 2908 --------------------
Train loss: 1.3535
Test loss: 1.4070989439884822
Test loss: 1.4515529225269954
Validation loss: 1.4071

-------------------- Epoch 2909 --------------------
Train loss: 1.3436
Test loss: 1.4070865909258525
Test loss: 1.4521799360712369
Validation loss: 1.4071

-------------------- Epoch 2910 --------------------
Train loss: 1.3514
Test loss: 1.4006070444981258
Test loss: 1.4435864388942719
Validation loss: 1.4006

-------------------- Epoch 2911 --------------------
Train loss: 1.3412
Test loss: 1.4027902831633885
Test loss: 1.4468746160467465
Validation loss: 1.4028

-------------------- Epoch 2912 --------------------
Train loss: 1.3520
Test loss: 1.4007187535365422
Test loss: 1.4427206267913182
Validation loss: 1.4007

-------------------- Epoch 2913 --------------------
Train loss: 1.3455
Test loss: 1.4058936014771461
Test loss: 1.4446816792090733
Validation loss: 1.4059

-------------------- Epoch 2914 --------------------
Train loss: 1.3441
Test loss: 1.4036613404750824
Test loss: 1.4438735196987789
Validation loss: 1.4037

-------------------- Epoch 2915 --------------------
Train loss: 1.3500
Test loss: 1.4018850574890773
Test loss: 1.4442166189352672
Validation loss: 1.4019

-------------------- Epoch 2916 --------------------
Train loss: 1.3522
Test loss: 1.401093065738678
Test loss: 1.4435670922199886
Validation loss: 1.4011

-------------------- Epoch 2917 --------------------
Train loss: 1.3445
Test loss: 1.4022459511955578
Test loss: 1.4428829078872998
Validation loss: 1.4022

-------------------- Epoch 2918 --------------------
Train loss: 1.3461
Test loss: 1.4029614205161731
Test loss: 1.4438748011986415
Validation loss: 1.4030

-------------------- Epoch 2919 --------------------
Train loss: 1.3494
Test loss: 1.4020643482605617
Test loss: 1.4457717115680377
Validation loss: 1.4021

-------------------- Epoch 2920 --------------------
Train loss: 1.3465
Test loss: 1.4064612711469333
Test loss: 1.4456920847296715
Validation loss: 1.4065

-------------------- Epoch 2921 --------------------
Train loss: 1.3483
Test loss: 1.404686227440834
Test loss: 1.448560744524002
Validation loss: 1.4047

-------------------- Epoch 2922 --------------------
Train loss: 1.6932
Test loss: 1.4023114865024884
Test loss: 1.4427963743607204
Validation loss: 1.4023

-------------------- Epoch 2923 --------------------
Train loss: 1.3501
Test loss: 1.4008393759528797
Test loss: 1.4427515019973118
Validation loss: 1.4008

-------------------- Epoch 2924 --------------------
Train loss: 1.3483
Test loss: 1.4025908857584
Test loss: 1.446016917626063
Validation loss: 1.4026

-------------------- Epoch 2925 --------------------
Train loss: 1.3554
Test loss: 1.400880495707194
Test loss: 1.44343647112449
Validation loss: 1.4009

-------------------- Epoch 2926 --------------------
Train loss: 1.3476
Test loss: 1.4022028247515361
Test loss: 1.4428268074989319
Validation loss: 1.4022

-------------------- Epoch 2927 --------------------
Train loss: 1.3538
Test loss: 1.4009519442915916
Test loss: 1.4426543340086937
Validation loss: 1.4010

-------------------- Epoch 2928 --------------------
Train loss: 1.3457
Test loss: 1.4015684351325035
Test loss: 1.444727415839831
Validation loss: 1.4016

-------------------- Epoch 2929 --------------------
Train loss: 1.3446
Test loss: 1.4026502991716068
Test loss: 1.4452633733550708
Validation loss: 1.4027

-------------------- Epoch 2930 --------------------
Train loss: 1.3531
Test loss: 1.4010179763038952
Test loss: 1.443453478316466
Validation loss: 1.4010

-------------------- Epoch 2931 --------------------
Train loss: 1.3529
Test loss: 1.4011872013409932
Test loss: 1.442581335703532
Validation loss: 1.4012

-------------------- Epoch 2932 --------------------
Train loss: 1.3487
Test loss: 1.4022019083301227
Test loss: 1.445019302268823
Validation loss: 1.4022

-------------------- Epoch 2933 --------------------
Train loss: 1.3479
Test loss: 1.4032157560189564
Test loss: 1.4463678499062855
Validation loss: 1.4032

-------------------- Epoch 2934 --------------------
Train loss: 1.3522
Test loss: 1.401711178322633
Test loss: 1.4433341125647228
Validation loss: 1.4017

-------------------- Epoch 2935 --------------------
Train loss: 1.3475
Test loss: 1.4037038112680118
Test loss: 1.4433518921335537
Validation loss: 1.4037

-------------------- Epoch 2936 --------------------
Train loss: 1.3437
Test loss: 1.4009682685136795
Test loss: 1.442864420513312
Validation loss: 1.4010

-------------------- Epoch 2937 --------------------
Train loss: 1.3408
Test loss: 1.401197890440623
Test loss: 1.4426525284846623
Validation loss: 1.4012

-------------------- Epoch 2938 --------------------
Train loss: 1.3458
Test loss: 1.4014692703882854
Test loss: 1.4434292713801067
Validation loss: 1.4015

-------------------- Epoch 2939 --------------------
Train loss: 1.3477
Test loss: 1.401985635360082
Test loss: 1.4447611570358276
Validation loss: 1.4020

-------------------- Epoch 2940 --------------------
Train loss: 1.3541
Test loss: 1.4013398612538974
Test loss: 1.4432284037272136
Validation loss: 1.4013

-------------------- Epoch 2941 --------------------
Train loss: 1.3499
Test loss: 1.401312033335368
Test loss: 1.443181611597538
Validation loss: 1.4013

-------------------- Epoch 2942 --------------------
Train loss: 1.3497
Test loss: 1.401177664597829
Test loss: 1.442749393483003
Validation loss: 1.4012

-------------------- Epoch 2943 --------------------
Train loss: 1.5999
Test loss: 1.401053433616956
Test loss: 1.4427215134104092
Validation loss: 1.4011

-------------------- Epoch 2944 --------------------
Train loss: 1.3456
Test loss: 1.4011254608631134
Test loss: 1.4434370299180348
Validation loss: 1.4011

-------------------- Epoch 2945 --------------------
Train loss: 1.3499
Test loss: 1.401527851819992
Test loss: 1.4425164659818013
Validation loss: 1.4015

-------------------- Epoch 2946 --------------------
Train loss: 1.3747
Test loss: 1.401463898519675
Test loss: 1.4437135780851047
Validation loss: 1.4015

-------------------- Epoch 2947 --------------------
Train loss: 1.4130
Test loss: 1.4011467769742012
Test loss: 1.4430015509327252
Validation loss: 1.4011

-------------------- Epoch 2948 --------------------
Train loss: 1.3507
Test loss: 1.401214713851611
Test loss: 1.4433435400327046
Validation loss: 1.4012

-------------------- Epoch 2949 --------------------
Train loss: 1.3465
Test loss: 1.4011388917764027
Test loss: 1.4431932394703229
Validation loss: 1.4011

-------------------- Epoch 2950 --------------------
Train loss: 1.3972
Test loss: 1.401640499631564
Test loss: 1.4439922248323758
Validation loss: 1.4016

-------------------- Epoch 2951 --------------------
Train loss: 1.3501
Test loss: 1.4017461016774178
Test loss: 1.4426763579249382
Validation loss: 1.4017

-------------------- Epoch 2952 --------------------
Train loss: 1.3439
Test loss: 1.4010776455203693
Test loss: 1.44319282968839
Validation loss: 1.4011

-------------------- Epoch 2953 --------------------
Train loss: 1.3460
Test loss: 1.4010984599590302
Test loss: 1.4428590834140778
Validation loss: 1.4011

-------------------- Epoch 2954 --------------------
Train loss: 1.3420
Test loss: 1.4012255370616913
Test loss: 1.4432216982046764
Validation loss: 1.4012

-------------------- Epoch 2955 --------------------
Train loss: 1.3426
Test loss: 1.4012591242790222
Test loss: 1.443465955555439
Validation loss: 1.4013

-------------------- Epoch 2956 --------------------
Train loss: 1.3425
Test loss: 1.4012020975351334
Test loss: 1.4427860428889592
Validation loss: 1.4012

-------------------- Epoch 2957 --------------------
Train loss: 1.4109
Test loss: 1.4011204615235329
Test loss: 1.4428593516349792
Validation loss: 1.4011

-------------------- Epoch 2958 --------------------
Train loss: 1.3455
Test loss: 1.4010122915108998
Test loss: 1.443175069987774
Validation loss: 1.4010

-------------------- Epoch 2959 --------------------
Train loss: 1.3504
Test loss: 1.4009446104367573
Test loss: 1.4427117134133975
Validation loss: 1.4009

-------------------- Epoch 2960 --------------------
Train loss: 1.3454
Test loss: 1.4009242927034695
Test loss: 1.4427784283955891
Validation loss: 1.4009

-------------------- Epoch 2961 --------------------
Train loss: 1.4163
Test loss: 1.4230276495218277
Test loss: 1.4676641821861267
Validation loss: 1.4230

-------------------- Epoch 2962 --------------------
Train loss: 1.4004
Test loss: 1.4310172696908314
Test loss: 1.4694877515236537
Validation loss: 1.4310

-------------------- Epoch 2963 --------------------
Train loss: 1.3932
Test loss: 1.4133166869481404
Test loss: 1.4508740877111752
Validation loss: 1.4133

-------------------- Epoch 2964 --------------------
Train loss: 1.3957
Test loss: 1.4148097584644954
Test loss: 1.4586300253868103
Validation loss: 1.4148

-------------------- Epoch 2965 --------------------
Train loss: 1.4074
Test loss: 1.5376853197813034
Test loss: 1.5744512379169464
Validation loss: 1.5377

-------------------- Epoch 2966 --------------------
Train loss: 1.4117
Test loss: 1.535402442018191
Test loss: 1.5722853591044743
Validation loss: 1.5354

-------------------- Epoch 2967 --------------------
Train loss: 1.3911
Test loss: 1.430821642279625
Test loss: 1.4813951551914215
Validation loss: 1.4308

-------------------- Epoch 2968 --------------------
Train loss: 1.4006
Test loss: 1.4219781905412674
Test loss: 1.4713044712940853
Validation loss: 1.4220

-------------------- Epoch 2969 --------------------
Train loss: 1.3952
Test loss: 1.4441949824492137
Test loss: 1.4940251509348552
Validation loss: 1.4442

-------------------- Epoch 2970 --------------------
Train loss: 1.4760
Test loss: 1.40815673271815
Test loss: 1.4494789317250252
Validation loss: 1.4082

-------------------- Epoch 2971 --------------------
Train loss: 1.3838
Test loss: 1.4812074452638626
Test loss: 1.506916602452596
Validation loss: 1.4812

-------------------- Epoch 2972 --------------------
Train loss: 1.4037
Test loss: 1.4205681756138802
Test loss: 1.4617293154199917
Validation loss: 1.4206

-------------------- Epoch 2973 --------------------
Train loss: 1.3797
Test loss: 1.433520793914795
Test loss: 1.477224623163541
Validation loss: 1.4335

-------------------- Epoch 2974 --------------------
Train loss: 1.3917
Test loss: 1.4244191348552704
Test loss: 1.4700524533788364
Validation loss: 1.4244

-------------------- Epoch 2975 --------------------
Train loss: 1.3907
Test loss: 1.4465515911579132
Test loss: 1.48353007932504
Validation loss: 1.4466

-------------------- Epoch 2976 --------------------
Train loss: 1.4030
Test loss: 1.426340028643608
Test loss: 1.4750252862771351
Validation loss: 1.4263

-------------------- Epoch 2977 --------------------
Train loss: 1.4047
Test loss: 1.4209223960836728
Test loss: 1.4725960170229275
Validation loss: 1.4209

-------------------- Epoch 2978 --------------------
Train loss: 1.4282
Test loss: 1.5477045228083928
Test loss: 1.5685140291849773
Validation loss: 1.5477

-------------------- Epoch 2979 --------------------
Train loss: 1.4163
Test loss: 1.4337006707986195
Test loss: 1.4678166508674622
Validation loss: 1.4337

-------------------- Epoch 2980 --------------------
Train loss: 1.4088
Test loss: 1.4692980622251828
Test loss: 1.5115477442741394
Validation loss: 1.4693

-------------------- Epoch 2981 --------------------
Train loss: 1.4042
Test loss: 1.4147490511337917
Test loss: 1.4593765164415042
Validation loss: 1.4147

-------------------- Epoch 2982 --------------------
Train loss: 1.3891
Test loss: 1.4695890098810196
Test loss: 1.5254490325848262
Validation loss: 1.4696

-------------------- Epoch 2983 --------------------
Train loss: 1.3957
Test loss: 1.4242925941944122
Test loss: 1.4535427764058113
Validation loss: 1.4243

-------------------- Epoch 2984 --------------------
Train loss: 1.4052
Test loss: 1.550238733490308
Test loss: 1.618082086245219
Validation loss: 1.5502

-------------------- Epoch 2985 --------------------
Train loss: 1.4090
Test loss: 1.4166594073176384
Test loss: 1.468564269443353
Validation loss: 1.4167

-------------------- Epoch 2986 --------------------
Train loss: 1.5252
Test loss: 1.4155386885007222
Test loss: 1.4574415683746338
Validation loss: 1.4155

-------------------- Epoch 2987 --------------------
Train loss: 1.3849
Test loss: 1.5063317865133286
Test loss: 1.5267715801795323
Validation loss: 1.5063

-------------------- Epoch 2988 --------------------
Train loss: 1.3904
Test loss: 1.4312106668949127
Test loss: 1.4651457592844963
Validation loss: 1.4312

-------------------- Epoch 2989 --------------------
Train loss: 1.4018
Test loss: 1.4399087230364482
Test loss: 1.4794297715028126
Validation loss: 1.4399

-------------------- Epoch 2990 --------------------
Train loss: 1.4000
Test loss: 1.4118346869945526
Test loss: 1.458301603794098
Validation loss: 1.4118

-------------------- Epoch 2991 --------------------
Train loss: 1.4184
Test loss: 1.4989746858676274
Test loss: 1.5583365509907405
Validation loss: 1.4990

-------------------- Epoch 2992 --------------------
Train loss: 1.4181
Test loss: 1.402738814552625
Test loss: 1.4455636218190193
Validation loss: 1.4027

-------------------- Epoch 2993 --------------------
Train loss: 1.3791
Test loss: 1.4281128123402596
Test loss: 1.4705833842357
Validation loss: 1.4281

-------------------- Epoch 2994 --------------------
Train loss: 1.3917
Test loss: 1.5285457968711853
Test loss: 1.585594708720843
Validation loss: 1.5285

-------------------- Epoch 2995 --------------------
Train loss: 1.4352
Test loss: 1.4203293472528458
Test loss: 1.4690125932296116
Validation loss: 1.4203

-------------------- Epoch 2996 --------------------
Train loss: 1.4094
Test loss: 1.510959729552269
Test loss: 1.5631082852681477
Validation loss: 1.5110

-------------------- Epoch 2997 --------------------
Train loss: 1.4001
Test loss: 1.5704813996950786
Test loss: 1.5886135300000508
Validation loss: 1.5705

-------------------- Epoch 2998 --------------------
Train loss: 1.4245
Test loss: 1.422076255083084
Test loss: 1.467674806714058
Validation loss: 1.4221

-------------------- Epoch 2999 --------------------
Train loss: 1.4237
Test loss: 1.4827971408764522
Test loss: 1.5374404986699421
Validation loss: 1.4828

-------------------- Epoch 3000 --------------------
Train loss: 1.3964
Test loss: 1.424153556426366
Test loss: 1.4698055138190587
Validation loss: 1.4242

-------------------- Final Results --------------------
Final Train loss: 1.3963812448761679
Final Validation loss: 1.424153556426366
Final Test loss: 1.4698055138190587
